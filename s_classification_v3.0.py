#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - ä¸“ä¸šç‰ˆ
=====================================
ç‰ˆæœ¬: 1.0
"""

import os
import sys
import time
import threading
import queue
import json
import pickle
from pathlib import Path
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
import matplotlib.colors as mcolors
import seaborn as sns
import geopandas as gpd
import rioxarray as rxr
import xarray as xr
from rasterio import features
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, 
                              AdaBoostClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.kernel_approximation import Nystroem, RBFSampler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, 
                           cohen_kappa_score, precision_score, recall_score, f1_score,
                           roc_curve, auc, precision_recall_curve, roc_auc_score)
from sklearn.inspection import permutation_importance
from scipy import ndimage
from skimage import morphology, filters
import warnings
warnings.filterwarnings('ignore')

sns.set_style("whitegrid")

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans", "Arial Unicode MS"]
plt.rcParams["axes.unicode_minus"] = False

# æ£€æŸ¥openpyxl
try:
    import openpyxl
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False
    print("âš ï¸  æœªå®‰è£…openpyxlï¼Œå°†æ— æ³•å¯¼å‡ºExcelæ–‡ä»¶")
    print("   å®‰è£…: pip install openpyxl")

# ==================== åç«¯å¤„ç†ç±» ====================
class ClassificationBackend:
    """åˆ†ç±»å¤„ç†åç«¯"""
    
    def __init__(self):
        self.RANDOM_STATE = 42
        
        # é¢„å®šä¹‰é¢œè‰²
        self.LANDUSE_COLORS = {
            "æ°´ä½“": "lightblue", "æ²³æµ": "blue", "æ¹–æ³Š": "deepskyblue",
            "æ¤è¢«": "forestgreen", "æ£®æ—": "darkgreen", "è‰åœ°": "limegreen",
            "å†œç”°": "yellowgreen", "è€•åœ°": "olivedrab",
            "å»ºç­‘": "gray", "åŸå¸‚": "dimgray", "å±…æ°‘åœ°": "slategray",
            "è£¸åœ°": "tan", "æ²™åœ°": "wheat", "å…¶ä»–": "darkred"
        }
        
        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', 
                             'darkred', 'purple', 'orange', 'pink', 'brown']
        
        # æ£€æŸ¥å¯é€‰åº“
        self.check_optional_libraries()
    
    def check_optional_libraries(self):
        """æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨"""
        self.has_xgboost = False
        self.has_lightgbm = False
        
        try:
            import xgboost
            from xgboost import XGBClassifier
            _ = XGBClassifier(n_estimators=10, verbosity=0)
            self.has_xgboost = True
            print("âœ“ XGBoost å¯ç”¨")
        except Exception:
            print("âœ— XGBoost ä¸å¯ç”¨")
        
        try:
            import lightgbm
            from lightgbm import LGBMClassifier
            _ = LGBMClassifier(n_estimators=10, verbose=-1)
            self.has_lightgbm = True
            print("âœ“ LightGBM å¯ç”¨")
        except Exception:
            print("âœ— LightGBM ä¸å¯ç”¨")
    
    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):
        """è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨"""
        if fast_mode:
            n_est = min(50, n_estimators)
            max_depth = 10
            max_iter = 200
        else:
            n_est = n_estimators
            max_depth = 20
            max_iter = 500
        
        if n_train_samples:
            n_components = min(1000, n_train_samples // 2)
        else:
            n_components = 1000
        
        classifiers = {
            "rf": (RandomForestClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE, 
                                         verbose=0, max_depth=max_depth, min_samples_split=5, 
                                         max_features='sqrt'),
                  "éšæœºæ£®æ—", "Random Forest", False, False, "fast"),
            
            "et": (ExtraTreesClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE,
                                       verbose=0, max_depth=max_depth, min_samples_split=5, max_features='sqrt'),
                  "æç«¯éšæœºæ ‘", "Extra Trees", False, False, "fast"),
            
            "dt": (DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=max_depth,
                                         min_samples_split=5, min_samples_leaf=2),
                  "å†³ç­–æ ‘", "Decision Tree", False, False, "very_fast"),
            
            "svm_linear": (SVC(kernel="linear", C=1.0, cache_size=500, probability=True, 
                             random_state=self.RANDOM_STATE, max_iter=max_iter),
                          "SVM-çº¿æ€§æ ¸", "SVM Linear", False, True, "medium"),
            
            "linear_svc": (CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=max_iter, random_state=self.RANDOM_STATE,
                                                           dual=False, loss='squared_hinge'), cv=3),
                          "çº¿æ€§SVM(å¿«)", "Linear SVM", False, True, "fast"),
            
            "sgd_svm": (SGDClassifier(loss='hinge', penalty='l2', max_iter=max_iter, n_jobs=-1,
                                     random_state=self.RANDOM_STATE, learning_rate='optimal'),
                       "SGD-SVM", "SGD SVM", False, True, "very_fast"),
            
            "nystroem_svm": (Pipeline([
                ("feature_map", Nystroem(kernel='rbf', gamma=0.1, n_components=n_components, 
                                        random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "æ ¸è¿‘ä¼¼SVM", "Nystroem SVM", False, True, "fast"),
            
            "rbf_sampler_svm": (Pipeline([
                ("feature_map", RBFSampler(gamma=0.1, n_components=n_components, random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "RBFé‡‡æ ·SVM", "RBF Sampler", False, True, "fast"),
            
            "svm_rbf": (SVC(kernel="rbf", C=1.0, gamma='scale', cache_size=500, probability=True, 
                          random_state=self.RANDOM_STATE),
                       "SVM-RBFæ ¸âš ï¸", "SVM RBF", False, True, "very_slow"),
            
            "knn": (KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm='ball_tree', leaf_size=30),
                   "Kè¿‘é‚»", "KNN", False, True, "slow"),
            
            "nb": (GaussianNB(), "æœ´ç´ è´å¶æ–¯", "Naive Bayes", False, False, "very_fast"),
            
            "gb": (GradientBoostingClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=5,
                                             random_state=self.RANDOM_STATE, verbose=0, subsample=0.8),
                  "æ¢¯åº¦æå‡", "Gradient Boosting", False, False, "medium"),
            
            # ä¿®å¤AdaBoostå‚æ•°é—®é¢˜
            "ada": (AdaBoostClassifier(n_estimators=n_est, learning_rate=1.0, 
                                      random_state=self.RANDOM_STATE),
                   "AdaBoost", "AdaBoost", False, False, "medium"),
            
            "lr": (LogisticRegression(max_iter=max_iter, n_jobs=-1, random_state=self.RANDOM_STATE,
                                     verbose=0, solver='lbfgs', multi_class='multinomial'),
                  "é€»è¾‘å›å½’", "Logistic Regression", False, True, "very_fast"),
            
            "mlp": (MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=max_iter, random_state=self.RANDOM_STATE,
                                 verbose=False, early_stopping=True, validation_fraction=0.1, 
                                 n_iter_no_change=10, learning_rate='adaptive'),
                   "ç¥ç»ç½‘ç»œ", "MLP", False, True, "medium"),
        }
        
        if self.has_xgboost:
            try:
                from xgboost import XGBClassifier
                classifiers["xgb"] = (
                    XGBClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=6, n_jobs=-1,
                                 random_state=self.RANDOM_STATE, verbosity=0, tree_method='hist',
                                 subsample=0.8, colsample_bytree=0.8),
                    "XGBoost", "XGBoost", True, False, "fast"
                )
            except Exception:
                pass
        
        if self.has_lightgbm:
            try:
                from lightgbm import LGBMClassifier
                classifiers["lgb"] = (
                    LGBMClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=max_depth, n_jobs=-1,
                                  random_state=self.RANDOM_STATE, verbose=-1, num_leaves=31,
                                  subsample=0.8, colsample_bytree=0.8, force_col_wise=True),
                    "LightGBM", "LightGBM", False, False, "very_fast"
                )
            except Exception:
                pass
        
        return classifiers

    def get_hyperparameter_grids(self, clf_code, n_samples=None):
        """è·å–å„åˆ†ç±»å™¨çš„è¶…å‚æ•°ç½‘æ ¼"""
        grids = {}
        
        # åŸºç¡€å‚æ•°
        if n_samples and n_samples < 1000:
            n_estimators_range = [50, 100]
            max_depth_range = [3, 5, 7]
        elif n_samples and n_samples < 10000:
            n_estimators_range = [100, 200]
            max_depth_range = [5, 10, 15]
        else:
            n_estimators_range = [100, 200, 300]
            max_depth_range = [10, 15, 20, None]
        
        if clf_code == "rf":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': max_depth_range,
                'min_samples_split': [2, 5, 10],
                'max_features': ['sqrt', 'log2', None]
            }
        elif clf_code == "xgb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': [3, 6, 9],
                'learning_rate': [0.01, 0.1, 0.2],
                'subsample': [0.8, 1.0],
                'colsample_bytree': [0.8, 1.0]
            }
        elif clf_code == "lgb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': [3, 6, 9, -1],
                'learning_rate': [0.01, 0.1, 0.2],
                'num_leaves': [31, 63, 127],
                'subsample': [0.8, 1.0]
            }
        elif clf_code == "svm_linear":
            grids[clf_code] = {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto']
            }
        elif clf_code == "svm_rbf":
            grids[clf_code] = {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto', 0.1, 1]
            }
        elif clf_code == "knn":
            grids[clf_code] = {
                'n_neighbors': [3, 5, 7, 9, 11],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan']
            }
        elif clf_code == "mlp":
            grids[clf_code] = {
                'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],
                'alpha': [0.0001, 0.001, 0.01],
                'learning_rate': ['constant', 'adaptive']
            }
        elif clf_code == "gb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'subsample': [0.8, 1.0]
            }
        
        return grids.get(clf_code, {})
    
    def optimize_hyperparameters(self, clf, clf_code, X_train, y_train, cv=3, n_iter=20):
        """è¶…å‚æ•°ä¼˜åŒ–"""
        param_grid = self.get_hyperparameter_grids(clf_code, len(y_train))
        
        if not param_grid:
            return clf, {}, 0
        
        try:
            # å¯¹äºå¤§æ•°æ®é›†ä½¿ç”¨éšæœºæœç´¢ï¼Œå°æ•°æ®é›†ä½¿ç”¨ç½‘æ ¼æœç´¢
            if len(y_train) > 1000 or len(param_grid) > 10:
                search = RandomizedSearchCV(
                    clf, param_grid, n_iter=min(n_iter, len(param_grid) * 3), 
                    cv=cv, scoring='accuracy', n_jobs=-1, random_state=self.RANDOM_STATE,
                    verbose=0
                )
            else:
                search = GridSearchCV(
                    clf, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, 
                    verbose=0
                )
            
            search.fit(X_train, y_train)
            
            return search.best_estimator_, search.best_params_, search.best_score_
        
        except Exception as e:
            print(f"è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return clf, {}, 0
    
    def apply_postprocessing(self, classified_array, method='majority', size=3):
        """åå¤„ç†æ»¤æ³¢"""
        if method == 'none':
            return classified_array
        
        # åˆ›å»ºæ©è†œï¼Œåªå¤„ç†éèƒŒæ™¯åŒºåŸŸ
        mask = classified_array > 0
        result = classified_array.copy()
        
        if method == 'majority':
            # å¤šæ•°æ»¤æ³¢
            from scipy.ndimage import generic_filter
            
            def majority_filter(x):
                values, counts = np.unique(x, return_counts=True)
                return values[np.argmax(counts)]
            
            result[mask] = generic_filter(
                classified_array, majority_filter, size=size, mode='constant', cval=0
            )[mask]
        
        elif method == 'median':
            # ä¸­å€¼æ»¤æ³¢
            result[mask] = ndimage.median_filter(classified_array, size=size)[mask]
        
        elif method == 'opening':
            # å½¢æ€å­¦å¼€è¿ç®—ï¼ˆå»é™¤å°æ–‘å—ï¼‰
            from skimage.morphology import opening, square
            result = opening(classified_array, square(size))
        
        elif method == 'closing':
            # å½¢æ€å­¦é—­è¿ç®—ï¼ˆå¡«å……å°æ´ï¼‰
            from skimage.morphology import closing, square
            result = closing(classified_array, square(size))
        
        return result
    
    def analyze_feature_importance(self, model, feature_names, X_val, y_val, n_repeats=5):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        try:
            # å¯¹äºæ ‘æ¨¡å‹ï¼Œä½¿ç”¨å†…ç½®ç‰¹å¾é‡è¦æ€§
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                
                # ä¿®å¤ï¼šç¡®ä¿stdæ˜¯æ­£ç¡®å½¢çŠ¶çš„æ•°ç»„
                if hasattr(model, 'estimators_') and model.estimators_ is not None:
                    try:
                        # è·å–æ‰€æœ‰æ ‘çš„é‡è¦æ€§
                        tree_importances = np.array([tree.feature_importances_ for tree in model.estimators_])
                        std = np.std(tree_importances, axis=0)
                    except:
                        std = np.zeros_like(importances)
                else:
                    std = np.zeros_like(importances)
                
                return {
                    'method': 'builtin',
                    'importances': importances,
                    'std': std,
                    'indices': np.argsort(importances)[::-1]
                }
            
            # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨æ’åˆ—é‡è¦æ€§
            else:
                try:
                    result = permutation_importance(
                        model, X_val, y_val, n_repeats=n_repeats, 
                        random_state=self.RANDOM_STATE, n_jobs=-1
                    )
                    
                    return {
                        'method': 'permutation',
                        'importances': result.importances_mean,
                        'std': result.importances_std,
                        'indices': np.argsort(result.importances_mean)[::-1]
                    }
                except Exception as e:
                    print(f"æ’åˆ—é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
                    return None
        
        except Exception as e:
            print(f"ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
            return None
    
    def plot_feature_importance(self, importance_data, feature_names, save_path, clf_name):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        if not importance_data:
            return None
        
        try:
            fig, ax = plt.subplots(figsize=(10, 6))
            
            indices = importance_data['indices']
            importances = importance_data['importances']
            
            # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†ç´¢å¼•å’Œé‡è¦æ€§æ•°ç»„
            if len(indices) > 0 and len(importances) > 0:
                # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                valid_indices = indices[indices < len(importances)]
                sorted_importances = importances[valid_indices]
                
                # å¤„ç†æ ‡å‡†å·®
                if 'std' in importance_data and importance_data['std'] is not None:
                    std = importance_data['std']
                    if len(std) == len(importances):
                        sorted_std = std[valid_indices]
                    else:
                        sorted_std = None
                else:
                    sorted_std = None
                
                features = [feature_names[i] for i in valid_indices if i < len(feature_names)]
                
                y_pos = np.arange(len(features))
                
                if sorted_std is not None and len(sorted_std) == len(sorted_importances):
                    ax.barh(y_pos, sorted_importances, xerr=sorted_std, align='center', alpha=0.7)
                else:
                    ax.barh(y_pos, sorted_importances, align='center', alpha=0.7)
                
                ax.set_yticks(y_pos)
                ax.set_yticklabels(features)
                ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
                ax.set_title(f'{clf_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ')
                ax.grid(True, alpha=0.3, axis='x')
                
                plt.tight_layout()
                fig.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close(fig)
                
                return save_path
            else:
                print("ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆ")
                return None
                
        except Exception as e:
            print(f"ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾å¤±è´¥: {e}")
            return None
    
    def plot_roc_curves(self, model, X_test, y_test, class_names, save_path, clf_name):
        """ç»˜åˆ¶ROCæ›²çº¿ï¼ˆé€‚ç”¨äºäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»ï¼‰"""
        try:
            # è·å–é¢„æµ‹æ¦‚ç‡
            if hasattr(model, 'predict_proba'):
                y_score = model.predict_proba(X_test)
            else:
                # å¯¹äºæ²¡æœ‰predict_probaçš„æ¨¡å‹ï¼Œä½¿ç”¨å†³ç­–å‡½æ•°
                y_score = model.decision_function(X_test)
                if y_score.ndim == 1:
                    y_score = y_score.reshape(-1, 1)
            
            n_classes = len(class_names)
            
            fig, ax = plt.subplots(figsize=(10, 8))
            
            if n_classes == 2:
                # äºŒåˆ†ç±»
                fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])
                roc_auc = auc(fpr, tpr)
                
                ax.plot(fpr, tpr, color='darkorange', lw=2,
                    label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})')
                ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨')
                
            else:
                # å¤šåˆ†ç±» - ä¸€å¯¹å¤š
                from sklearn.preprocessing import label_binarize
                
                # è·å–æ‰€æœ‰ç±»åˆ«
                classes = np.unique(y_test)
                y_test_bin = label_binarize(y_test, classes=classes)
                
                fpr = dict()
                tpr = dict()
                roc_auc = dict()
                
                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ROCæ›²çº¿
                for i, class_id in enumerate(classes):
                    if y_score.shape[1] > i:  # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
                        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
                        roc_auc[i] = auc(fpr[i], tpr[i])
                        
                        class_name = class_names.get(class_id, f'ç±»åˆ«_{class_id}')
                        ax.plot(fpr[i], tpr[i], lw=2,
                            label=f'{class_name} (AUC = {roc_auc[i]:.2f})')
                
                # è®¡ç®—å®å¹³å‡ROCæ›²çº¿
                all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes))]))
                mean_tpr = np.zeros_like(all_fpr)
                
                for i in range(len(classes)):
                    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
                
                mean_tpr /= len(classes)
                
                fpr["macro"] = all_fpr
                tpr["macro"] = mean_tpr
                roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])
                
                ax.plot(fpr["macro"], tpr["macro"],
                    label=f'å®å¹³å‡ (AUC = {roc_auc["macro"]:.2f})',
                    color='navy', linestyle=':', linewidth=4)
                
                ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨', alpha=0.8)
            
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡ (False Positive Rate)', fontsize=12)
            ax.set_ylabel('çœŸæ­£ç‡ (True Positive Rate)', fontsize=12)
            ax.set_title(f'{clf_name} - ROCæ›²çº¿', fontsize=14, fontweight='bold')
            ax.legend(loc="lower right", fontsize=10)
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close(fig)
            
            # ä¿å­˜AUCæ•°æ®
            auc_data = {
                'class_names': class_names,
                'auc_scores': roc_auc if n_classes == 2 else {class_names.get(k, f'ç±»åˆ«_{k}'): v for k, v in roc_auc.items()},
                'macro_auc': roc_auc if n_classes == 2 else roc_auc.get("macro", 0)
            }
            
            # ä¿å­˜è¯¦ç»†çš„ROCæ•°æ®
            roc_data = {
                'fpr': fpr if n_classes == 2 else {k: v.tolist() for k, v in fpr.items()},
                'tpr': tpr if n_classes == 2 else {k: v.tolist() for k, v in tpr.items()},
                'auc': roc_auc if n_classes == 2 else {k: v for k, v in roc_auc.items()}
            }
            
            with open(save_path.parent / f"{save_path.stem}_auc.json", 'w', encoding='utf-8') as f:
                json.dump(auc_data, f, indent=2, ensure_ascii=False)
            
            with open(save_path.parent / f"{save_path.stem}_roc_data.json", 'w', encoding='utf-8') as f:
                json.dump(roc_data, f, indent=2, ensure_ascii=False)
            
            return save_path, auc_data, roc_data
        
        except Exception as e:
            print(f"ROCæ›²çº¿ç»˜åˆ¶å¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            return None, None, None
    
    def save_model(self, model, file_path):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            with open(file_path, 'wb') as f:
                pickle.dump(model, f)
            return True
        except Exception as e:
            print(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def load_model(self, file_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            with open(file_path, 'rb') as f:
                model = pickle.load(f)
            return model
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def get_background_mask(self, image, background_value=0):
        """è·å–èƒŒæ™¯æ©è†œ"""
        data = image.values
        if background_value == 0:
            background_mask = np.all(data == 0, axis=0)
        else:
            background_mask = np.all(data == background_value, axis=0)
        return background_mask
    
    def get_shapefile_fields(self, shp_path):
        """è·å–shapefileçš„æ‰€æœ‰å­—æ®µå"""
        try:
            gdf = gpd.read_file(shp_path)
            return list(gdf.columns)
        except Exception as e:
            print(f"è¯»å–shapefileå­—æ®µå¤±è´¥: {e}")
            return []
    
    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):
        """ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯"""
        gdf = gpd.read_file(shp_path)
        
        if name_attr not in gdf.columns or name_attr == class_attr:
            gdf[name_attr] = gdf[class_attr].apply(lambda x: f"ç±»åˆ«_{x}")
        
        class_info = gdf[[class_attr, name_attr]].drop_duplicates()
        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))
        
        class_colors = {}
        for i, (class_id, class_name) in enumerate(class_names.items()):
            color_found = False
            for key, color in self.LANDUSE_COLORS.items():
                if key in str(class_name):
                    class_colors[class_id] = color
                    color_found = True
                    break
            if not color_found:
                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]
        
        return class_names, class_colors, sorted(class_names.keys())
    
    def rasterize_samples(self, shp, ref_img, attr):
        """çŸ¢é‡æ …æ ¼åŒ–"""
        gdf = gpd.read_file(shp)
        gdf = gdf.to_crs(ref_img.rio.crs)
        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))
        
        arr = features.rasterize(shapes=shapes, out_shape=ref_img.shape[1:],
                                transform=ref_img.rio.transform(), fill=0,
                                all_touched=True, dtype="uint16")
        return arr
    
    def extract_samples(self, image, mask, ignore_background=True, background_value=0, max_samples=None):
        """æå–æ ·æœ¬"""
        data = np.moveaxis(image.values, 0, -1)
        valid = mask > 0
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
            valid = valid & (~background_mask)
        
        X = data[valid]
        y = mask[valid]
        
        # æ¸…ç†NaNå’ŒInf
        nan_mask = np.isnan(X).any(axis=1)
        inf_mask = np.isinf(X).any(axis=1)
        bad_mask = nan_mask | inf_mask
        
        n_nan = np.sum(nan_mask)
        n_inf = np.sum(inf_mask)
        
        X = X[~bad_mask]
        y = y[~bad_mask]
        
        # åˆ†å±‚é‡‡æ ·
        n_sampled = 0
        if max_samples is not None and len(y) > max_samples:
            n_original = len(y)
            unique_classes = np.unique(y)
            
            if len(unique_classes) > 1:
                splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_samples, 
                                                 random_state=self.RANDOM_STATE)
                sample_idx, _ = next(splitter.split(X, y))
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
            else:
                np.random.seed(self.RANDOM_STATE)
                sample_idx = np.random.choice(len(y), max_samples, replace=False)
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
        
        return X, y, n_nan, n_inf, n_sampled
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'overall_accuracy': accuracy_score(y_true, y_pred),
            'kappa': cohen_kappa_score(y_true, y_pred),
            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        }
    
    def save_confusion_matrix(self, y_true, y_pred, class_names, save_path, clf_name):
        """ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆå›¾ç‰‡+Excelï¼‰"""
        if not HAS_OPENPYXL:
            return None, None
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred)
        
        # ä¿å­˜Excelæ ¼å¼
        cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)
        excel_path = save_path.parent / f"{save_path.stem}_confusion_matrix.xlsx"
        cm_df.to_excel(excel_path, engine='openpyxl')
        
        # ç»˜åˆ¶å¹¶ä¿å­˜å›¾ç‰‡
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=class_names, yticklabels=class_names,
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=12)
        ax.set_title(f'{clf_name} - æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        plt.tight_layout()
        
        img_path = save_path.parent / f"{save_path.stem}_confusion_matrix.png"
        fig.savefig(img_path, dpi=300, bbox_inches='tight')
        plt.close(fig)
        
        return excel_path, img_path
    
    def calculate_area_statistics(self, classified_array, pixel_size_x, pixel_size_y, 
                                  class_names, background_value=0):
        """è®¡ç®—é¢ç§¯ç»Ÿè®¡"""
        # è®¡ç®—æ¯ä¸ªåƒå…ƒçš„é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
        pixel_area = abs(pixel_size_x * pixel_size_y)
        
        # ç»Ÿè®¡å„ç±»åˆ«åƒå…ƒæ•°é‡
        unique_classes, counts = np.unique(classified_array[classified_array != background_value], 
                                          return_counts=True)
        
        # è®¡ç®—æ€»åƒå…ƒæ•°ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ï¼‰
        total_pixels = np.sum(counts)
        
        # æ„å»ºç»Ÿè®¡è¡¨
        stats = []
        for class_id, pixel_count in zip(unique_classes, counts):
            class_name = class_names.get(class_id, f"ç±»åˆ«_{class_id}")
            area_m2 = pixel_count * pixel_area
            area_km2 = area_m2 / 1_000_000
            area_ha = area_m2 / 10_000
            percentage = (pixel_count / total_pixels) * 100
            
            stats.append({
                'ç±»åˆ«ç¼–å·': int(class_id),
                'ç±»åˆ«åç§°': class_name,
                'åƒå…ƒæ•°é‡': int(pixel_count),
                'é¢ç§¯(mÂ²)': area_m2,
                'é¢ç§¯(ha)': area_ha,
                'é¢ç§¯(kmÂ²)': area_km2,
                'ç™¾åˆ†æ¯”(%)': percentage
            })
        
        df = pd.DataFrame(stats)
        
        # æ·»åŠ æ€»è®¡è¡Œ
        total_row = {
            'ç±»åˆ«ç¼–å·': '',
            'ç±»åˆ«åç§°': 'æ€»è®¡',
            'åƒå…ƒæ•°é‡': int(total_pixels),
            'é¢ç§¯(mÂ²)': df['é¢ç§¯(mÂ²)'].sum(),
            'é¢ç§¯(ha)': df['é¢ç§¯(ha)'].sum(),
            'é¢ç§¯(kmÂ²)': df['é¢ç§¯(kmÂ²)'].sum(),
            'ç™¾åˆ†æ¯”(%)': 100.0
        }
        df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)
        
        return df
    
    def save_classification_report(self, y_true, y_pred, class_names, save_path):
        """ä¿å­˜è¯¦ç»†åˆ†ç±»æŠ¥å‘Šï¼ˆæ–‡æœ¬+Excelï¼‰"""
        if not HAS_OPENPYXL:
            # ä»…ä¿å­˜æ–‡æœ¬æ ¼å¼
            txt_path = save_path.parent / f"{save_path.stem}_classification_report.txt"
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(classification_report(y_true, y_pred, 
                                             target_names=class_names,
                                             zero_division=0))
            return None, txt_path
        
        # è·å–sklearnçš„åˆ†ç±»æŠ¥å‘Š
        report_dict = classification_report(y_true, y_pred, 
                                           target_names=class_names,
                                           output_dict=True,
                                           zero_division=0)
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(report_dict).transpose()
        
        # ä¿å­˜Excel
        excel_path = save_path.parent / f"{save_path.stem}_classification_report.xlsx"
        df.to_excel(excel_path, engine='openpyxl')
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼
        txt_path = save_path.parent / f"{save_path.stem}_classification_report.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(classification_report(y_true, y_pred, 
                                         target_names=class_names,
                                         zero_division=0))
        
        return excel_path, txt_path
    
    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):
        """ä¼°ç®—é¢„æµ‹æ—¶é—´"""
        time_per_million = {"very_fast": 1, "fast": 3, "medium": 10, "slow": 30, "very_slow": 300}
        base_time = time_per_million.get(speed_tag, 10)
        return (n_pixels / 1_000_000) * base_time
    
    def predict_by_block(self, model, image, out_path, block_size=512, 
                        ignore_background=True, background_value=0, progress_callback=None,
                        label_encoder=None, scaler=None, postprocessing=None):
        """åˆ†å—é¢„æµ‹"""
        height, width = image.shape[1], image.shape[2]
        prediction = np.zeros((height, width), dtype='uint16')
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
        
        total_blocks = int(np.ceil(height / block_size))
        
        for i, y in enumerate(range(0, height, block_size)):
            if not hasattr(self, 'is_running') or self.is_running:
                h = min(block_size, height - y)
                block_data = image.isel(y=slice(y, y+h)).values
                data = np.moveaxis(block_data, 0, -1)
                original_shape = data.shape
                data_flat = data.reshape(-1, data.shape[-1])
                
                if ignore_background:
                    block_bg_mask = background_mask[y:y+h, :].flatten()
                    non_bg_indices = ~block_bg_mask
                    
                    if np.any(non_bg_indices):
                        data_to_predict = np.nan_to_num(data_flat[non_bg_indices], 
                                                       nan=0.0, posinf=0.0, neginf=0.0)
                        
                        if scaler is not None:
                            data_to_predict = scaler.transform(data_to_predict)
                        
                        preds_non_bg = model.predict(data_to_predict)
                        
                        if label_encoder is not None:
                            preds_non_bg = label_encoder.inverse_transform(preds_non_bg)
                        
                        preds_flat = np.zeros(len(data_flat), dtype='uint16')
                        preds_flat[non_bg_indices] = preds_non_bg
                        preds = preds_flat.reshape(original_shape[0], original_shape[1])
                    else:
                        preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')
                else:
                    data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)
                    
                    if scaler is not None:
                        data_flat = scaler.transform(data_flat)
                    
                    preds = model.predict(data_flat)
                    
                    if label_encoder is not None:
                        preds = label_encoder.inverse_transform(preds)
                    
                    preds = preds.reshape(original_shape[0], original_shape[1]).astype("uint16")
                
                prediction[y:y+h, :] = preds
                
                if progress_callback:
                    progress_callback((i + 1) / total_blocks * 100)
            else:
                break
        
        # åº”ç”¨åå¤„ç†
        if postprocessing and postprocessing != 'none':
            prediction = self.apply_postprocessing(prediction, method=postprocessing)
        
        # ä¿å­˜ç»“æœ
        prediction_da = xr.DataArray(prediction, dims=['y', 'x'],
                                     coords={'y': image.coords['y'], 'x': image.coords['x']})
        
        prediction_da.rio.write_crs(image.rio.crs, inplace=True)
        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)
        prediction_da.rio.write_nodata(background_value, inplace=True)
        
        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', 
                                    compress='lzw', tiled=True)
        return out_path

# ==================== GUIä¸»ç±» ====================
class ClassificationGUI:
    """é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢ï¼ˆä¸“ä¸šç‰ˆ v1.0ï¼‰"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ")
        
        # çª—å£æœ€å¤§åŒ–
        try:
            # Windows
            self.root.state('zoomed')
        except:
            try:
                # Linux/Mac
                self.root.attributes('-zoomed', True)
            except:
                # å¤‡é€‰æ–¹æ¡ˆï¼šè®¾ç½®ä¸ºå±å¹•å¤§å°
                screen_width = self.root.winfo_screenwidth()
                screen_height = self.root.winfo_screenheight()
                self.root.geometry(f"{screen_width}x{screen_height}+0+0")
        
        # åç«¯å¤„ç†å¯¹è±¡
        self.backend = ClassificationBackend()
        
        # æ•°æ®å˜é‡
        self.image_path = tk.StringVar()
        self.train_shp_path = tk.StringVar()
        self.val_shp_path = tk.StringVar()
        self.output_dir = tk.StringVar(value=str(Path("./results_gui")))
        
        # å­—æ®µé€‰æ‹©
        self.train_fields = []
        self.class_attr = tk.StringVar()
        self.name_attr = tk.StringVar()
        
        # èƒŒæ™¯å€¼
        self.background_value = tk.IntVar(value=0)
        self.ignore_background = tk.BooleanVar(value=True)
        
        # å…¶ä»–å‚æ•°
        self.n_estimators = tk.IntVar(value=100)
        self.block_size = tk.IntVar(value=512)
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.enable_sampling = tk.BooleanVar(value=True)
        self.max_samples = tk.IntVar(value=50000)
        self.fast_mode = tk.BooleanVar(value=False)
        
        # æ–°å¢åŠŸèƒ½å‚æ•°
        self.enable_hyperparameter_optimization = tk.BooleanVar(value=False)
        self.hyperparameter_optimization_method = tk.StringVar(value="random")
        self.hyperparameter_iterations = tk.IntVar(value=20)
        
        self.enable_postprocessing = tk.BooleanVar(value=True)
        self.postprocessing_method = tk.StringVar(value="majority")
        self.postprocessing_size = tk.IntVar(value=3)
        
        self.enable_feature_importance = tk.BooleanVar(value=True)
        self.enable_roc_analysis = tk.BooleanVar(value=True)
        self.enable_model_saving = tk.BooleanVar(value=True)
        
        # åˆ†ç±»å™¨é€‰æ‹©
        self.classifier_vars = {}
        all_classifiers = self.backend.get_all_classifiers()
        for code in all_classifiers.keys():
            self.classifier_vars[code] = tk.BooleanVar(value=False)
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.log_queue = queue.Queue()
        
        # å­˜å‚¨ç»“æœæ•°æ®
        self.comparison_results = []
        self.current_confusion_matrix = None
        self.current_y_true = None
        self.current_y_pred = None
        self.class_names_dict = {}
        self.class_colors_dict = {}
        self.best_result_path = None
        
        # æ„å»ºç•Œé¢
        self.build_ui()
        
        # å¯åŠ¨æ—¥å¿—æ›´æ–°
        self.update_log()
    
    def build_ui(self):
        """æ„å»ºç”¨æˆ·ç•Œé¢ï¼ˆå·¦å³åˆ†æ ï¼‰"""
        # åˆ›å»ºä¸»PanedWindow
        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # ===== å·¦ä¾§é¢æ¿ï¼šå‚æ•°è®¾ç½® =====
        left_frame = ttk.Frame(main_paned, width=600)
        main_paned.add(left_frame, weight=1)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        canvas = tk.Canvas(left_frame)
        scrollbar = ttk.Scrollbar(left_frame, orient="vertical", command=canvas.yview)
        scrollable_left = ttk.Frame(canvas)
        
        scrollable_left.bind("<Configure>", 
                            lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
        
        canvas.create_window((0, 0), window=scrollable_left, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # 1. æ–‡ä»¶é€‰æ‹©
        file_frame = ttk.LabelFrame(scrollable_left, text="ğŸ“ æ•°æ®æ–‡ä»¶", padding="10")
        file_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(file_frame, text="å½±åƒæ–‡ä»¶:").grid(row=0, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.image_path, width=40).grid(
            row=0, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_image).grid(row=0, column=2)
        
        ttk.Label(file_frame, text="è®­ç»ƒæ ·æœ¬:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=40).grid(
            row=1, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_train_shp).grid(row=1, column=2)
        
        ttk.Label(file_frame, text="éªŒè¯æ ·æœ¬:").grid(row=2, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=40).grid(
            row=2, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_val_shp).grid(row=2, column=2)
        
        ttk.Label(file_frame, text="è¾“å‡ºç›®å½•:").grid(row=3, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.output_dir, width=40).grid(
            row=3, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_output).grid(row=3, column=2)
        
        file_frame.columnconfigure(1, weight=1)
        
        # 2. å­—æ®µé€‰æ‹©
        field_frame = ttk.LabelFrame(scrollable_left, text="ğŸ·ï¸ å­—æ®µé…ç½®", padding="10")
        field_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(field_frame, text="ç±»åˆ«ç¼–å·å­—æ®µ:").grid(row=0, column=0, sticky=tk.W, pady=3)
        self.class_attr_combo = ttk.Combobox(field_frame, textvariable=self.class_attr, 
                                            width=20, state="readonly")
        self.class_attr_combo.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=5)
        
        ttk.Label(field_frame, text="ç±»åˆ«åç§°å­—æ®µ:").grid(row=1, column=0, sticky=tk.W, pady=3)
        self.name_attr_combo = ttk.Combobox(field_frame, textvariable=self.name_attr, 
                                           width=20, state="readonly")
        self.name_attr_combo.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5)
        
        ttk.Button(field_frame, text="ğŸ”„ åˆ·æ–°å­—æ®µåˆ—è¡¨", 
                  command=self.refresh_fields).grid(row=0, column=2, rowspan=2, padx=5)
        
        field_frame.columnconfigure(1, weight=1)
        
        # 3. èƒŒæ™¯å€¼è®¾ç½®
        bg_frame = ttk.LabelFrame(scrollable_left, text="ğŸ¨ èƒŒæ™¯å€¼è®¾ç½®", padding="10")
        bg_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Checkbutton(bg_frame, text="å¿½ç•¥èƒŒæ™¯å€¼", 
                       variable=self.ignore_background).grid(row=0, column=0, sticky=tk.W, pady=3)
        
        ttk.Label(bg_frame, text="èƒŒæ™¯å€¼:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(bg_frame, from_=-9999, to=9999, textvariable=self.background_value, 
                   width=15).grid(row=1, column=1, sticky=tk.W, padx=5)
        ttk.Label(bg_frame, text="(é»˜è®¤0, å¸¸è§: -9999, 255)", 
                 font=('', 8), foreground='gray').grid(row=1, column=2, sticky=tk.W)
        
        # 4. åˆ†ç±»å‚æ•°
        param_frame = ttk.LabelFrame(scrollable_left, text="âš™ï¸ åˆ†ç±»å‚æ•°", padding="10")
        param_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(param_frame, text="æ ‘æ¨¡å‹æ•°é‡:").grid(row=0, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, 
                   width=15).grid(row=0, column=1, sticky=tk.W, padx=5)
        
        ttk.Label(param_frame, text="åˆ†å—å¤§å°:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, 
                   textvariable=self.block_size, width=15).grid(row=1, column=1, sticky=tk.W, padx=5)
        
        # 5. æ€§èƒ½ä¼˜åŒ–
        opt_frame = ttk.LabelFrame(scrollable_left, text="âš¡ æ€§èƒ½ä¼˜åŒ–", padding="10")
        opt_frame.pack(fill=tk.X, padx=5, pady=5)
        
        sample_frame = ttk.Frame(opt_frame)
        sample_frame.pack(fill=tk.X, pady=2)
        
        ttk.Checkbutton(sample_frame, text="å¯ç”¨é‡‡æ ·", 
                       variable=self.enable_sampling,
                       command=self.toggle_sampling).pack(side=tk.LEFT)
        
        ttk.Label(sample_frame, text="æœ€å¤§æ ·æœ¬æ•°:").pack(side=tk.LEFT, padx=(10, 0))
        self.max_samples_spinbox = ttk.Spinbox(sample_frame, from_=10000, to=200000, 
                                              increment=10000, textvariable=self.max_samples, 
                                              width=10)
        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)
        
        ttk.Checkbutton(opt_frame, text="å¿«é€Ÿæ¨¡å¼", 
                       variable=self.fast_mode).pack(anchor=tk.W, pady=2)
        
        # 6. æ–°å¢åŠŸèƒ½é…ç½®
        advanced_frame = ttk.LabelFrame(scrollable_left, text="ğŸš€ é«˜çº§åŠŸèƒ½", padding="10")
        advanced_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # è¶…å‚æ•°ä¼˜åŒ–
        hyper_frame = ttk.Frame(advanced_frame)
        hyper_frame.pack(fill=tk.X, pady=2)
        
        ttk.Checkbutton(hyper_frame, text="è¶…å‚æ•°ä¼˜åŒ–", 
                       variable=self.enable_hyperparameter_optimization).pack(side=tk.LEFT)
        
        ttk.Label(hyper_frame, text="æ–¹æ³•:").pack(side=tk.LEFT, padx=(10, 0))
        hyper_method_combo = ttk.Combobox(hyper_frame, 
                                         textvariable=self.hyperparameter_optimization_method,
                                         values=["random", "grid"], width=8, state="readonly")
        hyper_method_combo.pack(side=tk.LEFT, padx=5)
        
        ttk.Label(hyper_frame, text="è¿­ä»£æ¬¡æ•°:").pack(side=tk.LEFT, padx=(10, 0))
        ttk.Spinbox(hyper_frame, from_=5, to=100, 
                   textvariable=self.hyperparameter_iterations, width=8).pack(side=tk.LEFT, padx=5)
        
        # åå¤„ç†
        post_frame = ttk.Frame(advanced_frame)
        post_frame.pack(fill=tk.X, pady=2)
        
        ttk.Checkbutton(post_frame, text="åå¤„ç†æ»¤æ³¢", 
                       variable=self.enable_postprocessing).pack(side=tk.LEFT)
        
        ttk.Label(post_frame, text="æ–¹æ³•:").pack(side=tk.LEFT, padx=(10, 0))
        post_method_combo = ttk.Combobox(post_frame, 
                                        textvariable=self.postprocessing_method,
                                        values=["none", "majority", "median", "opening", "closing"], 
                                        width=10, state="readonly")
        post_method_combo.pack(side=tk.LEFT, padx=5)
        
        ttk.Label(post_frame, text="çª—å£å¤§å°:").pack(side=tk.LEFT, padx=(10, 0))
        ttk.Spinbox(post_frame, from_=3, to=9, increment=2,
                   textvariable=self.postprocessing_size, width=8).pack(side=tk.LEFT, padx=5)
        
        # åˆ†æé€‰é¡¹
        analysis_frame = ttk.Frame(advanced_frame)
        analysis_frame.pack(fill=tk.X, pady=2)
        
        ttk.Checkbutton(analysis_frame, text="ç‰¹å¾é‡è¦æ€§åˆ†æ", 
                       variable=self.enable_feature_importance).pack(side=tk.LEFT)
        
        ttk.Checkbutton(analysis_frame, text="ROCæ›²çº¿åˆ†æ", 
                       variable=self.enable_roc_analysis).pack(side=tk.LEFT, padx=(10, 0))
        
        ttk.Checkbutton(analysis_frame, text="ä¿å­˜æ¨¡å‹", 
                       variable=self.enable_model_saving).pack(side=tk.LEFT, padx=(10, 0))
        
        # 7. åˆ†ç±»å™¨é€‰æ‹©
        clf_frame = ttk.LabelFrame(scrollable_left, text="ğŸ¤– åˆ†ç±»å™¨é€‰æ‹©", padding="10")
        clf_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # å¿«æ·æŒ‰é’®
        btn_frame = ttk.Frame(clf_frame)
        btn_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Button(btn_frame, text="å…¨é€‰", command=self.select_all_classifiers, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="å…¨ä¸é€‰", command=self.deselect_all_classifiers, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="âœ“æ¨è", command=self.select_recommended, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="âš¡å¿«é€Ÿ", command=self.select_fast, 
                  width=10).pack(side=tk.LEFT, padx=2)
        
        # åˆ†ç±»å™¨å¤é€‰æ¡†
        all_classifiers = self.backend.get_all_classifiers()
        
        clf_canvas = tk.Canvas(clf_frame, height=150)
        clf_scrollbar = ttk.Scrollbar(clf_frame, orient="vertical", command=clf_canvas.yview)
        clf_scrollable = ttk.Frame(clf_canvas)
        
        clf_scrollable.bind("<Configure>", 
                           lambda e: clf_canvas.configure(scrollregion=clf_canvas.bbox("all")))
        
        clf_canvas.create_window((0, 0), window=clf_scrollable, anchor="nw")
        clf_canvas.configure(yscrollcommand=clf_scrollbar.set)
        
        # SVMç»„
        ttk.Label(clf_scrollable, text="SVM:", font=('', 9, 'bold')).grid(
            row=0, column=0, sticky=tk.W, pady=2
        )
        row = 1
        svm_codes = ["svm_linear", "linear_svc", "sgd_svm", "nystroem_svm", 
                     "rbf_sampler_svm", "svm_rbf"]
        for code in svm_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name, 
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        # æ ‘æ¨¡å‹
        ttk.Label(clf_scrollable, text="æ ‘æ¨¡å‹:", font=('', 9, 'bold')).grid(
            row=row, column=0, sticky=tk.W, pady=(5, 2)
        )
        row += 1
        tree_codes = ["rf", "et", "dt", "xgb", "lgb", "gb", "ada"]
        for code in tree_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name,
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        # å…¶ä»–
        ttk.Label(clf_scrollable, text="å…¶ä»–:", font=('', 9, 'bold')).grid(
            row=row, column=0, sticky=tk.W, pady=(5, 2)
        )
        row += 1
        other_codes = ["knn", "nb", "lr", "mlp"]
        for code in other_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name,
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        clf_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        clf_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # 8. æ§åˆ¶æŒ‰é’®
        control_frame = ttk.LabelFrame(scrollable_left, text="ğŸ® è¿è¡Œæ§åˆ¶", padding="10")
        control_frame.pack(fill=tk.X, padx=5, pady=5)
        
        btn_control_frame = ttk.Frame(control_frame)
        btn_control_frame.pack(fill=tk.X)
        
        self.start_btn = ttk.Button(btn_control_frame, text="â–¶ å¼€å§‹åˆ†ç±»", 
                                    command=self.start_classification, width=15)
        self.start_btn.pack(side=tk.LEFT, padx=5)
        
        self.stop_btn = ttk.Button(btn_control_frame, text="â¸ åœæ­¢", 
                                   command=self.stop_classification, 
                                   state=tk.DISABLED, width=15)
        self.stop_btn.pack(side=tk.LEFT, padx=5)
        
        ttk.Button(btn_control_frame, text="ğŸ’¾ ä¿å­˜é…ç½®", 
                  command=self.save_config, width=15).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(btn_control_frame, text="ğŸ“‚ åŠ è½½é…ç½®", 
                  command=self.load_config, width=15).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(btn_control_frame, text="ğŸ“ æ‰“å¼€ç»“æœ", 
                  command=self.open_result_dir, width=15).pack(side=tk.LEFT, padx=5)
        
        # è¿›åº¦æ¡
        ttk.Label(control_frame, text="è¿›åº¦:").pack(anchor=tk.W, pady=(10, 0))
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, 
                                           maximum=100)
        self.progress_bar.pack(fill=tk.X, pady=5)
        
        # çŠ¶æ€
        self.status_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(control_frame, textvariable=self.status_var, 
                 relief=tk.SUNKEN, anchor=tk.W).pack(fill=tk.X)
        
        # ===== å³ä¾§é¢æ¿ï¼šå›¾ä»¶æ˜¾ç¤º =====
        right_frame = ttk.Frame(main_paned, width=900)
        main_paned.add(right_frame, weight=2)
        
        # åˆ›å»ºNotebook
        self.notebook = ttk.Notebook(right_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        # æ ‡ç­¾é¡µ1ï¼šè¿è¡Œæ—¥å¿—
        log_tab = ttk.Frame(self.notebook)
        self.notebook.add(log_tab, text="ğŸ“ è¿è¡Œæ—¥å¿—")
        
        self.log_text = scrolledtext.ScrolledText(log_tab, wrap=tk.WORD, 
                                                  font=('Consolas', 9))
        self.log_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ ‡ç­¾é¡µ2ï¼šç²¾åº¦å¯¹æ¯”
        accuracy_tab = ttk.Frame(self.notebook)
        self.notebook.add(accuracy_tab, text="ğŸ“Š ç²¾åº¦å¯¹æ¯”")
        
        self.accuracy_fig = Figure(figsize=(10, 6), dpi=100)
        self.accuracy_canvas = FigureCanvasTkAgg(self.accuracy_fig, accuracy_tab)
        self.accuracy_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_acc = ttk.Frame(accuracy_tab)
        toolbar_acc.pack(fill=tk.X)
        NavigationToolbar2Tk(self.accuracy_canvas, toolbar_acc)
        
        # æ ‡ç­¾é¡µ3ï¼šæ··æ·†çŸ©é˜µ
        cm_tab = ttk.Frame(self.notebook)
        self.notebook.add(cm_tab, text="ğŸ”¥ æ··æ·†çŸ©é˜µ")
        
        self.cm_fig = Figure(figsize=(8, 6), dpi=100)
        self.cm_canvas = FigureCanvasTkAgg(self.cm_fig, cm_tab)
        self.cm_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_cm = ttk.Frame(cm_tab)
        toolbar_cm.pack(fill=tk.X)
        NavigationToolbar2Tk(self.cm_canvas, toolbar_cm)
        
        # æ ‡ç­¾é¡µ4ï¼šæ—¶é—´å¯¹æ¯”
        time_tab = ttk.Frame(self.notebook)
        self.notebook.add(time_tab, text="â±ï¸ æ—¶é—´å¯¹æ¯”")
        
        self.time_fig = Figure(figsize=(10, 6), dpi=100)
        self.time_canvas = FigureCanvasTkAgg(self.time_fig, time_tab)
        self.time_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_time = ttk.Frame(time_tab)
        toolbar_time.pack(fill=tk.X)
        NavigationToolbar2Tk(self.time_canvas, toolbar_time)
        
        # æ ‡ç­¾é¡µ5ï¼šåˆ†ç±»ç»“æœé¢„è§ˆ
        result_tab = ttk.Frame(self.notebook)
        self.notebook.add(result_tab, text="ğŸ—ºï¸ ç»“æœé¢„è§ˆ")
        
        self.result_fig = Figure(figsize=(10, 6), dpi=100)
        self.result_canvas = FigureCanvasTkAgg(self.result_fig, result_tab)
        self.result_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_result = ttk.Frame(result_tab)
        toolbar_result.pack(fill=tk.X)
        NavigationToolbar2Tk(self.result_canvas, toolbar_result)
        
        # æ ‡ç­¾é¡µ6ï¼šç‰¹å¾é‡è¦æ€§
        feature_tab = ttk.Frame(self.notebook)
        self.notebook.add(feature_tab, text="ğŸ“ˆ ç‰¹å¾é‡è¦æ€§")
        
        self.feature_fig = Figure(figsize=(10, 6), dpi=100)
        self.feature_canvas = FigureCanvasTkAgg(self.feature_fig, feature_tab)
        self.feature_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_feature = ttk.Frame(feature_tab)
        toolbar_feature.pack(fill=tk.X)
        NavigationToolbar2Tk(self.feature_canvas, toolbar_feature)
        
        # æ ‡ç­¾é¡µ7ï¼šROCæ›²çº¿
        roc_tab = ttk.Frame(self.notebook)
        self.notebook.add(roc_tab, text="ğŸ“‰ ROCæ›²çº¿")
        
        self.roc_fig = Figure(figsize=(10, 6), dpi=100)
        self.roc_canvas = FigureCanvasTkAgg(self.roc_fig, roc_tab)
        self.roc_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_roc = ttk.Frame(roc_tab)
        toolbar_roc.pack(fill=tk.X)
        NavigationToolbar2Tk(self.roc_canvas, toolbar_roc)
    
    # ===== è¾…åŠ©å‡½æ•° =====
    def toggle_sampling(self):
        if self.enable_sampling.get():
            self.max_samples_spinbox.config(state=tk.NORMAL)
        else:
            self.max_samples_spinbox.config(state=tk.DISABLED)
    
    def refresh_fields(self):
        train_shp = self.train_shp_path.get()
        if not train_shp or not os.path.exists(train_shp):
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è®­ç»ƒæ ·æœ¬æ–‡ä»¶ï¼")
            return
        
        fields = self.backend.get_shapefile_fields(train_shp)
        if fields:
            fields = [f for f in fields if f.lower() != 'geometry']
            
            self.class_attr_combo['values'] = fields
            self.name_attr_combo['values'] = fields
            
            if 'class' in fields:
                self.class_attr.set('class')
            elif 'Class' in fields:
                self.class_attr.set('Class')
            elif fields:
                self.class_attr.set(fields[0])
            
            if 'name' in fields:
                self.name_attr.set('name')
            elif 'Name' in fields:
                self.name_attr.set('Name')
            elif len(fields) > 1:
                self.name_attr.set(fields[1])
            elif fields:
                self.name_attr.set(fields[0])
            
            messagebox.showinfo("æˆåŠŸ", f"å·²åŠ è½½ {len(fields)} ä¸ªå­—æ®µ")
        else:
            messagebox.showerror("é”™è¯¯", "æ— æ³•è¯»å–å­—æ®µåˆ—è¡¨ï¼")
    
    def browse_image(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©å½±åƒæ–‡ä»¶",
            filetypes=[("GeoTIFF", "*.tif *.tiff"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.image_path.set(filename)
            self.status_var.set(f"å·²é€‰æ‹©å½±åƒ: {Path(filename).name}")
    
    def browse_train_shp(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©è®­ç»ƒæ ·æœ¬",
            filetypes=[("Shapefile", "*.shp"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.train_shp_path.set(filename)
            self.refresh_fields()
    
    def browse_val_shp(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©éªŒè¯æ ·æœ¬",
            filetypes=[("Shapefile", "*.shp"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.val_shp_path.set(filename)
    
    def browse_output(self):
        dirname = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
        if dirname:
            self.output_dir.set(dirname)
    
    def select_all_classifiers(self):
        for var in self.classifier_vars.values():
            var.set(True)
    
    def deselect_all_classifiers(self):
        for var in self.classifier_vars.values():
            var.set(False)
    
    def select_recommended(self):
        recommended = ["rf", "xgb", "et", "lgb", "linear_svc", "nystroem_svm"]
        for code, var in self.classifier_vars.items():
            var.set(code in recommended)
    
    def select_fast(self):
        fast = ["rf", "et", "dt", "xgb", "lgb", "nb", "lr", "sgd_svm", "linear_svc"]
        for code, var in self.classifier_vars.items():
            var.set(code in fast)
    
    def save_config(self):
        """ä¿å­˜å½“å‰é…ç½®åˆ°JSONæ–‡ä»¶"""
        config = {
            'image_path': self.image_path.get(),
            'train_shp_path': self.train_shp_path.get(),
            'val_shp_path': self.val_shp_path.get(),
            'output_dir': self.output_dir.get(),
            'class_attr': self.class_attr.get(),
            'name_attr': self.name_attr.get(),
            'background_value': self.background_value.get(),
            'ignore_background': self.ignore_background.get(),
            'n_estimators': self.n_estimators.get(),
            'block_size': self.block_size.get(),
            'enable_sampling': self.enable_sampling.get(),
            'max_samples': self.max_samples.get(),
            'fast_mode': self.fast_mode.get(),
            'enable_hyperparameter_optimization': self.enable_hyperparameter_optimization.get(),
            'hyperparameter_optimization_method': self.hyperparameter_optimization_method.get(),
            'hyperparameter_iterations': self.hyperparameter_iterations.get(),
            'enable_postprocessing': self.enable_postprocessing.get(),
            'postprocessing_method': self.postprocessing_method.get(),
            'postprocessing_size': self.postprocessing_size.get(),
            'enable_feature_importance': self.enable_feature_importance.get(),
            'enable_roc_analysis': self.enable_roc_analysis.get(),
            'enable_model_saving': self.enable_model_saving.get(),
            'selected_classifiers': {code: var.get() for code, var in self.classifier_vars.items()}
        }
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜é…ç½®",
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")],
            defaultextension=".json"
        )
        
        if filename:
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                messagebox.showinfo("æˆåŠŸ", f"é…ç½®å·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
    
    def load_config(self):
        """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®"""
        filename = filedialog.askopenfilename(
            title="åŠ è½½é…ç½®",
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if filename:
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                # æ¢å¤é…ç½®
                self.image_path.set(config.get('image_path', ''))
                self.train_shp_path.set(config.get('train_shp_path', ''))
                self.val_shp_path.set(config.get('val_shp_path', ''))
                self.output_dir.set(config.get('output_dir', './results_gui'))
                self.class_attr.set(config.get('class_attr', ''))
                self.name_attr.set(config.get('name_attr', ''))
                self.background_value.set(config.get('background_value', 0))
                self.ignore_background.set(config.get('ignore_background', True))
                self.n_estimators.set(config.get('n_estimators', 100))
                self.block_size.set(config.get('block_size', 512))
                self.enable_sampling.set(config.get('enable_sampling', True))
                self.max_samples.set(config.get('max_samples', 50000))
                self.fast_mode.set(config.get('fast_mode', False))
                
                # æ–°åŠŸèƒ½é…ç½®
                self.enable_hyperparameter_optimization.set(config.get('enable_hyperparameter_optimization', False))
                self.hyperparameter_optimization_method.set(config.get('hyperparameter_optimization_method', 'random'))
                self.hyperparameter_iterations.set(config.get('hyperparameter_iterations', 20))
                self.enable_postprocessing.set(config.get('enable_postprocessing', True))
                self.postprocessing_method.set(config.get('postprocessing_method', 'majority'))
                self.postprocessing_size.set(config.get('postprocessing_size', 3))
                self.enable_feature_importance.set(config.get('enable_feature_importance', True))
                self.enable_roc_analysis.set(config.get('enable_roc_analysis', True))
                self.enable_model_saving.set(config.get('enable_model_saving', True))
                
                # åˆ†ç±»å™¨é€‰æ‹©
                selected_classifiers = config.get('selected_classifiers', {})
                for code, var in self.classifier_vars.items():
                    var.set(selected_classifiers.get(code, False))
                
                messagebox.showinfo("æˆåŠŸ", f"é…ç½®å·²ä» {filename} åŠ è½½")
                
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
    
    def log(self, message):
        self.log_queue.put(message)
    
    def update_log(self):
        try:
            while True:
                message = self.log_queue.get_nowait()
                self.log_text.insert(tk.END, message + "\n")
                self.log_text.see(tk.END)
        except queue.Empty:
            pass
        self.root.after(100, self.update_log)
    
    def update_accuracy_plot(self):
        """æ›´æ–°ç²¾åº¦å¯¹æ¯”å›¾"""
        if not self.comparison_results:
            return
        
        df = pd.DataFrame(self.comparison_results)
        
        self.accuracy_fig.clear()
        
        # åˆ›å»ºå­å›¾
        ax1 = self.accuracy_fig.add_subplot(121)
        ax2 = self.accuracy_fig.add_subplot(122)
        
        # ç²¾åº¦å¯¹æ¯”
        x = np.arange(len(df))
        width = 0.35
        
        ax1.bar(x - width/2, df['è®­ç»ƒé›†ç²¾åº¦'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax1.bar(x + width/2, df['éªŒè¯é›†ç²¾åº¦'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax1.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax1.set_ylabel('ç²¾åº¦', fontsize=11)
        ax1.set_title('æ€»ä½“ç²¾åº¦å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        ax1.set_ylim([0, 1.05])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (train_acc, val_acc) in enumerate(zip(df['è®­ç»ƒé›†ç²¾åº¦'], df['éªŒè¯é›†ç²¾åº¦'])):
            ax1.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
            ax1.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
        
        # Kappaå¯¹æ¯”
        ax2.bar(x - width/2, df['è®­ç»ƒé›†Kappa'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax2.bar(x + width/2, df['éªŒè¯é›†Kappa'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax2.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax2.set_ylabel('Kappaç³»æ•°', fontsize=11)
        ax2.set_title('Kappaç³»æ•°å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim([0, 1.05])
        
        self.accuracy_fig.tight_layout()
        self.accuracy_canvas.draw()
    
    def update_confusion_matrix(self, y_true, y_pred, class_names):
        """æ›´æ–°æ··æ·†çŸ©é˜µæ˜¾ç¤º"""
        self.cm_fig.clear()
        ax = self.cm_fig.add_subplot(111)
        
        cm = confusion_matrix(y_true, y_pred)
        
        # ç»˜åˆ¶çƒ­å›¾
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=class_names, yticklabels=class_names,
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)
        ax.set_title('æœ€ä½³åˆ†ç±»å™¨æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        
        self.cm_fig.tight_layout()
        self.cm_canvas.draw()
    
    def update_time_plot(self):
        """æ›´æ–°æ—¶é—´å¯¹æ¯”å›¾"""
        if not self.comparison_results:
            return
        
        df = pd.DataFrame(self.comparison_results)
        
        self.time_fig.clear()
        ax = self.time_fig.add_subplot(111)
        
        x = np.arange(len(df))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, df['è®­ç»ƒæ—¶é—´(ç§’)'], width, label='è®­ç»ƒæ—¶é—´', 
                      alpha=0.8, color='lightgreen')
        bars2 = ax.bar(x + width/2, df['é¢„æµ‹æ—¶é—´(ç§’)'], width, label='é¢„æµ‹æ—¶é—´', 
                      alpha=0.8, color='lightcoral')
        
        ax.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=11)
        ax.set_title('è®­ç»ƒå’Œé¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}s', ha='center', va='bottom', fontsize=8)
        
        self.time_fig.tight_layout()
        self.time_canvas.draw()
    
    def update_feature_importance_plot(self, importance_data, feature_names, clf_name):
        """æ›´æ–°ç‰¹å¾é‡è¦æ€§å›¾"""
        if not importance_data:
            return
        
        self.feature_fig.clear()
        ax = self.feature_fig.add_subplot(111)
        
        indices = importance_data['indices']
        importances = importance_data['importances']
        
        # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
        valid_indices = indices[indices < len(importances)]
        sorted_importances = importances[valid_indices]
        
        features = [feature_names[i] for i in valid_indices if i < len(feature_names)]
        
        y_pos = np.arange(len(features))
        
        ax.barh(y_pos, sorted_importances, align='center', alpha=0.7, color='steelblue')
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(features)
        ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
        ax.set_title(f'{clf_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ')
        ax.grid(True, alpha=0.3, axis='x')
        
        self.feature_fig.tight_layout()
        self.feature_canvas.draw()
    
    def update_roc_plot(self, roc_data, clf_name):
        """æ›´æ–°ROCæ›²çº¿å›¾"""
        if not roc_data:
            # ç»˜åˆ¶ç©ºçš„ROCæ›²çº¿
            self.roc_fig.clear()
            ax = self.roc_fig.add_subplot(111)
            ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºåˆ†ç±»å™¨')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡')
            ax.set_ylabel('çœŸæ­£ç‡')
            ax.set_title(f'{clf_name} - ROCæ›²çº¿')
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            self.roc_fig.tight_layout()
            self.roc_canvas.draw()
            return
        
        try:
            self.roc_fig.clear()
            ax = self.roc_fig.add_subplot(111)
            
            # ä»ä¿å­˜çš„æ•°æ®ä¸­ç»˜åˆ¶ROCæ›²çº¿
            fpr = roc_data.get('fpr', {})
            tpr = roc_data.get('tpr', {})
            auc_scores = roc_data.get('auc', {})
            
            if isinstance(fpr, dict) and isinstance(tpr, dict):
                # å¤šåˆ†ç±»æƒ…å†µ
                colors = plt.cm.Set1(np.linspace(0, 1, len(fpr)))
                
                for i, (key, fpr_val) in enumerate(fpr.items()):
                    if key == 'macro':
                        # å®å¹³å‡ä½¿ç”¨ç‰¹æ®Šæ ·å¼
                        ax.plot(fpr_val, tpr[key], color='navy', linestyle=':', linewidth=4,
                            label=f'å®å¹³å‡ (AUC = {auc_scores.get(key, 0):.2f})')
                    elif key in auc_scores:
                        # å•ä¸ªç±»åˆ«
                        class_name = f'ç±»åˆ«_{key}' if isinstance(key, int) else str(key)
                        ax.plot(fpr_val, tpr[key], color=colors[i % len(colors)], lw=2,
                            label=f'{class_name} (AUC = {auc_scores[key]:.2f})')
                
                # æ·»åŠ éšæœºåˆ†ç±»å™¨çº¿
                ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨', alpha=0.8)
                
            else:
                # äºŒåˆ†ç±»æƒ…å†µ
                ax.plot(fpr, tpr, color='darkorange', lw=2,
                    label=f'ROCæ›²çº¿ (AUC = {auc_scores:.2f})')
                ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨')
            
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡ (False Positive Rate)', fontsize=12)
            ax.set_ylabel('çœŸæ­£ç‡ (True Positive Rate)', fontsize=12)
            ax.set_title(f'{clf_name} - ROCæ›²çº¿', fontsize=14, fontweight='bold')
            ax.legend(loc="lower right", fontsize=10)
            ax.grid(True, alpha=0.3)
            
            self.roc_fig.tight_layout()
            self.roc_canvas.draw()
            
        except Exception as e:
            print(f"æ›´æ–°ROCæ›²çº¿å¤±è´¥: {e}")
            # ç»˜åˆ¶ç©ºçš„ROCæ›²çº¿ä½œä¸ºå¤‡é€‰
            self.roc_fig.clear()
            ax = self.roc_fig.add_subplot(111)
            ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºåˆ†ç±»å™¨')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡')
            ax.set_ylabel('çœŸæ­£ç‡')
            ax.set_title(f'{clf_name} - ROCæ›²çº¿')
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            self.roc_fig.tight_layout()
            self.roc_canvas.draw()
    
    def update_result_preview(self, image_path, classified_path, class_names, class_colors):
        """æ›´æ–°åˆ†ç±»ç»“æœé¢„è§ˆ"""
        try:
            self.result_fig.clear()
            
            # è¯»å–å½±åƒå’Œåˆ†ç±»ç»“æœ
            img = rxr.open_rasterio(image_path, masked=True)
            classified = rxr.open_rasterio(classified_path)
            
            # åˆ›å»ºå­å›¾
            ax1 = self.result_fig.add_subplot(121)
            ax2 = self.result_fig.add_subplot(122)
            
            # æ˜¾ç¤ºåŸå§‹å½±åƒ
            if img.shape[0] >= 3:
                rgb_data = np.moveaxis(img.values[:3], 0, -1)
                p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))
                rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)
                ax1.imshow(rgb_display)
            else:
                ax1.imshow(img.values[0], cmap='gray')
            
            ax1.set_title('åŸå§‹é¥æ„Ÿå½±åƒ', fontsize=12, fontweight='bold')
            ax1.axis('off')
            
            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            classified_data = classified.values.squeeze()
            
            # è·å–ç±»åˆ«
            classes = np.unique(classified_data)
            classes = classes[classes > 0]
            
            # åˆ›å»ºé¢œè‰²æ˜ å°„
            colors = [class_colors.get(c, 'black') for c in classes]
            labels = [class_names.get(c, f'ç±»åˆ«_{c}') for c in classes]
            
            cmap = mcolors.ListedColormap(colors)
            bounds = np.append(classes, classes[-1] + 1) - 0.5
            norm = mcolors.BoundaryNorm(bounds, cmap.N)
            
            # èƒŒæ™¯è®¾ä¸ºé€æ˜
            display_data = classified_data.astype(float)
            display_data[classified_data == 0] = np.nan
            
            im = ax2.imshow(display_data, cmap=cmap, norm=norm)
            ax2.set_title('åˆ†ç±»ç»“æœï¼ˆæœ€ä½³åˆ†ç±»å™¨ï¼‰', fontsize=12, fontweight='bold')
            ax2.axis('off')
            
            # æ·»åŠ å›¾ä¾‹
            from matplotlib.patches import Patch
            legend_elements = [Patch(facecolor=color, label=label) 
                              for color, label in zip(colors, labels)]
            ax2.legend(handles=legend_elements, loc='upper left', 
                      bbox_to_anchor=(1.05, 1), fontsize=9)
            
            self.result_fig.tight_layout()
            self.result_canvas.draw()
            
        except Exception as e:
            self.log(f"é¢„è§ˆæ˜¾ç¤ºé”™è¯¯: {str(e)}")
    
    def export_to_excel(self, out_dir):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        if not HAS_OPENPYXL:
            self.log("âš ï¸  æœªå®‰è£…openpyxlï¼Œæ— æ³•å¯¼å‡ºExcel")
            return
        
        if not self.comparison_results:
            return
        
        try:
            df = pd.DataFrame(self.comparison_results)
            
            excel_path = out_dir / "classification_comparison.xlsx"
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # ä¸»ç»“æœè¡¨
                df.to_excel(writer, sheet_name='åˆ†ç±»å™¨å¯¹æ¯”', index=False)
                
                # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨
                workbook = writer.book
                worksheet = writer.sheets['åˆ†ç±»å™¨å¯¹æ¯”']
                
                # è®¾ç½®åˆ—å®½
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
                
                # æ·»åŠ ç»Ÿè®¡æ‘˜è¦è¡¨
                summary_data = {
                    'æŒ‡æ ‡': ['æœ€é«˜ç²¾åº¦', 'æœ€é«˜Kappa', 'æœ€å¿«è®­ç»ƒ', 'æœ€å¿«é¢„æµ‹'],
                    'åˆ†ç±»å™¨': [
                        df.loc[df['éªŒè¯é›†ç²¾åº¦'].idxmax(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['éªŒè¯é›†Kappa'].idxmax(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['è®­ç»ƒæ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['é¢„æµ‹æ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°']
                    ],
                    'æ•°å€¼': [
                        f"{df['éªŒè¯é›†ç²¾åº¦'].max():.4f}",
                        f"{df['éªŒè¯é›†Kappa'].max():.4f}",
                        f"{df['è®­ç»ƒæ—¶é—´(ç§’)'].min():.2f}ç§’",
                        f"{df['é¢„æµ‹æ—¶é—´(ç§’)'].min():.2f}ç§’"
                    ]
                }
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='æ€§èƒ½æ‘˜è¦', index=False)
            
            self.log(f"âœ“ ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_path}")
            
        except Exception as e:
            self.log(f"Excelå¯¼å‡ºå¤±è´¥: {str(e)}")
    
    def start_classification(self):
        """å¼€å§‹åˆ†ç±»"""
        # æ£€æŸ¥è¾“å…¥
        if not self.image_path.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼")
            return
        
        if not self.train_shp_path.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼")
            return
        
        if not self.class_attr.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©ç±»åˆ«ç¼–å·å­—æ®µï¼")
            return
        
        selected_classifiers = [code for code, var in self.classifier_vars.items() if var.get()]
        if not selected_classifiers:
            messagebox.showerror("é”™è¯¯", "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼")
            return
        
        # æ€§èƒ½è­¦å‘Š
        all_classifiers = self.backend.get_all_classifiers()
        very_slow_clfs = []
        
        for code in selected_classifiers:
            if code in all_classifiers:
                speed_tag = all_classifiers[code][5]
                name = all_classifiers[code][1]
                if speed_tag == "very_slow":
                    very_slow_clfs.append(name)
        
        if very_slow_clfs:
            warning_msg = "âš ï¸ ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹éå¸¸æ…¢:\n"
            for clf in very_slow_clfs:
                warning_msg += f"  â€¢ {clf}\n"
            warning_msg += "\næ˜¯å¦ç»§ç»­?"
            
            if not messagebox.askyesno("æ€§èƒ½è­¦å‘Š", warning_msg, icon='warning'):
                return
        
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        self.is_running = True
        
        # æ¸…ç©º
        self.log_text.delete(1.0, tk.END)
        self.comparison_results = []
        
        self.log("="*80)
        self.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v5.1 - ä¸“ä¸šç‰ˆ")
        self.log("="*80)
        self.log(f"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª")
        self.log(f"èƒŒæ™¯å€¼: {self.background_value.get()}")
        self.log("")
        
        # åˆ‡æ¢åˆ°æ—¥å¿—æ ‡ç­¾é¡µ
        self.notebook.select(0)
        
        thread = threading.Thread(target=self.run_classification, args=(selected_classifiers,))
        thread.daemon = True
        thread.start()
    
    def stop_classification(self):
        self.is_running = False
        self.log("\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...")
        self.status_var.set("å·²åœæ­¢")
    
    def run_classification(self, selected_classifiers):
        """æ‰§è¡Œåˆ†ç±»ï¼ˆä¸»æµç¨‹ï¼‰"""
        try:
            out_dir = Path(self.output_dir.get())
            out_dir.mkdir(exist_ok=True)
            
            # ä¿å­˜å½“å‰é…ç½®
            self.save_config_to_file(out_dir / "classification_config.json")
            
            # è¯»å–å½±åƒ
            self.log(f"ğŸ“ è¯»å–å½±åƒ...")
            self.status_var.set("è¯»å–å½±åƒ...")
            img = rxr.open_rasterio(self.image_path.get(), masked=True)
            n_pixels = img.shape[1] * img.shape[2]
            self.log(f"   å°ºå¯¸: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ")
            
            # è·å–åƒå…ƒå¤§å°
            transform = img.rio.transform()
            pixel_size_x = transform[0]  # Xæ–¹å‘åˆ†è¾¨ç‡
            pixel_size_y = abs(transform[4])  # Yæ–¹å‘åˆ†è¾¨ç‡
            self.log(f"   åˆ†è¾¨ç‡: {pixel_size_x:.2f} Ã— {pixel_size_y:.2f} ç±³")
            
            # è·å–æ³¢æ®µåç§°
            band_names = [f"æ³¢æ®µ_{i+1}" for i in range(img.shape[0])]
            if hasattr(img, 'long_name') and img.long_name:
                band_names = img.long_name
            elif hasattr(img, 'band') and img.band.values is not None:
                band_names = [f"æ³¢æ®µ_{b}" for b in img.band.values]
            
            self.log(f"   æ³¢æ®µæ•°: {len(band_names)}")
            
            if not self.is_running:
                return
            
            # è¯»å–ç±»åˆ«ä¿¡æ¯
            self.log(f"\nğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...")
            class_names, class_colors, _ = self.backend.get_class_info_from_shp(
                self.train_shp_path.get(), 
                self.class_attr.get(), 
                self.name_attr.get()
            )
            self.class_names_dict = class_names
            self.class_colors_dict = class_colors
            self.log(f"   ç±»åˆ«: {list(class_names.values())}")
            
            # æå–è®­ç»ƒæ ·æœ¬
            self.log(f"\nğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...")
            self.status_var.set("å¤„ç†è®­ç»ƒæ ·æœ¬...")
            train_mask = self.backend.rasterize_samples(
                self.train_shp_path.get(), img, self.class_attr.get()
            )
            
            max_samples = self.max_samples.get() if self.enable_sampling.get() else None
            
            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(
                img, train_mask, 
                ignore_background=self.ignore_background.get(),
                background_value=self.background_value.get(),
                max_samples=max_samples
            )
            
            self.log(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}")
            if n_nan > 0:
                self.log(f"   â””â”€ ç§»é™¤NaN: {n_nan:,}")
            if n_sampled > 0:
                self.log(f"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}")
            
            if not self.is_running:
                return
            
            # æå–éªŒè¯æ ·æœ¬
            val_exists = os.path.exists(self.val_shp_path.get())
            X_val, yv_true = None, None
            valid_val = None
            
            if val_exists:
                self.log(f"\nâœ… å¤„ç†éªŒè¯æ ·æœ¬...")
                val_mask = self.backend.rasterize_samples(
                    self.val_shp_path.get(), img, self.class_attr.get()
                )
                
                if self.ignore_background.get():
                    background_mask = self.backend.get_background_mask(
                        img, self.background_value.get()
                    )
                    valid_val = (val_mask > 0) & (~background_mask)
                else:
                    valid_val = val_mask > 0
                
                # æå–éªŒè¯æ ·æœ¬ç‰¹å¾
                data = np.moveaxis(img.values, 0, -1)
                X_val = data[valid_val]
                yv_true = val_mask[valid_val]
                
                # æ¸…ç†NaNå’ŒInf
                nan_mask = np.isnan(X_val).any(axis=1)
                inf_mask = np.isinf(X_val).any(axis=1)
                bad_mask = nan_mask | inf_mask
                X_val = X_val[~bad_mask]
                yv_true = yv_true[~bad_mask]
                
                self.log(f"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}")
            
            # åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°
            all_classifiers = self.backend.get_all_classifiers(
                self.n_estimators.get(), 
                fast_mode=self.fast_mode.get(),
                n_train_samples=len(y_train)
            )
            
            comparison_results = []
            total_start_time = time.time()
            best_accuracy = 0
            best_clf_code = None
            
            for i, clf_code in enumerate(selected_classifiers):
                if not self.is_running:
                    break
                
                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]
                
                self.log(f"\n{'='*80}")
                self.log(f"[{i+1}/{len(selected_classifiers)}] {clf_name}")
                self.log(f"{'='*80}")
                
                self.status_var.set(f"[{i+1}/{len(selected_classifiers)}] è®­ç»ƒ {clf_name}...")
                
                clf_dir = out_dir / clf_code
                clf_dir.mkdir(exist_ok=True)
                
                try:
                    # æ•°æ®é¢„å¤„ç†
                    label_encoder = None
                    scaler = None
                    X_train_use = X_train.copy()
                    y_train_use = y_train.copy()
                    
                    if needs_encoding:
                        self.log("   ğŸ”„ æ ‡ç­¾ç¼–ç ...")
                        label_encoder = LabelEncoder()
                        y_train_use = label_encoder.fit_transform(y_train)
                    
                    if needs_scaling:
                        self.log("   ğŸ“ ç‰¹å¾ç¼©æ”¾...")
                        scaler = StandardScaler()
                        X_train_use = scaler.fit_transform(X_train_use)
                    
                    # è¶…å‚æ•°ä¼˜åŒ–
                    best_params = {}
                    optimization_score = 0
                    
                    if self.enable_hyperparameter_optimization.get():
                        self.log("   ğŸ¯ è¶…å‚æ•°ä¼˜åŒ–ä¸­...")
                        opt_start = time.time()
                        
                        clf_optimized, best_params, optimization_score = self.backend.optimize_hyperparameters(
                            clf, clf_code, X_train_use, y_train_use,
                            n_iter=self.hyperparameter_iterations.get()
                        )
                        
                        if clf_optimized is not clf:
                            clf = clf_optimized
                            self.log(f"   âœ“ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ: {time.time() - opt_start:.2f}ç§’")
                            self.log(f"   ğŸ“Š ä¼˜åŒ–åå¾—åˆ†: {optimization_score:.4f}")
                            if best_params:
                                self.log(f"   âš™ï¸  æœ€ä½³å‚æ•°: {best_params}")
                        else:
                            self.log("   âš ï¸  è¶…å‚æ•°ä¼˜åŒ–æœªæ”¹å–„æ€§èƒ½ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                    
                    # è®­ç»ƒ
                    self.log("   ğŸ”¨ è®­ç»ƒä¸­...")
                    train_start = time.time()
                    clf.fit(X_train_use, y_train_use)
                    train_time = time.time() - train_start
                    self.log(f"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’")
                    
                    # ä¿å­˜æ¨¡å‹
                    if self.enable_model_saving.get():
                        model_path = clf_dir / f"{clf_code}_model.pkl"
                        if self.backend.save_model(clf, model_path):
                            self.log(f"   ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path.name}")
                    
                    # è®­ç»ƒé›†ç²¾åº¦
                    y_train_pred = clf.predict(X_train_use)
                    
                    if label_encoder is not None:
                        y_train_pred = label_encoder.inverse_transform(y_train_pred)
                    
                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)
                    self.log(f"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}")
                    
                    # ä¿å­˜è®­ç»ƒé›†æ··æ·†çŸ©é˜µå’ŒæŠ¥å‘Š
                    if HAS_OPENPYXL:
                        self.log("   ğŸ’¾ ä¿å­˜è®­ç»ƒé›†ç»“æœ...")
                        train_classes = sorted(np.unique(y_train))
                        train_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in train_classes]
                        
                        excel_path, img_path = self.backend.save_confusion_matrix(
                            y_train, y_train_pred, train_class_names,
                            clf_dir / f"{clf_code}_train",
                            f"{clf_name} (è®­ç»ƒé›†)"
                        )
                        if excel_path:
                            self.log(f"      âœ“ æ··æ·†çŸ©é˜µ: {excel_path.name}")
                            self.log(f"      âœ“ å›¾ç‰‡: {img_path.name}")
                        
                        excel_path, txt_path = self.backend.save_classification_report(
                            y_train, y_train_pred, train_class_names,
                            clf_dir / f"{clf_code}_train"
                        )
                        if excel_path:
                            self.log(f"      âœ“ åˆ†ç±»æŠ¥å‘Š: {excel_path.name}")
                    
                    # ç‰¹å¾é‡è¦æ€§åˆ†æ
                    if self.enable_feature_importance.get() and X_val is not None:
                        self.log("   ğŸ“Š åˆ†æç‰¹å¾é‡è¦æ€§...")
                        importance_data = self.backend.analyze_feature_importance(
                            clf, band_names, X_val, yv_true
                        )
                        
                        if importance_data:
                            importance_path = clf_dir / f"{clf_code}_feature_importance.png"
                            saved_path = self.backend.plot_feature_importance(
                                importance_data, band_names, importance_path, clf_name
                            )
                            if saved_path:
                                self.log(f"      âœ“ ç‰¹å¾é‡è¦æ€§å›¾: {saved_path.name}")
                                
                                # æ›´æ–°ç‰¹å¾é‡è¦æ€§æ˜¾ç¤º
                                self.root.after(0, lambda: self.update_feature_importance_plot(
                                    importance_data, band_names, clf_name
                                ))
                            else:
                                self.log("      âš ï¸  ç‰¹å¾é‡è¦æ€§å›¾ç”Ÿæˆå¤±è´¥")
                        else:
                            self.log("      âš ï¸  ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥")
                    
                    # ROCæ›²çº¿åˆ†æ
                    if self.enable_roc_analysis.get() and X_val is not None:
                        self.log("   ğŸ“‰ ç»˜åˆ¶ROCæ›²çº¿...")
                        val_classes = sorted(np.unique(yv_true))
                        val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                        
                        roc_path = clf_dir / f"{clf_code}_roc_curve.png"
                        roc_path, auc_data, roc_data = self.backend.plot_roc_curves(
                            clf, X_val, yv_true, class_names, roc_path, clf_name
                        )
                        
                        if roc_path:
                            self.log(f"      âœ“ ROCæ›²çº¿: {roc_path.name}")
                            if auc_data:
                                self.log(f"      âœ“ å¹³å‡AUC: {auc_data['macro_auc']:.4f}")
                            
                            # æ›´æ–°ROCæ›²çº¿æ˜¾ç¤º
                            self.root.after(0, lambda: self.update_roc_plot(roc_data, clf_name))
                        else:
                            self.log("      âš ï¸ ROCæ›²çº¿ç»˜åˆ¶å¤±è´¥")
                    
                    if not self.is_running:
                        break
                    
                    # é¢„æµ‹æ•´å¹…å½±åƒ
                    self.log("   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...")
                    self.status_var.set(f"[{i+1}/{len(selected_classifiers)}] é¢„æµ‹ {clf_name}...")
                    
                    pred_start = time.time()
                    classified_path = clf_dir / f"classified_{clf_code}.tif"
                    
                    def update_progress(progress):
                        self.progress_var.set(progress)
                    
                    # åå¤„ç†è®¾ç½®
                    postprocessing = self.postprocessing_method.get() if self.enable_postprocessing.get() else 'none'
                    
                    # ä¼ é€’è¿è¡ŒçŠ¶æ€ç»™åç«¯
                    self.backend.is_running = self.is_running
                    
                    result_path = self.backend.predict_by_block(
                        clf, img, classified_path, 
                        block_size=self.block_size.get(),
                        ignore_background=self.ignore_background.get(),
                        background_value=self.background_value.get(),
                        progress_callback=update_progress,
                        label_encoder=label_encoder,
                        scaler=scaler,
                        postprocessing=postprocessing
                    )
                    
                    if result_path and os.path.exists(result_path):
                        pred_time = time.time() - pred_start
                        self.log(f"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’")
                        
                        # è¯»å–åˆ†ç±»ç»“æœè¿›è¡Œé¢ç§¯ç»Ÿè®¡
                        self.log("   ğŸ“Š è®¡ç®—é¢ç§¯ç»Ÿè®¡...")
                        with rxr.open_rasterio(classified_path) as pred_img:
                            pred_arr = pred_img.values.squeeze()
                        
                        # è®¡ç®—é¢ç§¯ç»Ÿè®¡
                        area_stats = self.backend.calculate_area_statistics(
                            pred_arr, pixel_size_x, pixel_size_y,
                            class_names, self.background_value.get()
                        )
                        
                        # ä¿å­˜é¢ç§¯ç»Ÿè®¡
                        if HAS_OPENPYXL:
                            area_excel_path = clf_dir / f"{clf_code}_area_statistics.xlsx"
                            area_stats.to_excel(area_excel_path, index=False, engine='openpyxl')
                            self.log(f"      âœ“ é¢ç§¯ç»Ÿè®¡: {area_excel_path.name}")
                        
                        # æ˜¾ç¤ºé¢ç§¯ç»Ÿè®¡æ‘˜è¦
                        self.log("   é¢ç§¯ç»Ÿè®¡æ‘˜è¦:")
                        for _, row in area_stats.iterrows():
                            if row['ç±»åˆ«åç§°'] == 'æ€»è®¡':
                                self.log(f"      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                                self.log(f"      {row['ç±»åˆ«åç§°']}: {row['é¢ç§¯(kmÂ²)']:.2f} kmÂ²")
                            else:
                                self.log(f"      {row['ç±»åˆ«åç§°']}: {row['é¢ç§¯(kmÂ²)']:.2f} kmÂ² ({row['ç™¾åˆ†æ¯”(%)']:.2f}%)")
                        
                        # éªŒè¯é›†ç²¾åº¦
                        val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan}
                        yv_pred = None
                        
                        if val_exists:
                            yv_pred = pred_arr[valid_val]
                            val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)
                            self.log(f"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}")
                            
                            # ä¿å­˜éªŒè¯é›†æ··æ·†çŸ©é˜µå’ŒæŠ¥å‘Š
                            if HAS_OPENPYXL:
                                self.log("   ğŸ’¾ ä¿å­˜éªŒè¯é›†ç»“æœ...")
                                val_classes = sorted(np.unique(yv_true))
                                val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                                
                                excel_path, img_path = self.backend.save_confusion_matrix(
                                    yv_true, yv_pred, val_class_names,
                                    clf_dir / f"{clf_code}_val",
                                    f"{clf_name} (éªŒè¯é›†)"
                                )
                                if excel_path:
                                    self.log(f"      âœ“ æ··æ·†çŸ©é˜µ: {excel_path.name}")
                                    self.log(f"      âœ“ å›¾ç‰‡: {img_path.name}")
                                
                                excel_path, txt_path = self.backend.save_classification_report(
                                    yv_true, yv_pred, val_class_names,
                                    clf_dir / f"{clf_code}_val"
                                )
                                if excel_path:
                                    self.log(f"      âœ“ åˆ†ç±»æŠ¥å‘Š: {excel_path.name}")
                            
                            # è®°å½•æœ€ä½³åˆ†ç±»å™¨
                            if val_metrics['overall_accuracy'] > best_accuracy:
                                best_accuracy = val_metrics['overall_accuracy']
                                best_clf_code = clf_code
                                self.best_result_path = classified_path
                                self.current_y_true = yv_true
                                self.current_y_pred = yv_pred
                        
                        # è®°å½•ç»“æœ
                        result = {
                            'åˆ†ç±»å™¨ä»£ç ': clf_code,
                            'åˆ†ç±»å™¨åç§°': clf_name,
                            'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],
                            'è®­ç»ƒé›†Kappa': train_metrics['kappa'],
                            'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],
                            'éªŒè¯é›†Kappa': val_metrics['kappa'],
                            'è®­ç»ƒæ—¶é—´(ç§’)': train_time,
                            'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,
                            'è¶…å‚æ•°ä¼˜åŒ–': bool(best_params),
                            'ä¼˜åŒ–å¾—åˆ†': optimization_score,
                        }
                        comparison_results.append(result)
                        self.comparison_results = comparison_results
                        
                        # å®æ—¶æ›´æ–°å›¾è¡¨
                        self.root.after(0, self.update_accuracy_plot)
                        self.root.after(0, self.update_time_plot)
                        
                        self.log(f"   âœ… {clf_name} å®Œæˆ!")
                    else:
                        self.log(f"   âŒ {clf_name} é¢„æµ‹å¤±è´¥æˆ–ç”¨æˆ·å–æ¶ˆ")
                    
                except Exception as e:
                    self.log(f"   âŒ {clf_name} å¤±è´¥: {str(e)}")
                    import traceback
                    self.log(traceback.format_exc())
                    continue
                
                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)
            
            # ç”ŸæˆæŠ¥å‘Š
            if comparison_results and self.is_running:
                total_time = time.time() - total_start_time
                
                self.log(f"\n{'='*80}")
                self.log("ğŸ“ ç”Ÿæˆæ€»ä½“æŠ¥å‘Š...")
                
                comparison_df = pd.DataFrame(comparison_results)
                
                # å¯¼å‡ºExcel
                self.export_to_excel(out_dir)
                
                # æ–‡å­—æŠ¥å‘Š
                with open(out_dir / "comparison_summary.txt", 'w', encoding='utf-8') as f:
                    f.write("é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n")
                    f.write("="*70 + "\n\n")
                    f.write(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"å½±åƒ: {img.shape[1]}Ã—{img.shape[2]}\n")
                    f.write(f"åˆ†è¾¨ç‡: {pixel_size_x:.2f}m Ã— {pixel_size_y:.2f}m\n")
                    f.write(f"è®­ç»ƒæ ·æœ¬: {len(y_train):,}\n")
                    f.write(f"æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\n")
                    f.write(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\n\n")
                    
                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)
                    f.write("éªŒè¯é›†ç²¾åº¦æ’å:\n")
                    f.write("-"*70 + "\n")
                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):
                        f.write(f"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - "
                               f"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}, "
                               f"Kappa: {row['éªŒè¯é›†Kappa']:.4f}\n")
                
                # æ›´æ–°æ··æ·†çŸ©é˜µ
                if self.current_y_true is not None and self.current_y_pred is not None:
                    val_classes = sorted(np.unique(self.current_y_true))
                    val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                    self.root.after(0, lambda: self.update_confusion_matrix(
                        self.current_y_true, self.current_y_pred, val_class_names
                    ))
                
                # æ›´æ–°ç»“æœé¢„è§ˆ
                if self.best_result_path:
                    self.root.after(0, lambda: self.update_result_preview(
                        self.image_path.get(), self.best_result_path, 
                        class_names, class_colors
                    ))
                
                self.log("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
                self.log(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
                
                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]
                self.log(f"\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})")
                
                self.status_var.set(f"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']}")
                
                # åˆ‡æ¢åˆ°ç²¾åº¦å¯¹æ¯”æ ‡ç­¾é¡µ
                self.root.after(0, lambda: self.notebook.select(1))
                
                messagebox.showinfo("ä»»åŠ¡å®Œæˆ", 
                    f"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\n\n"
                    f"âœ… æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\n"
                    f"ğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\n"
                    f"ğŸ“Š æ¯ä¸ªåˆ†ç±»å™¨çš„ç»“æœåŒ…æ‹¬:\n"
                    f"   â€¢ æ··æ·†çŸ©é˜µ (å›¾ç‰‡+Excel)\n"
                    f"   â€¢ åˆ†ç±»æŠ¥å‘Š (æ–‡æœ¬+Excel)\n"
                    f"   â€¢ é¢ç§¯ç»Ÿè®¡ (Excel)\n"
                    f"   â€¢ åˆ†ç±»ç»“æœå½±åƒ (GeoTIFF)\n"
                    f"   â€¢ ç‰¹å¾é‡è¦æ€§åˆ†æ\n"
                    f"   â€¢ ROCæ›²çº¿åˆ†æ\n"
                    f"   â€¢ è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
                 # æ˜¾ç¤ºæœ€ä½³åˆ†ç±»å™¨çš„ROCæ›²çº¿
                best_clf_code = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax(), 'åˆ†ç±»å™¨ä»£ç ']
                best_clf_name = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax(), 'åˆ†ç±»å™¨åç§°']
                
                # å°è¯•åŠ è½½æœ€ä½³åˆ†ç±»å™¨çš„ROCæ•°æ®
                best_clf_dir = out_dir / best_clf_code
                roc_data_file = best_clf_dir / f"{best_clf_code}_roc_curve_roc_data.json"
                
                if roc_data_file.exists():
                    try:
                        with open(roc_data_file, 'r', encoding='utf-8') as f:
                            best_roc_data = json.load(f)
                        self.root.after(0, lambda: self.update_roc_plot(best_roc_data, f"æœ€ä½³: {best_clf_name}"))
                    except Exception as e:
                        self.log(f"åŠ è½½æœ€ä½³åˆ†ç±»å™¨ROCæ•°æ®å¤±è´¥: {e}")
        except Exception as e:
            self.log(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc())
            messagebox.showerror("é”™è¯¯", f"å‘ç”Ÿé”™è¯¯:\n{str(e)}")
            self.status_var.set("âŒ é”™è¯¯")
        
        finally:
            self.start_btn.config(state=tk.NORMAL)
            self.stop_btn.config(state=tk.DISABLED)
            self.progress_var.set(0)
            self.is_running = False
    
    def save_config_to_file(self, file_path):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config = {
            'image_path': self.image_path.get(),
            'train_shp_path': self.train_shp_path.get(),
            'val_shp_path': self.val_shp_path.get(),
            'output_dir': self.output_dir.get(),
            'class_attr': self.class_attr.get(),
            'name_attr': self.name_attr.get(),
            'background_value': self.background_value.get(),
            'ignore_background': self.ignore_background.get(),
            'n_estimators': self.n_estimators.get(),
            'block_size': self.block_size.get(),
            'enable_sampling': self.enable_sampling.get(),
            'max_samples': self.max_samples.get(),
            'fast_mode': self.fast_mode.get(),
            'enable_hyperparameter_optimization': self.enable_hyperparameter_optimization.get(),
            'hyperparameter_optimization_method': self.hyperparameter_optimization_method.get(),
            'hyperparameter_iterations': self.hyperparameter_iterations.get(),
            'enable_postprocessing': self.enable_postprocessing.get(),
            'postprocessing_method': self.postprocessing_method.get(),
            'postprocessing_size': self.postprocessing_size.get(),
            'enable_feature_importance': self.enable_feature_importance.get(),
            'enable_roc_analysis': self.enable_roc_analysis.get(),
            'enable_model_saving': self.enable_model_saving.get(),
            'selected_classifiers': {code: var.get() for code, var in self.classifier_vars.items()},
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            return True
        except Exception as e:
            self.log(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
            return False
    
    def open_result_dir(self):
        """æ‰“å¼€ç»“æœç›®å½•"""
        out_dir = Path(self.output_dir.get())
        if out_dir.exists():
            import subprocess
            import platform
            
            if platform.system() == "Windows":
                os.startfile(out_dir)
            elif platform.system() == "Darwin":
                subprocess.Popen(["open", out_dir])
            else:
                subprocess.Popen(["xdg-open", out_dir])
        else:
            messagebox.showwarning("è­¦å‘Š", "ç»“æœç›®å½•ä¸å­˜åœ¨ï¼")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
def main():
    """ç¨‹åºå…¥å£"""
    print("="*80)
    print("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ")
    print("="*80)
    print("\næ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...")
    
    root = tk.Tk()
    app = ClassificationGUI(root)
    
    # æ¬¢è¿ä¿¡æ¯
    app.log("="*80)
    app.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ")
    app.log("                     @ 3S&MLå®éªŒå®¤")
    app.log("="*80)
    app.log("\næ ¸å¿ƒåŠŸèƒ½:")
    app.log("  âœ… å¤šåˆ†ç±»å™¨æ”¯æŒ: é›†æˆ12+ç§æœºå™¨å­¦ä¹ åˆ†ç±»å™¨")
    app.log("  âœ… è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–: è‡ªåŠ¨å¯»æ‰¾æœ€ä½³å‚æ•°ç»„åˆ")
    app.log("  âœ… åå¤„ç†æ»¤æ³¢: æå‡åˆ†ç±»ç»“æœè´¨é‡")
    app.log("  âœ… ROCæ›²çº¿åˆ†æ: ä¸“ä¸šæ¨¡å‹è¯„ä¼°")
    app.log("  âœ… ç‰¹å¾é‡è¦æ€§åˆ†æ: æ³¢æ®µè´¡çŒ®åº¦åˆ†æ")
    app.log("  âœ… æ¨¡å‹ä¿å­˜/åŠ è½½: æ”¯æŒæ¨¡å‹å¤ç”¨")
    app.log("  âœ… æ‰¹é‡å¤„ç†: å¤šåˆ†ç±»å™¨å¹¶è¡Œå¯¹æ¯”")
    app.log("  âœ… å¯è§†åŒ–åˆ†æ: å®æ—¶å›¾è¡¨æ˜¾ç¤º")
    app.log("\nä½¿ç”¨æµç¨‹:")
    app.log("  1. é€‰æ‹©å½±åƒå’Œæ ·æœ¬æ–‡ä»¶")
    app.log("  2. ç‚¹å‡»'åˆ·æ–°å­—æ®µåˆ—è¡¨'é€‰æ‹©ç±»åˆ«å­—æ®µ")
    app.log("  3. è®¾ç½®èƒŒæ™¯å€¼å’Œå…¶ä»–å‚æ•°")
    app.log("  4. é€‰æ‹©åˆ†ç±»å™¨")
    app.log("  5. é…ç½®é«˜çº§åŠŸèƒ½ï¼ˆè¶…å‚æ•°ä¼˜åŒ–ã€åå¤„ç†ç­‰ï¼‰")
    app.log("  6. ç‚¹å‡»'å¼€å§‹åˆ†ç±»'")
    app.log("  7. æŸ¥çœ‹å³ä¾§å®æ—¶å›¾è¡¨å’Œå„åˆ†ç±»å™¨è¯¦ç»†ç»“æœ")
    app.log("="*80)
    app.log("\næŠ€æœ¯ä¼˜åŠ¿:")
    app.log("  ğŸš€ é«˜æ€§èƒ½: æ”¯æŒåˆ†å—å¤„ç†å¤§å½±åƒ")
    app.log("  ğŸ“Š ä¸“ä¸šè¯„ä¼°: æä¾›å®Œæ•´çš„ç²¾åº¦è¯„ä»·æŒ‡æ ‡")
    app.log("  ğŸ’¾ å¤šç§æ ¼å¼: æ”¯æŒå¤šç§æ•°æ®æ ¼å¼è¾“å‡º")
    app.log("  ğŸ”§ çµæ´»é…ç½®: å‚æ•°å¯è°ƒï¼Œé€‚åº”ä¸åŒéœ€æ±‚")
    app.log("")
    
    print("\nâœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!")
    
    root.mainloop()

if __name__ == "__main__":
    main()