#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - ä¸“ä¸šç‰ˆ v5.1 (PyQt5ç‰ˆæœ¬)
=====================================
ä¿®å¤é—®é¢˜:
1. âœ… ä¿®å¤ç‰¹å¾é‡è¦æ€§åˆ†æä¸­çš„IndexError
2. âœ… ä¿®å¤AdaBooståˆ†ç±»å™¨å‚æ•°é”™è¯¯
3. âœ… ä¼˜åŒ–ç‰¹å¾é‡è¦æ€§æ˜¾ç¤º
4. âœ… å¢å¼ºé”™è¯¯å¤„ç†æœºåˆ¶
5. âœ… ç§»æ¤å®Œæ•´çš„åˆ†ç±»åŠŸèƒ½åˆ°PyQt5ç‰ˆæœ¬
6. âœ… å®ç°å³ä¾§å…­ä¸ªæ ‡ç­¾é¡µçš„å›¾è¡¨ç»˜åˆ¶åŠŸèƒ½
"""

import os
import sys
import time
import threading
import queue
import json
import pickle
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg, NavigationToolbar2QT
from matplotlib.figure import Figure
import matplotlib.colors as mcolors
import seaborn as sns
import geopandas as gpd
import rioxarray as rxr
import xarray as xr
from rasterio import features
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, 
                              AdaBoostClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.kernel_approximation import Nystroem, RBFSampler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, 
                           cohen_kappa_score, precision_score, recall_score, f1_score,
                           roc_curve, auc, precision_recall_curve, roc_auc_score)
from sklearn.inspection import permutation_importance
from scipy import ndimage
from skimage import morphology, filters
import warnings
warnings.filterwarnings('ignore')

# PyQt5 imports
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, 
                             QSplitter, QGroupBox, QLabel, QLineEdit, QPushButton, QComboBox, 
                             QCheckBox, QSpinBox, QProgressBar, QTextEdit, QTabWidget, 
                             QScrollArea, QGridLayout, QFrame, QMessageBox, QFileDialog,
                             QRadioButton, QButtonGroup, QDialog, QDialogButtonBox)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QFont, QPalette, QColor

sns.set_style("whitegrid")

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans", "Arial Unicode MS"]
plt.rcParams["axes.unicode_minus"] = False

# æ£€æŸ¥openpyxl
try:
    import openpyxl
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False
    print("âš ï¸  æœªå®‰è£…openpyxlï¼Œå°†æ— æ³•å¯¼å‡ºExcelæ–‡ä»¶")
    print("   å®‰è£…: pip install openpyxl")

# ==================== åç«¯å¤„ç†ç±» ====================
class ClassificationBackend:
    """åˆ†ç±»å¤„ç†åç«¯"""
    
    def __init__(self):
        self.RANDOM_STATE = 42
        
        # é¢„å®šä¹‰é¢œè‰²
        self.LANDUSE_COLORS = {
            "æ°´ä½“": "lightblue", "æ²³æµ": "blue", "æ¹–æ³Š": "deepskyblue",
            "æ¤è¢«": "forestgreen", "æ£®æ—": "darkgreen", "è‰åœ°": "limegreen",
            "å†œç”°": "yellowgreen", "è€•åœ°": "olivedrab",
            "å»ºç­‘": "gray", "åŸå¸‚": "dimgray", "å±…æ°‘åœ°": "slategray",
            "è£¸åœ°": "tan", "æ²™åœ°": "wheat", "å…¶ä»–": "darkred"
        }
        
        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', 
                             'darkred', 'purple', 'orange', 'pink', 'brown']
        
        # æ£€æŸ¥å¯é€‰åº“
        self.check_optional_libraries()
    
    def check_optional_libraries(self):
        """æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨"""
        self.has_xgboost = False
        self.has_lightgbm = False
        
        try:
            import xgboost
            from xgboost import XGBClassifier
            _ = XGBClassifier(n_estimators=10, verbosity=0)
            self.has_xgboost = True
            print("âœ“ XGBoost å¯ç”¨")
        except Exception:
            print("âœ— XGBoost ä¸å¯ç”¨")
        
        try:
            import lightgbm
            from lightgbm import LGBMClassifier
            _ = LGBMClassifier(n_estimators=10, verbose=-1)
            self.has_lightgbm = True
            print("âœ“ LightGBM å¯ç”¨")
        except Exception:
            print("âœ— LightGBM ä¸å¯ç”¨")
    
    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):
        """è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨"""
        if fast_mode:
            n_est = min(50, n_estimators)
            max_depth = 10
            max_iter = 200
        else:
            n_est = n_estimators
            max_depth = 20
            max_iter = 500
        
        if n_train_samples:
            n_components = min(1000, n_train_samples // 2)
        else:
            n_components = 1000
        
        classifiers = {
            "rf": (RandomForestClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE, 
                                         verbose=0, max_depth=max_depth, min_samples_split=5, 
                                         max_features='sqrt'),
                  "éšæœºæ£®æ—", "Random Forest", False, False, "fast"),
            
            "et": (ExtraTreesClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE,
                                       verbose=0, max_depth=max_depth, min_samples_split=5, max_features='sqrt'),
                  "æç«¯éšæœºæ ‘", "Extra Trees", False, False, "fast"),
            
            "dt": (DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=max_depth,
                                         min_samples_split=5, min_samples_leaf=2),
                  "å†³ç­–æ ‘", "Decision Tree", False, False, "very_fast"),
            
            "svm_linear": (SVC(kernel="linear", C=1.0, cache_size=500, probability=True, 
                             random_state=self.RANDOM_STATE, max_iter=max_iter),
                          "SVM-çº¿æ€§æ ¸", "SVM Linear", False, True, "medium"),
            
            "linear_svc": (CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=max_iter, random_state=self.RANDOM_STATE,
                                                           dual=False, loss='squared_hinge'), cv=3),
                          "çº¿æ€§SVM(å¿«)", "Linear SVM", False, True, "fast"),
            
            "sgd_svm": (SGDClassifier(loss='hinge', penalty='l2', max_iter=max_iter, n_jobs=-1,
                                     random_state=self.RANDOM_STATE, learning_rate='optimal'),
                       "SGD-SVM", "SGD SVM", False, True, "very_fast"),
            
            "nystroem_svm": (Pipeline([
                ("feature_map", Nystroem(kernel='rbf', gamma=0.1, n_components=n_components, 
                                        random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "æ ¸è¿‘ä¼¼SVM", "Nystroem SVM", False, True, "fast"),
            
            "rbf_sampler_svm": (Pipeline([
                ("feature_map", RBFSampler(gamma=0.1, n_components=n_components, random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "RBFé‡‡æ ·SVM", "RBF Sampler", False, True, "fast"),
            
            "svm_rbf": (SVC(kernel="rbf", C=1.0, gamma='scale', cache_size=500, probability=True, 
                          random_state=self.RANDOM_STATE),
                       "SVM-RBFæ ¸âš ï¸", "SVM RBF", False, True, "very_slow"),
            
            "knn": (KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm='ball_tree', leaf_size=30),
                   "Kè¿‘é‚»", "KNN", False, True, "slow"),
            
            "nb": (GaussianNB(), "æœ´ç´ è´å¶æ–¯", "Naive Bayes", False, False, "very_fast"),
            
            "gb": (GradientBoostingClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=5,
                                             random_state=self.RANDOM_STATE, verbose=0, subsample=0.8),
                  "æ¢¯åº¦æå‡", "Gradient Boosting", False, False, "medium"),
            
            # ä¿®å¤AdaBoostå‚æ•°é—®é¢˜
            "ada": (AdaBoostClassifier(n_estimators=n_est, learning_rate=1.0, 
                                      random_state=self.RANDOM_STATE),
                   "AdaBoost", "AdaBoost", False, False, "medium"),
            
            "lr": (LogisticRegression(max_iter=max_iter, n_jobs=-1, random_state=self.RANDOM_STATE,
                                     verbose=0, solver='lbfgs', multi_class='multinomial'),
                  "é€»è¾‘å›å½’", "Logistic Regression", False, True, "very_fast"),
            
            "mlp": (MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=max_iter, random_state=self.RANDOM_STATE,
                                 verbose=False, early_stopping=True, validation_fraction=0.1, 
                                 n_iter_no_change=10, learning_rate='adaptive'),
                   "ç¥ç»ç½‘ç»œ", "MLP", False, True, "medium"),
        }
        
        if self.has_xgboost:
            try:
                from xgboost import XGBClassifier
                classifiers["xgb"] = (
                    XGBClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=6, n_jobs=-1,
                                 random_state=self.RANDOM_STATE, verbosity=0, tree_method='hist',
                                 subsample=0.8, colsample_bytree=0.8),
                    "XGBoost", "XGBoost", True, False, "fast"
                )
            except Exception:
                pass
        
        if self.has_lightgbm:
            try:
                from lightgbm import LGBMClassifier
                classifiers["lgb"] = (
                    LGBMClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=max_depth, n_jobs=-1,
                                  random_state=self.RANDOM_STATE, verbose=-1, num_leaves=31,
                                  subsample=0.8, colsample_bytree=0.8, force_col_wise=True),
                    "LightGBM", "LightGBM", False, False, "very_fast"
                )
            except Exception:
                pass
        
        return classifiers

    def get_hyperparameter_grids(self, clf_code, n_samples=None):
        """è·å–å„åˆ†ç±»å™¨çš„è¶…å‚æ•°ç½‘æ ¼"""
        grids = {}
        
        # åŸºç¡€å‚æ•°
        if n_samples and n_samples < 1000:
            n_estimators_range = [50, 100]
            max_depth_range = [3, 5, 7]
        elif n_samples and n_samples < 10000:
            n_estimators_range = [100, 200]
            max_depth_range = [5, 10, 15]
        else:
            n_estimators_range = [100, 200, 300]
            max_depth_range = [10, 15, 20, None]
        
        if clf_code == "rf":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': max_depth_range,
                'min_samples_split': [2, 5, 10],
                'max_features': ['sqrt', 'log2', None]
            }
        elif clf_code == "xgb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': [3, 6, 9],
                'learning_rate': [0.01, 0.1, 0.2],
                'subsample': [0.8, 1.0],
                'colsample_bytree': [0.8, 1.0]
            }
        elif clf_code == "lgb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'max_depth': [3, 6, 9, -1],
                'learning_rate': [0.01, 0.1, 0.2],
                'num_leaves': [31, 63, 127],
                'subsample': [0.8, 1.0]
            }
        elif clf_code == "svm_linear":
            grids[clf_code] = {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto']
            }
        elif clf_code == "svm_rbf":
            grids[clf_code] = {
                'C': [0.1, 1, 10, 100],
                'gamma': ['scale', 'auto', 0.1, 1]
            }
        elif clf_code == "knn":
            grids[clf_code] = {
                'n_neighbors': [3, 5, 7, 9, 11],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan']
            }
        elif clf_code == "mlp":
            grids[clf_code] = {
                'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],
                'alpha': [0.0001, 0.001, 0.01],
                'learning_rate': ['constant', 'adaptive']
            }
        elif clf_code == "gb":
            grids[clf_code] = {
                'n_estimators': n_estimators_range,
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'subsample': [0.8, 1.0]
            }
        
        return grids.get(clf_code, {})
    
    def optimize_hyperparameters(self, clf, clf_code, X_train, y_train, cv=3, n_iter=20):
        """è¶…å‚æ•°ä¼˜åŒ–"""
        param_grid = self.get_hyperparameter_grids(clf_code, len(y_train))
        
        if not param_grid:
            return clf, {}, 0
        
        try:
            # å¯¹äºå¤§æ•°æ®é›†ä½¿ç”¨éšæœºæœç´¢ï¼Œå°æ•°æ®é›†ä½¿ç”¨ç½‘æ ¼æœç´¢
            if len(y_train) > 1000 or len(param_grid) > 10:
                search = RandomizedSearchCV(
                    clf, param_grid, n_iter=min(n_iter, len(param_grid) * 3), 
                    cv=cv, scoring='accuracy', n_jobs=-1, random_state=self.RANDOM_STATE,
                    verbose=0
                )
            else:
                search = GridSearchCV(
                    clf, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, 
                    verbose=0
                )
            
            search.fit(X_train, y_train)
            
            return search.best_estimator_, search.best_params_, search.best_score_
        
        except Exception as e:
            print(f"è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}")
            return clf, {}, 0
    
    def apply_postprocessing(self, classified_array, method='majority', size=3):
        """åå¤„ç†æ»¤æ³¢"""
        if method == 'none':
            return classified_array
        
        # åˆ›å»ºæ©è†œï¼Œåªå¤„ç†éèƒŒæ™¯åŒºåŸŸ
        mask = classified_array > 0
        result = classified_array.copy()
        
        if method == 'majority':
            # å¤šæ•°æ»¤æ³¢
            from scipy.ndimage import generic_filter
            
            def majority_filter(x):
                values, counts = np.unique(x, return_counts=True)
                return values[np.argmax(counts)]
            
            result[mask] = generic_filter(
                classified_array, majority_filter, size=size, mode='constant', cval=0
            )[mask]
        
        elif method == 'median':
            # ä¸­å€¼æ»¤æ³¢
            result[mask] = ndimage.median_filter(classified_array, size=size)[mask]
        
        elif method == 'opening':
            # å½¢æ€å­¦å¼€è¿ç®—ï¼ˆå»é™¤å°æ–‘å—ï¼‰
            from skimage.morphology import opening, square
            result = opening(classified_array, square(size))
        
        elif method == 'closing':
            # å½¢æ€å­¦é—­è¿ç®—ï¼ˆå¡«å……å°æ´ï¼‰
            from skimage.morphology import closing, square
            result = closing(classified_array, square(size))
        
        return result
    
    def analyze_feature_importance(self, model, feature_names, X_val, y_val, n_repeats=5):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        try:
            # å¯¹äºæ ‘æ¨¡å‹ï¼Œä½¿ç”¨å†…ç½®ç‰¹å¾é‡è¦æ€§
            if hasattr(model, 'feature_importances_'):
                importances = model.feature_importances_
                
                # ä¿®å¤ï¼šç¡®ä¿stdæ˜¯æ­£ç¡®å½¢çŠ¶çš„æ•°ç»„
                if hasattr(model, 'estimators_') and model.estimators_ is not None:
                    try:
                        # è·å–æ‰€æœ‰æ ‘çš„é‡è¦æ€§
                        tree_importances = np.array([tree.feature_importances_ for tree in model.estimators_])
                        std = np.std(tree_importances, axis=0)
                    except:
                        std = np.zeros_like(importances)
                else:
                    std = np.zeros_like(importances)
                
                return {
                    'method': 'builtin',
                    'importances': importances,
                    'std': std,
                    'indices': np.argsort(importances)[::-1]
                }
            
            # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨æ’åˆ—é‡è¦æ€§
            else:
                try:
                    result = permutation_importance(
                        model, X_val, y_val, n_repeats=n_repeats, 
                        random_state=self.RANDOM_STATE, n_jobs=-1
                    )
                    
                    return {
                        'method': 'permutation',
                        'importances': result.importances_mean,
                        'std': result.importances_std,
                        'indices': np.argsort(result.importances_mean)[::-1]
                    }
                except Exception as e:
                    print(f"æ’åˆ—é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
                    return None
        
        except Exception as e:
            print(f"ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
            return None
    
    def plot_feature_importance(self, importance_data, feature_names, save_path, clf_name):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        if not importance_data:
            return None
        
        try:
            fig, ax = plt.subplots(figsize=(10, 6))
            
            indices = importance_data['indices']
            importances = importance_data['importances']
            
            # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†ç´¢å¼•å’Œé‡è¦æ€§æ•°ç»„
            if len(indices) > 0 and len(importances) > 0:
                # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                valid_indices = indices[indices < len(importances)]
                sorted_importances = importances[valid_indices]
                
                # å¤„ç†æ ‡å‡†å·®
                if 'std' in importance_data and importance_data['std'] is not None:
                    std = importance_data['std']
                    if len(std) == len(importances):
                        sorted_std = std[valid_indices]
                    else:
                        sorted_std = None
                else:
                    sorted_std = None
                
                features = [feature_names[i] for i in valid_indices if i < len(feature_names)]
                
                y_pos = np.arange(len(features))
                
                if sorted_std is not None and len(sorted_std) == len(sorted_importances):
                    ax.barh(y_pos, sorted_importances, xerr=sorted_std, align='center', alpha=0.7)
                else:
                    ax.barh(y_pos, sorted_importances, align='center', alpha=0.7)
                
                ax.set_yticks(y_pos)
                ax.set_yticklabels(features)
                ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
                ax.set_title(f'{clf_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ')
                ax.grid(True, alpha=0.3, axis='x')
                
                plt.tight_layout()
                fig.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close(fig)
                
                return save_path
            else:
                print("ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆ")
                return None
                
        except Exception as e:
            print(f"ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾å¤±è´¥: {e}")
            return None
    
    def plot_roc_curves(self, model, X_test, y_test, class_names, save_path, clf_name):
        """ç»˜åˆ¶ROCæ›²çº¿ï¼ˆé€‚ç”¨äºäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»ï¼‰"""
        try:
            # è·å–é¢„æµ‹æ¦‚ç‡
            if hasattr(model, 'predict_proba'):
                y_score = model.predict_proba(X_test)
            else:
                # å¯¹äºæ²¡æœ‰predict_probaçš„æ¨¡å‹ï¼Œä½¿ç”¨å†³ç­–å‡½æ•°
                y_score = model.decision_function(X_test)
                if y_score.ndim == 1:
                    y_score = y_score.reshape(-1, 1)
            
            n_classes = len(class_names)
            
            fig, ax = plt.subplots(figsize=(10, 8))
            
            if n_classes == 2:
                # äºŒåˆ†ç±»
                fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])
                roc_auc = auc(fpr, tpr)
                
                ax.plot(fpr, tpr, color='darkorange', lw=2,
                    label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})')
                ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨')
                
            else:
                # å¤šåˆ†ç±» - ä¸€å¯¹å¤š
                from sklearn.preprocessing import label_binarize
                
                # è·å–æ‰€æœ‰ç±»åˆ«
                classes = np.unique(y_test)
                y_test_bin = label_binarize(y_test, classes=classes)
                
                fpr = dict()
                tpr = dict()
                roc_auc = dict()
                
                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ROCæ›²çº¿
                for i, class_id in enumerate(classes):
                    if y_score.shape[1] > i:  # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
                        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
                        roc_auc[i] = auc(fpr[i], tpr[i])
                        
                        class_name = class_names.get(class_id, f'ç±»åˆ«_{class_id}')
                        ax.plot(fpr[i], tpr[i], lw=2,
                            label=f'{class_name} (AUC = {roc_auc[i]:.2f})')
                
                # è®¡ç®—å®å¹³å‡ROCæ›²çº¿
                all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes))]))
                mean_tpr = np.zeros_like(all_fpr)
                
                for i in range(len(classes)):
                    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
                
                mean_tpr /= len(classes)
                
                fpr["macro"] = all_fpr
                tpr["macro"] = mean_tpr
                roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])
                
                ax.plot(fpr["macro"], tpr["macro"],
                    label=f'å®å¹³å‡ (AUC = {roc_auc["macro"]:.2f})',
                    color='navy', linestyle=':', linewidth=4)
                
                ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨', alpha=0.8)
            
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡ (False Positive Rate)', fontsize=12)
            ax.set_ylabel('çœŸæ­£ç‡ (True Positive Rate)', fontsize=12)
            ax.set_title(f'{clf_name} - ROCæ›²çº¿', fontsize=14, fontweight='bold')
            ax.legend(loc="lower right", fontsize=10)
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            fig.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close(fig)
            
            # ä¿å­˜AUCæ•°æ®
            auc_data = {
                'class_names': class_names,
                'auc_scores': roc_auc if n_classes == 2 else {class_names.get(k, f'ç±»åˆ«_{k}'): v for k, v in roc_auc.items()},
                'macro_auc': roc_auc if n_classes == 2 else roc_auc.get("macro", 0)
            }
            
            # ä¿å­˜è¯¦ç»†çš„ROCæ•°æ®
            roc_data = {
                'fpr': fpr if n_classes == 2 else {k: v.tolist() for k, v in fpr.items()},
                'tpr': tpr if n_classes == 2 else {k: v.tolist() for k, v in tpr.items()},
                'auc': roc_auc if n_classes == 2 else {k: v for k, v in roc_auc.items()}
            }
            
            with open(save_path.parent / f"{save_path.stem}_auc.json", 'w', encoding='utf-8') as f:
                json.dump(auc_data, f, indent=2, ensure_ascii=False)
            
            with open(save_path.parent / f"{save_path.stem}_roc_data.json", 'w', encoding='utf-8') as f:
                json.dump(roc_data, f, indent=2, ensure_ascii=False)
            
            return save_path, auc_data, roc_data
        
        except Exception as e:
            print(f"ROCæ›²çº¿ç»˜åˆ¶å¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            return None, None, None
    
    def save_model(self, model, file_path):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            with open(file_path, 'wb') as f:
                pickle.dump(model, f)
            return True
        except Exception as e:
            print(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def load_model(self, file_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            with open(file_path, 'rb') as f:
                model = pickle.load(f)
            return model
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def get_background_mask(self, image, background_value=0):
        """è·å–èƒŒæ™¯æ©è†œ"""
        data = image.values
        if background_value == 0:
            background_mask = np.all(data == 0, axis=0)
        else:
            background_mask = np.all(data == background_value, axis=0)
        return background_mask
    
    def get_shapefile_fields(self, shp_path):
        """è·å–shapefileçš„æ‰€æœ‰å­—æ®µå"""
        try:
            gdf = gpd.read_file(shp_path)
            return list(gdf.columns)
        except Exception as e:
            print(f"è¯»å–shapefileå­—æ®µå¤±è´¥: {e}")
            return []
    
    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):
        """ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯"""
        gdf = gpd.read_file(shp_path)
        
        if name_attr not in gdf.columns or name_attr == class_attr:
            gdf[name_attr] = gdf[class_attr].apply(lambda x: f"ç±»åˆ«_{x}")
        
        class_info = gdf[[class_attr, name_attr]].drop_duplicates()
        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))
        
        class_colors = {}
        for i, (class_id, class_name) in enumerate(class_names.items()):
            color_found = False
            for key, color in self.LANDUSE_COLORS.items():
                if key in str(class_name):
                    class_colors[class_id] = color
                    color_found = True
                    break
            if not color_found:
                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]
        
        return class_names, class_colors, sorted(class_names.keys())
    
    def rasterize_samples(self, shp, ref_img, attr):
        """çŸ¢é‡æ …æ ¼åŒ–"""
        gdf = gpd.read_file(shp)
        gdf = gdf.to_crs(ref_img.rio.crs)
        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))
        
        arr = features.rasterize(shapes=shapes, out_shape=ref_img.shape[1:],
                                transform=ref_img.rio.transform(), fill=0,
                                all_touched=True, dtype="uint16")
        return arr
    
    def extract_samples(self, image, mask, ignore_background=True, background_value=0, max_samples=None):
        """æå–æ ·æœ¬"""
        data = np.moveaxis(image.values, 0, -1)
        valid = mask > 0
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
            valid = valid & (~background_mask)
        
        X = data[valid]
        y = mask[valid]
        
        # æ¸…ç†NaNå’ŒInf
        nan_mask = np.isnan(X).any(axis=1)
        inf_mask = np.isinf(X).any(axis=1)
        bad_mask = nan_mask | inf_mask
        
        n_nan = np.sum(nan_mask)
        n_inf = np.sum(inf_mask)
        
        X = X[~bad_mask]
        y = y[~bad_mask]
        
        # åˆ†å±‚é‡‡æ ·
        n_sampled = 0
        if max_samples is not None and len(y) > max_samples:
            n_original = len(y)
            unique_classes = np.unique(y)
            
            if len(unique_classes) > 1:
                splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_samples, 
                                                 random_state=self.RANDOM_STATE)
                sample_idx, _ = next(splitter.split(X, y))
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
            else:
                np.random.seed(self.RANDOM_STATE)
                sample_idx = np.random.choice(len(y), max_samples, replace=False)
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
        
        return X, y, n_nan, n_inf, n_sampled
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'overall_accuracy': accuracy_score(y_true, y_pred),
            'kappa': cohen_kappa_score(y_true, y_pred),
            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        }
    
    def save_confusion_matrix(self, y_true, y_pred, class_names, save_path, clf_name):
        """ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆå›¾ç‰‡+Excelï¼‰"""
        if not HAS_OPENPYXL:
            return None, None
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred)
        
        # ä¿å­˜Excelæ ¼å¼
        cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)
        excel_path = save_path.parent / f"{save_path.stem}_confusion_matrix.xlsx"
        cm_df.to_excel(excel_path, engine='openpyxl')
        
        # ç»˜åˆ¶å¹¶ä¿å­˜å›¾ç‰‡
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=class_names, yticklabels=class_names,
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=12)
        ax.set_title(f'{clf_name} - æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        plt.tight_layout()
        
        img_path = save_path.parent / f"{save_path.stem}_confusion_matrix.png"
        fig.savefig(img_path, dpi=300, bbox_inches='tight')
        plt.close(fig)
        
        return excel_path, img_path
    
    def calculate_area_statistics(self, classified_array, pixel_size_x, pixel_size_y, 
                                  class_names, background_value=0):
        """è®¡ç®—é¢ç§¯ç»Ÿè®¡"""
        # è®¡ç®—æ¯ä¸ªåƒå…ƒçš„é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
        pixel_area = abs(pixel_size_x * pixel_size_y)
        
        # ç»Ÿè®¡å„ç±»åˆ«åƒå…ƒæ•°é‡
        unique_classes, counts = np.unique(classified_array[classified_array != background_value], 
                                          return_counts=True)
        
        # è®¡ç®—æ€»åƒå…ƒæ•°ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ï¼‰
        total_pixels = np.sum(counts)
        
        # æ„å»ºç»Ÿè®¡è¡¨
        stats = []
        for class_id, pixel_count in zip(unique_classes, counts):
            class_name = class_names.get(class_id, f"ç±»åˆ«_{class_id}")
            area_m2 = pixel_count * pixel_area
            area_km2 = area_m2 / 1_000_000
            area_ha = area_m2 / 10_000
            percentage = (pixel_count / total_pixels) * 100
            
            stats.append({
                'ç±»åˆ«ç¼–å·': int(class_id),
                'ç±»åˆ«åç§°': class_name,
                'åƒå…ƒæ•°é‡': int(pixel_count),
                'é¢ç§¯(mÂ²)': area_m2,
                'é¢ç§¯(ha)': area_ha,
                'é¢ç§¯(kmÂ²)': area_km2,
                'ç™¾åˆ†æ¯”(%)': percentage
            })
        
        df = pd.DataFrame(stats)
        
        # æ·»åŠ æ€»è®¡è¡Œ
        total_row = {
            'ç±»åˆ«ç¼–å·': '',
            'ç±»åˆ«åç§°': 'æ€»è®¡',
            'åƒå…ƒæ•°é‡': int(total_pixels),
            'é¢ç§¯(mÂ²)': df['é¢ç§¯(mÂ²)'].sum(),
            'é¢ç§¯(ha)': df['é¢ç§¯(ha)'].sum(),
            'é¢ç§¯(kmÂ²)': df['é¢ç§¯(kmÂ²)'].sum(),
            'ç™¾åˆ†æ¯”(%)': 100.0
        }
        df = pd.concat([df, pd.DataFrame([total_row])], ignore_index=True)
        
        return df
    
    def save_classification_report(self, y_true, y_pred, class_names, save_path):
        """ä¿å­˜è¯¦ç»†åˆ†ç±»æŠ¥å‘Šï¼ˆæ–‡æœ¬+Excelï¼‰"""
        if not HAS_OPENPYXL:
            # ä»…ä¿å­˜æ–‡æœ¬æ ¼å¼
            txt_path = save_path.parent / f"{save_path.stem}_classification_report.txt"
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(classification_report(y_true, y_pred, 
                                             target_names=class_names,
                                             zero_division=0))
            return None, txt_path
        
        # è·å–sklearnçš„åˆ†ç±»æŠ¥å‘Š
        report_dict = classification_report(y_true, y_pred, 
                                           target_names=class_names,
                                           output_dict=True,
                                           zero_division=0)
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(report_dict).transpose()
        
        # ä¿å­˜Excel
        excel_path = save_path.parent / f"{save_path.stem}_classification_report.xlsx"
        df.to_excel(excel_path, engine='openpyxl')
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼
        txt_path = save_path.parent / f"{save_path.stem}_classification_report.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(classification_report(y_true, y_pred, 
                                         target_names=class_names,
                                         zero_division=0))
        
        return excel_path, txt_path
    
    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):
        """ä¼°ç®—é¢„æµ‹æ—¶é—´"""
        time_per_million = {"very_fast": 1, "fast": 3, "medium": 10, "slow": 30, "very_slow": 300}
        base_time = time_per_million.get(speed_tag, 10)
        return (n_pixels / 1_000_000) * base_time
    
    def predict_by_block(self, model, image, out_path, block_size=512, 
                        ignore_background=True, background_value=0, progress_callback=None,
                        label_encoder=None, scaler=None, postprocessing=None):
        """åˆ†å—é¢„æµ‹"""
        height, width = image.shape[1], image.shape[2]
        prediction = np.zeros((height, width), dtype='uint16')
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
        
        total_blocks = int(np.ceil(height / block_size))
        
        for i, y in enumerate(range(0, height, block_size)):
            if not hasattr(self, 'is_running') or self.is_running:
                h = min(block_size, height - y)
                block_data = image.isel(y=slice(y, y+h)).values
                data = np.moveaxis(block_data, 0, -1)
                original_shape = data.shape
                data_flat = data.reshape(-1, data.shape[-1])
                
                if ignore_background:
                    block_bg_mask = background_mask[y:y+h, :].flatten()
                    non_bg_indices = ~block_bg_mask
                    
                    if np.any(non_bg_indices):
                        data_to_predict = np.nan_to_num(data_flat[non_bg_indices], 
                                                       nan=0.0, posinf=0.0, neginf=0.0)
                        
                        if scaler is not None:
                            data_to_predict = scaler.transform(data_to_predict)
                        
                        preds_non_bg = model.predict(data_to_predict)
                        
                        if label_encoder is not None:
                            preds_non_bg = label_encoder.inverse_transform(preds_non_bg)
                        
                        preds_flat = np.zeros(len(data_flat), dtype='uint16')
                        preds_flat[non_bg_indices] = preds_non_bg
                        preds = preds_flat.reshape(original_shape[0], original_shape[1])
                    else:
                        preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')
                else:
                    data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)
                    
                    if scaler is not None:
                        data_flat = scaler.transform(data_flat)
                    
                    preds = model.predict(data_flat)
                    
                    if label_encoder is not None:
                        preds = label_encoder.inverse_transform(preds)
                    
                    preds = preds.reshape(original_shape[0], original_shape[1]).astype("uint16")
                
                prediction[y:y+h, :] = preds
                
                if progress_callback:
                    progress_callback((i + 1) / total_blocks * 100)
            else:
                break
        
        # åº”ç”¨åå¤„ç†
        if postprocessing and postprocessing != 'none':
            prediction = self.apply_postprocessing(prediction, method=postprocessing)
        
        # ä¿å­˜ç»“æœ
        prediction_da = xr.DataArray(prediction, dims=['y', 'x'],
                                     coords={'y': image.coords['y'], 'x': image.coords['x']})
        
        prediction_da.rio.write_crs(image.rio.crs, inplace=True)
        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)
        prediction_da.rio.write_nodata(background_value, inplace=True)
        
        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', 
                                    compress='lzw', tiled=True)
        return out_path


# ==================== PyQt5 GUI ç»„ä»¶ ====================

class MatplotlibWidget(QWidget):
    """Matplotlibå›¾è¡¨ç»„ä»¶"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.canvas = FigureCanvasQTAgg(Figure(figsize=(10, 6)))
        self.toolbar = NavigationToolbar2QT(self.canvas, self)
        
        layout = QVBoxLayout()
        layout.addWidget(self.toolbar)
        layout.addWidget(self.canvas)
        self.setLayout(layout)
        
        self.figure = self.canvas.figure
        self.axes = self.figure.add_subplot(111)
    
    def clear(self):
        self.figure.clear()
        self.axes = self.figure.add_subplot(111)


class LogWidget(QTextEdit):
    """æ—¥å¿—æ˜¾ç¤ºç»„ä»¶"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setReadOnly(True)
        self.setFont(QFont("Consolas", 9))
        
        # è®¾ç½®æ·±è‰²ä¸»é¢˜
        palette = self.palette()
        palette.setColor(QPalette.Base, QColor(30, 30, 30))
        palette.setColor(QPalette.Text, QColor(220, 220, 220))
        self.setPalette(palette)


class FileSelectorWidget(QWidget):
    """æ–‡ä»¶é€‰æ‹©ç»„ä»¶"""
    def __init__(self, label_text, file_types="æ‰€æœ‰æ–‡ä»¶ (*.*)", is_directory=False, parent=None):
        super().__init__(parent)
        self.is_directory = is_directory
        self.file_types = file_types
        
        layout = QHBoxLayout()
        layout.setContentsMargins(0, 0, 0, 0)
        
        self.label = QLabel(label_text)
        self.entry = QLineEdit()
        self.browse_btn = QPushButton("æµè§ˆ")
        self.browse_btn.clicked.connect(self.browse)
        
        layout.addWidget(self.label)
        layout.addWidget(self.entry)
        layout.addWidget(self.browse_btn)
        
        self.setLayout(layout)
    
    def browse(self):
        if self.is_directory:
            directory = QFileDialog.getExistingDirectory(self, "é€‰æ‹©ç›®å½•", self.entry.text())
            if directory:
                self.entry.setText(directory)
        else:
            file_path, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©æ–‡ä»¶", self.entry.text(), self.file_types)
            if file_path:
                self.entry.setText(file_path)
    
    def get_path(self):
        return self.entry.text()
    
    def set_path(self, path):
        self.entry.setText(path)


class ClassificationThread(QThread):
    """åˆ†ç±»çº¿ç¨‹"""
    progress_signal = pyqtSignal(int)
    log_signal = pyqtSignal(str)
    status_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(bool, str, list, object, object, object, object)
    
    def __init__(self, backend, config, selected_classifiers):
        super().__init__()
        self.backend = backend
        self.config = config
        self.selected_classifiers = selected_classifiers
        self.is_running = True
    
    def run(self):
        try:
            # å®Œæ•´çš„åˆ†ç±»æµç¨‹
            out_dir = Path(self.config['output_dir'])
            out_dir.mkdir(exist_ok=True)
            
            self.log_signal.emit("="*80)
            self.log_signal.emit("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v5.1 - ä¸“ä¸šç‰ˆ (PyQt5)")
            self.log_signal.emit("="*80)
            self.log_signal.emit(f"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(self.selected_classifiers)} ä¸ª")
            self.log_signal.emit(f"èƒŒæ™¯å€¼: {self.config['background_value']}")
            self.log_signal.emit("")
            
            # è¯»å–å½±åƒ
            self.log_signal.emit("ğŸ“ è¯»å–å½±åƒ...")
            self.status_signal.emit("è¯»å–å½±åƒ...")
            img = rxr.open_rasterio(self.config['image_path'], masked=True)
            n_pixels = img.shape[1] * img.shape[2]
            self.log_signal.emit(f"   å°ºå¯¸: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ")
            
            # è·å–åƒå…ƒå¤§å°
            transform = img.rio.transform()
            pixel_size_x = transform[0]  # Xæ–¹å‘åˆ†è¾¨ç‡
            pixel_size_y = abs(transform[4])  # Yæ–¹å‘åˆ†è¾¨ç‡
            self.log_signal.emit(f"   åˆ†è¾¨ç‡: {pixel_size_x:.2f} Ã— {pixel_size_y:.2f} ç±³")
            
            # è·å–æ³¢æ®µåç§°
            band_names = [f"æ³¢æ®µ_{i+1}" for i in range(img.shape[0])]
            if hasattr(img, 'long_name') and img.long_name:
                band_names = img.long_name
            elif hasattr(img, 'band') and img.band.values is not None:
                band_names = [f"æ³¢æ®µ_{b}" for b in img.band.values]
            
            self.log_signal.emit(f"   æ³¢æ®µæ•°: {len(band_names)}")
            
            if not self.is_running:
                return
            
            # è¯»å–ç±»åˆ«ä¿¡æ¯
            self.log_signal.emit("ğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...")
            class_names, class_colors, _ = self.backend.get_class_info_from_shp(
                self.config['train_shp_path'], 
                self.config['class_attr'], 
                self.config['name_attr']
            )
            self.log_signal.emit(f"   ç±»åˆ«: {list(class_names.values())}")
            
            # æå–è®­ç»ƒæ ·æœ¬
            self.log_signal.emit("ğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...")
            self.status_signal.emit("å¤„ç†è®­ç»ƒæ ·æœ¬...")
            train_mask = self.backend.rasterize_samples(
                self.config['train_shp_path'], img, self.config['class_attr']
            )
            
            max_samples = self.config['max_samples'] if self.config['enable_sampling'] else None
            
            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(
                img, train_mask, 
                ignore_background=self.config['ignore_background'],
                background_value=self.config['background_value'],
                max_samples=max_samples
            )
            
            self.log_signal.emit(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}")
            if n_nan > 0:
                self.log_signal.emit(f"   â””â”€ ç§»é™¤NaN: {n_nan:,}")
            if n_sampled > 0:
                self.log_signal.emit(f"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}")
            
            if not self.is_running:
                return
            
            # æå–éªŒè¯æ ·æœ¬
            val_exists = os.path.exists(self.config['val_shp_path'])
            X_val, yv_true = None, None
            valid_val = None
            
            if val_exists:
                self.log_signal.emit("âœ… å¤„ç†éªŒè¯æ ·æœ¬...")
                val_mask = self.backend.rasterize_samples(
                    self.config['val_shp_path'], img, self.config['class_attr']
                )
                
                if self.config['ignore_background']:
                    background_mask = self.backend.get_background_mask(
                        img, self.config['background_value']
                    )
                    valid_val = (val_mask > 0) & (~background_mask)
                else:
                    valid_val = val_mask > 0
                
                # æå–éªŒè¯æ ·æœ¬ç‰¹å¾
                data = np.moveaxis(img.values, 0, -1)
                X_val = data[valid_val]
                yv_true = val_mask[valid_val]
                
                # æ¸…ç†NaNå’ŒInf
                nan_mask = np.isnan(X_val).any(axis=1)
                inf_mask = np.isinf(X_val).any(axis=1)
                bad_mask = nan_mask | inf_mask
                X_val = X_val[~bad_mask]
                yv_true = yv_true[~bad_mask]
                
                self.log_signal.emit(f"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}")
            
            # åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°
            all_classifiers = self.backend.get_all_classifiers(
                self.config['n_estimators'], 
                fast_mode=self.config['fast_mode'],
                n_train_samples=len(y_train)
            )
            
            comparison_results = []
            total_start_time = time.time()
            best_accuracy = 0
            best_clf_code = None
            best_y_true = None
            best_y_pred = None
            best_class_names = class_names
            best_class_colors = class_colors
            best_result_path = None
            
            # å­˜å‚¨ç‰¹å¾é‡è¦æ€§æ•°æ®å’ŒROCæ•°æ®
            feature_importance_data = {}
            roc_data_dict = {}
            
            for i, clf_code in enumerate(self.selected_classifiers):
                if not self.is_running:
                    break
                
                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]
                
                self.log_signal.emit(f"\n{'='*80}")
                self.log_signal.emit(f"[{i+1}/{len(self.selected_classifiers)}] {clf_name}")
                self.log_signal.emit(f"{'='*80}")
                
                self.status_signal.emit(f"[{i+1}/{len(self.selected_classifiers)}] è®­ç»ƒ {clf_name}...")
                
                clf_dir = out_dir / clf_code
                clf_dir.mkdir(exist_ok=True)
                
                try:
                    # æ•°æ®é¢„å¤„ç†
                    label_encoder = None
                    scaler = None
                    X_train_use = X_train.copy()
                    y_train_use = y_train.copy()
                    
                    if needs_encoding:
                        self.log_signal.emit("   ğŸ”„ æ ‡ç­¾ç¼–ç ...")
                        label_encoder = LabelEncoder()
                        y_train_use = label_encoder.fit_transform(y_train)
                    
                    if needs_scaling:
                        self.log_signal.emit("   ğŸ“ ç‰¹å¾ç¼©æ”¾...")
                        scaler = StandardScaler()
                        X_train_use = scaler.fit_transform(X_train_use)
                    
                    # è¶…å‚æ•°ä¼˜åŒ–
                    best_params = {}
                    optimization_score = 0
                    
                    if self.config['enable_hyperparameter_optimization']:
                        self.log_signal.emit("   ğŸ¯ è¶…å‚æ•°ä¼˜åŒ–ä¸­...")
                        opt_start = time.time()
                        
                        clf_optimized, best_params, optimization_score = self.backend.optimize_hyperparameters(
                            clf, clf_code, X_train_use, y_train_use,
                            n_iter=self.config['hyperparameter_iterations']
                        )
                        
                        if clf_optimized is not clf:
                            clf = clf_optimized
                            self.log_signal.emit(f"   âœ“ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ: {time.time() - opt_start:.2f}ç§’")
                            self.log_signal.emit(f"   ğŸ“Š ä¼˜åŒ–åå¾—åˆ†: {optimization_score:.4f}")
                            if best_params:
                                self.log_signal.emit(f"   âš™ï¸  æœ€ä½³å‚æ•°: {best_params}")
                        else:
                            self.log_signal.emit("   âš ï¸  è¶…å‚æ•°ä¼˜åŒ–æœªæ”¹å–„æ€§èƒ½ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                    
                    # è®­ç»ƒ
                    self.log_signal.emit("   ğŸ”¨ è®­ç»ƒä¸­...")
                    train_start = time.time()
                    clf.fit(X_train_use, y_train_use)
                    train_time = time.time() - train_start
                    self.log_signal.emit(f"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’")
                    
                    # ä¿å­˜æ¨¡å‹
                    if self.config['enable_model_saving']:
                        model_path = clf_dir / f"{clf_code}_model.pkl"
                        if self.backend.save_model(clf, model_path):
                            self.log_signal.emit(f"   ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path.name}")
                    
                    # è®­ç»ƒé›†ç²¾åº¦
                    y_train_pred = clf.predict(X_train_use)
                    
                    if label_encoder is not None:
                        y_train_pred = label_encoder.inverse_transform(y_train_pred)
                    
                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)
                    self.log_signal.emit(f"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}")
                    
                    # ä¿å­˜è®­ç»ƒé›†æ··æ·†çŸ©é˜µå’ŒæŠ¥å‘Š
                    if HAS_OPENPYXL:
                        self.log_signal.emit("   ğŸ’¾ ä¿å­˜è®­ç»ƒé›†ç»“æœ...")
                        train_classes = sorted(np.unique(y_train))
                        train_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in train_classes]
                        
                        excel_path, img_path = self.backend.save_confusion_matrix(
                            y_train, y_train_pred, train_class_names,
                            clf_dir / f"{clf_code}_train",
                            f"{clf_name} (è®­ç»ƒé›†)"
                        )
                        if excel_path:
                            self.log_signal.emit(f"      âœ“ æ··æ·†çŸ©é˜µ: {excel_path.name}")
                            self.log_signal.emit(f"      âœ“ å›¾ç‰‡: {img_path.name}")
                        
                        excel_path, txt_path = self.backend.save_classification_report(
                            y_train, y_train_pred, train_class_names,
                            clf_dir / f"{clf_code}_train"
                        )
                        if excel_path:
                            self.log_signal.emit(f"      âœ“ åˆ†ç±»æŠ¥å‘Š: {excel_path.name}")
                    
                    # ç‰¹å¾é‡è¦æ€§åˆ†æ
                    importance_data = None
                    if self.config['enable_feature_importance'] and X_val is not None:
                        self.log_signal.emit("   ğŸ“Š åˆ†æç‰¹å¾é‡è¦æ€§...")
                        importance_data = self.backend.analyze_feature_importance(
                            clf, band_names, X_val, yv_true
                        )
                        
                        if importance_data:
                            feature_importance_data[clf_code] = importance_data
                            importance_path = clf_dir / f"{clf_code}_feature_importance.png"
                            saved_path = self.backend.plot_feature_importance(
                                importance_data, band_names, importance_path, clf_name
                            )
                            if saved_path:
                                self.log_signal.emit(f"      âœ“ ç‰¹å¾é‡è¦æ€§å›¾: {saved_path.name}")
                            else:
                                self.log_signal.emit("      âš ï¸  ç‰¹å¾é‡è¦æ€§å›¾ç”Ÿæˆå¤±è´¥")
                        else:
                            self.log_signal.emit("      âš ï¸  ç‰¹å¾é‡è¦æ€§åˆ†æå¤±è´¥")
                    
                    # ROCæ›²çº¿åˆ†æ
                    roc_data = None
                    if self.config['enable_roc_analysis'] and X_val is not None:
                        self.log_signal.emit("   ğŸ“‰ ç»˜åˆ¶ROCæ›²çº¿...")
                        val_classes = sorted(np.unique(yv_true))
                        val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                        
                        roc_path = clf_dir / f"{clf_code}_roc_curve.png"
                        roc_path, auc_data, roc_data = self.backend.plot_roc_curves(
                            clf, X_val, yv_true, class_names, roc_path, clf_name
                        )
                        
                        if roc_path:
                            roc_data_dict[clf_code] = roc_data
                            self.log_signal.emit(f"      âœ“ ROCæ›²çº¿: {roc_path.name}")
                            if auc_data:
                                self.log_signal.emit(f"      âœ“ å¹³å‡AUC: {auc_data['macro_auc']:.4f}")
                        else:
                            self.log_signal.emit("      âš ï¸ ROCæ›²çº¿ç»˜åˆ¶å¤±è´¥")
                    
                    if not self.is_running:
                        break
                    
                    # é¢„æµ‹æ•´å¹…å½±åƒ
                    self.log_signal.emit("   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...")
                    self.status_signal.emit(f"[{i+1}/{len(self.selected_classifiers)}] é¢„æµ‹ {clf_name}...")
                    
                    pred_start = time.time()
                    classified_path = clf_dir / f"classified_{clf_code}.tif"
                    
                    # åå¤„ç†è®¾ç½®
                    postprocessing = self.config['postprocessing_method'] if self.config['enable_postprocessing'] else 'none'
                    
                    # ä¼ é€’è¿è¡ŒçŠ¶æ€ç»™åç«¯
                    self.backend.is_running = self.is_running
                    
                    result_path = self.backend.predict_by_block(
                        clf, img, classified_path, 
                        block_size=self.config['block_size'],
                        ignore_background=self.config['ignore_background'],
                        background_value=self.config['background_value'],
                        progress_callback=lambda p: self.progress_signal.emit(p),
                        label_encoder=label_encoder,
                        scaler=scaler,
                        postprocessing=postprocessing
                    )
                    
                    if result_path and os.path.exists(result_path):
                        pred_time = time.time() - pred_start
                        self.log_signal.emit(f"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’")
                        
                        # è¯»å–åˆ†ç±»ç»“æœè¿›è¡Œé¢ç§¯ç»Ÿè®¡
                        self.log_signal.emit("   ğŸ“Š è®¡ç®—é¢ç§¯ç»Ÿè®¡...")
                        with rxr.open_rasterio(classified_path) as pred_img:
                            pred_arr = pred_img.values.squeeze()
                        
                        # è®¡ç®—é¢ç§¯ç»Ÿè®¡
                        area_stats = self.backend.calculate_area_statistics(
                            pred_arr, pixel_size_x, pixel_size_y,
                            class_names, self.config['background_value']
                        )
                        
                        # ä¿å­˜é¢ç§¯ç»Ÿè®¡
                        if HAS_OPENPYXL:
                            area_excel_path = clf_dir / f"{clf_code}_area_statistics.xlsx"
                            area_stats.to_excel(area_excel_path, index=False, engine='openpyxl')
                            self.log_signal.emit(f"      âœ“ é¢ç§¯ç»Ÿè®¡: {area_excel_path.name}")
                        
                        # æ˜¾ç¤ºé¢ç§¯ç»Ÿè®¡æ‘˜è¦
                        self.log_signal.emit("   é¢ç§¯ç»Ÿè®¡æ‘˜è¦:")
                        for _, row in area_stats.iterrows():
                            if row['ç±»åˆ«åç§°'] == 'æ€»è®¡':
                                self.log_signal.emit(f"      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                                self.log_signal.emit(f"      {row['ç±»åˆ«åç§°']}: {row['é¢ç§¯(kmÂ²)']:.2f} kmÂ²")
                            else:
                                self.log_signal.emit(f"      {row['ç±»åˆ«åç§°']}: {row['é¢ç§¯(kmÂ²)']:.2f} kmÂ² ({row['ç™¾åˆ†æ¯”(%)']:.2f}%)")
                        
                        # éªŒè¯é›†ç²¾åº¦
                        val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan}
                        yv_pred = None
                        
                        if val_exists:
                            yv_pred = pred_arr[valid_val]
                            val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)
                            self.log_signal.emit(f"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}")
                            
                            # ä¿å­˜éªŒè¯é›†æ··æ·†çŸ©é˜µå’ŒæŠ¥å‘Š
                            if HAS_OPENPYXL:
                                self.log_signal.emit("   ğŸ’¾ ä¿å­˜éªŒè¯é›†ç»“æœ...")
                                val_classes = sorted(np.unique(yv_true))
                                val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                                
                                excel_path, img_path = self.backend.save_confusion_matrix(
                                    yv_true, yv_pred, val_class_names,
                                    clf_dir / f"{clf_code}_val",
                                    f"{clf_name} (éªŒè¯é›†)"
                                )
                                if excel_path:
                                    self.log_signal.emit(f"      âœ“ æ··æ·†çŸ©é˜µ: {excel_path.name}")
                                    self.log_signal.emit(f"      âœ“ å›¾ç‰‡: {img_path.name}")
                                
                                excel_path, txt_path = self.backend.save_classification_report(
                                    yv_true, yv_pred, val_class_names,
                                    clf_dir / f"{clf_code}_val"
                                )
                                if excel_path:
                                    self.log_signal.emit(f"      âœ“ åˆ†ç±»æŠ¥å‘Š: {excel_path.name}")
                            
                            # è®°å½•æœ€ä½³åˆ†ç±»å™¨
                            if val_metrics['overall_accuracy'] > best_accuracy:
                                best_accuracy = val_metrics['overall_accuracy']
                                best_clf_code = clf_code
                                best_y_true = yv_true
                                best_y_pred = yv_pred
                                best_result_path = classified_path
                        
                        # è®°å½•ç»“æœ
                        result = {
                            'åˆ†ç±»å™¨ä»£ç ': clf_code,
                            'åˆ†ç±»å™¨åç§°': clf_name,
                            'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],
                            'è®­ç»ƒé›†Kappa': train_metrics['kappa'],
                            'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],
                            'éªŒè¯é›†Kappa': val_metrics['kappa'],
                            'è®­ç»ƒæ—¶é—´(ç§’)': train_time,
                            'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,
                            'è¶…å‚æ•°ä¼˜åŒ–': bool(best_params),
                            'ä¼˜åŒ–å¾—åˆ†': optimization_score,
                        }
                        comparison_results.append(result)
                        
                        self.log_signal.emit(f"   âœ… {clf_name} å®Œæˆ!")
                    else:
                        self.log_signal.emit(f"   âŒ {clf_name} é¢„æµ‹å¤±è´¥æˆ–ç”¨æˆ·å–æ¶ˆ")
                    
                except Exception as e:
                    self.log_signal.emit(f"   âŒ {clf_name} å¤±è´¥: {str(e)}")
                    import traceback
                    self.log_signal.emit(traceback.format_exc())
                    continue
                
                self.progress_signal.emit((i + 1) / len(self.selected_classifiers) * 100)
            
            # ç”ŸæˆæŠ¥å‘Š
            if comparison_results and self.is_running:
                total_time = time.time() - total_start_time
                
                self.log_signal.emit(f"\n{'='*80}")
                self.log_signal.emit("ğŸ“ ç”Ÿæˆæ€»ä½“æŠ¥å‘Š...")
                
                comparison_df = pd.DataFrame(comparison_results)
                
                # å¯¼å‡ºExcel
                if HAS_OPENPYXL:
                    excel_path = out_dir / "classification_comparison.xlsx"
                    comparison_df.to_excel(excel_path, index=False, engine='openpyxl')
                    self.log_signal.emit(f"âœ“ ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_path}")
                
                # æ–‡å­—æŠ¥å‘Š
                with open(out_dir / "comparison_summary.txt", 'w', encoding='utf-8') as f:
                    f.write("é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n")
                    f.write("="*70 + "\n\n")
                    f.write(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"å½±åƒ: {img.shape[1]}Ã—{img.shape[2]}\n")
                    f.write(f"åˆ†è¾¨ç‡: {pixel_size_x:.2f}m Ã— {pixel_size_y:.2f}m\n")
                    f.write(f"è®­ç»ƒæ ·æœ¬: {len(y_train):,}\n")
                    f.write(f"æˆåŠŸ: {len(comparison_results)}/{len(self.selected_classifiers)}\n")
                    f.write(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\n\n")
                    
                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)
                    f.write("éªŒè¯é›†ç²¾åº¦æ’å:\n")
                    f.write("-"*70 + "\n")
                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):
                        f.write(f"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - "
                               f"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}, "
                               f"Kappa: {row['éªŒè¯é›†Kappa']:.4f}\n")
                
                self.log_signal.emit("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
                self.log_signal.emit(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
                
                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]
                self.log_signal.emit(f"\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})")
                
                self.status_signal.emit(f"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']}")
                
                # å‘å°„å®Œæˆä¿¡å·ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„æ•°æ®
                self.finished_signal.emit(
                    True, 
                    f"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\n\nâœ… æˆåŠŸ: {len(comparison_results)}/{len(self.selected_classifiers)}\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})",
                    comparison_results,
                    (best_y_true, best_y_pred, best_class_names) if best_y_true is not None else None,
                    feature_importance_data,
                    roc_data_dict,
                    (self.config['image_path'], best_result_path, best_class_names, best_class_colors) if best_result_path else None
                )
            else:
                self.finished_signal.emit(False, "åˆ†ç±»ä»»åŠ¡è¢«å–æ¶ˆæˆ–æ²¡æœ‰æˆåŠŸå®Œæˆ", [], None, {}, {}, None)
                
        except Exception as e:
            self.log_signal.emit(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            self.log_signal.emit(traceback.format_exc())
            self.finished_signal.emit(False, f"å‘ç”Ÿé”™è¯¯:\n{str(e)}", [], None, {}, {}, None)
    
    def stop(self):
        self.is_running = False


# ==================== ä¸»çª—å£ ====================

class ClassificationGUI(QMainWindow):
    """é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢ï¼ˆPyQt5ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        super().__init__()
        self.backend = ClassificationBackend()
        self.init_data()  # å…ˆåˆå§‹åŒ–æ•°æ®
        self.init_ui()    # å†åˆå§‹åŒ–ç•Œé¢
    
    def init_data(self):
        """åˆå§‹åŒ–æ•°æ®"""
        self.image_path = ""
        self.train_shp_path = ""
        self.val_shp_path = ""
        self.output_dir = str(Path("./results_gui"))
        
        self.train_fields = []
        self.class_attr = ""
        self.name_attr = ""
        
        # åˆ†ç±»å™¨é€‰æ‹©
        self.classifier_vars = {}
        all_classifiers = self.backend.get_all_classifiers()
        for code in all_classifiers.keys():
            self.classifier_vars[code] = False
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.classification_thread = None
        
        # å­˜å‚¨ç»“æœæ•°æ®
        self.comparison_results = []
        self.current_confusion_matrix = None
        self.current_y_true = None
        self.current_y_pred = None
        self.class_names_dict = {}
        self.class_colors_dict = {}
        self.best_result_path = None
        
        # å­˜å‚¨å›¾è¡¨æ•°æ®
        self.feature_importance_data = {}
        self.roc_data_dict = {}
    
    def init_ui(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        self.setWindowTitle("é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ (PyQt5)")
        self.setGeometry(100, 50, 1600, 900)
        
        # è®¾ç½®çª—å£æœ€å¤§åŒ–
        self.showMaximized()
        
        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶å’Œä¸»å¸ƒå±€
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        main_layout = QHBoxLayout(central_widget)
        
        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = QSplitter(Qt.Horizontal)
        main_layout.addWidget(splitter)
        
        # å·¦ä¾§é¢æ¿ - å‚æ•°è®¾ç½®
        left_panel = self.create_left_panel()
        splitter.addWidget(left_panel)
        
        # å³ä¾§é¢æ¿ - ç»“æœæ˜¾ç¤º
        right_panel = self.create_right_panel()
        splitter.addWidget(right_panel)
        
        # è®¾ç½®åˆ†å‰²æ¯”ä¾‹ - å³ä¾§æ›´å¤§ï¼Œé€‚åˆå›¾è¡¨æ˜¾ç¤º
        splitter.setSizes([400, 1200])  # å·¦ä¾§400ï¼Œå³ä¾§1200
        
        # çŠ¶æ€æ 
        self.status_bar = self.statusBar()
        self.status_bar.showMessage("å°±ç»ª")
    
    def create_left_panel(self):
        """åˆ›å»ºå·¦ä¾§å‚æ•°é¢æ¿"""
        scroll_area = QScrollArea()
        scroll_widget = QWidget()
        scroll_layout = QVBoxLayout(scroll_widget)
        
        # 1. æ•°æ®æ–‡ä»¶
        file_group = QGroupBox("ğŸ“ æ•°æ®æ–‡ä»¶")
        file_layout = QVBoxLayout()
        
        self.image_selector = FileSelectorWidget("å½±åƒæ–‡ä»¶:", "GeoTIFF (*.tif *.tiff)")
        self.train_shp_selector = FileSelectorWidget("è®­ç»ƒæ ·æœ¬:", "Shapefile (*.shp)")
        self.val_shp_selector = FileSelectorWidget("éªŒè¯æ ·æœ¬:", "Shapefile (*.shp)")
        self.output_selector = FileSelectorWidget("è¾“å‡ºç›®å½•:", is_directory=True)
        self.output_selector.set_path(self.output_dir)  # ä½¿ç”¨set_pathæ–¹æ³•
        
        file_layout.addWidget(self.image_selector)
        file_layout.addWidget(self.train_shp_selector)
        file_layout.addWidget(self.val_shp_selector)
        file_layout.addWidget(self.output_selector)
        
        file_group.setLayout(file_layout)
        scroll_layout.addWidget(file_group)
        
        # 2. å­—æ®µé…ç½®
        field_group = QGroupBox("ğŸ·ï¸ å­—æ®µé…ç½®")
        field_layout = QGridLayout()
        
        field_layout.addWidget(QLabel("ç±»åˆ«ç¼–å·å­—æ®µ:"), 0, 0)
        self.class_attr_combo = QComboBox()
        field_layout.addWidget(self.class_attr_combo, 0, 1)
        
        field_layout.addWidget(QLabel("ç±»åˆ«åç§°å­—æ®µ:"), 1, 0)
        self.name_attr_combo = QComboBox()
        field_layout.addWidget(self.name_attr_combo, 1, 1)
        
        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°å­—æ®µåˆ—è¡¨")
        refresh_btn.clicked.connect(self.refresh_fields)
        field_layout.addWidget(refresh_btn, 0, 2, 2, 1)
        
        field_group.setLayout(field_layout)
        scroll_layout.addWidget(field_group)
        
        # 3. èƒŒæ™¯å€¼è®¾ç½®
        bg_group = QGroupBox("ğŸ¨ èƒŒæ™¯å€¼è®¾ç½®")
        bg_layout = QGridLayout()
        
        self.ignore_background = QCheckBox("å¿½ç•¥èƒŒæ™¯å€¼")
        self.ignore_background.setChecked(True)
        bg_layout.addWidget(self.ignore_background, 0, 0)
        
        bg_layout.addWidget(QLabel("èƒŒæ™¯å€¼:"), 1, 0)
        self.background_value = QSpinBox()
        self.background_value.setRange(-9999, 9999)
        self.background_value.setValue(0)
        bg_layout.addWidget(self.background_value, 1, 1)
        
        bg_layout.addWidget(QLabel("(é»˜è®¤0, å¸¸è§: -9999, 255)"), 1, 2)
        
        bg_group.setLayout(bg_layout)
        scroll_layout.addWidget(bg_group)
        
        # 4. åˆ†ç±»å‚æ•°
        param_group = QGroupBox("âš™ï¸ åˆ†ç±»å‚æ•°")
        param_layout = QGridLayout()
        
        param_layout.addWidget(QLabel("æ ‘æ¨¡å‹æ•°é‡:"), 0, 0)
        self.n_estimators = QSpinBox()
        self.n_estimators.setRange(10, 500)
        self.n_estimators.setValue(100)
        param_layout.addWidget(self.n_estimators, 0, 1)
        
        param_layout.addWidget(QLabel("åˆ†å—å¤§å°:"), 1, 0)
        self.block_size = QSpinBox()
        self.block_size.setRange(256, 2048)
        self.block_size.setSingleStep(256)
        self.block_size.setValue(512)
        param_layout.addWidget(self.block_size, 1, 1)
        
        param_group.setLayout(param_layout)
        scroll_layout.addWidget(param_group)
        
        # 5. æ€§èƒ½ä¼˜åŒ–
        opt_group = QGroupBox("âš¡ æ€§èƒ½ä¼˜åŒ–")
        opt_layout = QVBoxLayout()
        
        sample_layout = QHBoxLayout()
        self.enable_sampling = QCheckBox("å¯ç”¨é‡‡æ ·")
        self.enable_sampling.setChecked(True)
        self.enable_sampling.toggled.connect(self.toggle_sampling)
        sample_layout.addWidget(self.enable_sampling)
        
        sample_layout.addWidget(QLabel("æœ€å¤§æ ·æœ¬æ•°:"))
        self.max_samples = QSpinBox()
        self.max_samples.setRange(10000, 200000)
        self.max_samples.setSingleStep(10000)
        self.max_samples.setValue(50000)
        sample_layout.addWidget(self.max_samples)
        
        opt_layout.addLayout(sample_layout)
        
        self.fast_mode = QCheckBox("å¿«é€Ÿæ¨¡å¼")
        opt_layout.addWidget(self.fast_mode)
        
        opt_group.setLayout(opt_layout)
        scroll_layout.addWidget(opt_group)
        
        # 6. é«˜çº§åŠŸèƒ½
        advanced_group = QGroupBox("ğŸš€ é«˜çº§åŠŸèƒ½")
        advanced_layout = QVBoxLayout()
        
        # è¶…å‚æ•°ä¼˜åŒ–
        hyper_layout = QHBoxLayout()
        self.enable_hyperparameter_optimization = QCheckBox("è¶…å‚æ•°ä¼˜åŒ–")
        hyper_layout.addWidget(self.enable_hyperparameter_optimization)
        
        hyper_layout.addWidget(QLabel("æ–¹æ³•:"))
        self.hyperparameter_optimization_method = QComboBox()
        self.hyperparameter_optimization_method.addItems(["random", "grid"])
        hyper_layout.addWidget(self.hyperparameter_optimization_method)
        
        hyper_layout.addWidget(QLabel("è¿­ä»£æ¬¡æ•°:"))
        self.hyperparameter_iterations = QSpinBox()
        self.hyperparameter_iterations.setRange(5, 100)
        self.hyperparameter_iterations.setValue(20)
        hyper_layout.addWidget(self.hyperparameter_iterations)
        
        advanced_layout.addLayout(hyper_layout)
        
        # åå¤„ç†
        post_layout = QHBoxLayout()
        self.enable_postprocessing = QCheckBox("åå¤„ç†æ»¤æ³¢")
        self.enable_postprocessing.setChecked(True)
        post_layout.addWidget(self.enable_postprocessing)
        
        post_layout.addWidget(QLabel("æ–¹æ³•:"))
        self.postprocessing_method = QComboBox()
        self.postprocessing_method.addItems(["none", "majority", "median", "opening", "closing"])
        post_layout.addWidget(self.postprocessing_method)
        
        post_layout.addWidget(QLabel("çª—å£å¤§å°:"))
        self.postprocessing_size = QSpinBox()
        self.postprocessing_size.setRange(3, 9)
        self.postprocessing_size.setSingleStep(2)
        self.postprocessing_size.setValue(3)
        post_layout.addWidget(self.postprocessing_size)
        
        advanced_layout.addLayout(post_layout)
        
        # åˆ†æé€‰é¡¹
        analysis_layout = QHBoxLayout()
        self.enable_feature_importance = QCheckBox("ç‰¹å¾é‡è¦æ€§åˆ†æ")
        self.enable_feature_importance.setChecked(True)
        analysis_layout.addWidget(self.enable_feature_importance)
        
        self.enable_roc_analysis = QCheckBox("ROCæ›²çº¿åˆ†æ")
        self.enable_roc_analysis.setChecked(True)
        analysis_layout.addWidget(self.enable_roc_analysis)
        
        self.enable_model_saving = QCheckBox("ä¿å­˜æ¨¡å‹")
        self.enable_model_saving.setChecked(True)
        analysis_layout.addWidget(self.enable_model_saving)
        
        advanced_layout.addLayout(analysis_layout)
        
        advanced_group.setLayout(advanced_layout)
        scroll_layout.addWidget(advanced_group)
        
        # 7. åˆ†ç±»å™¨é€‰æ‹©
        clf_group = QGroupBox("ğŸ¤– åˆ†ç±»å™¨é€‰æ‹©")
        clf_layout = QVBoxLayout()
        
        # å¿«æ·æŒ‰é’®
        btn_layout = QHBoxLayout()
        select_all_btn = QPushButton("å…¨é€‰")
        select_all_btn.clicked.connect(self.select_all_classifiers)
        btn_layout.addWidget(select_all_btn)
        
        deselect_all_btn = QPushButton("å…¨ä¸é€‰")
        deselect_all_btn.clicked.connect(self.deselect_all_classifiers)
        btn_layout.addWidget(deselect_all_btn)
        
        recommended_btn = QPushButton("âœ“æ¨è")
        recommended_btn.clicked.connect(self.select_recommended)
        btn_layout.addWidget(recommended_btn)
        
        fast_btn = QPushButton("âš¡å¿«é€Ÿ")
        fast_btn.clicked.connect(self.select_fast)
        btn_layout.addWidget(fast_btn)
        
        clf_layout.addLayout(btn_layout)
        
        # åˆ†ç±»å™¨å¤é€‰æ¡†
        clf_scroll = QScrollArea()
        clf_scroll_widget = QWidget()
        clf_scroll_layout = QGridLayout(clf_scroll_widget)
        
        all_classifiers = self.backend.get_all_classifiers()
        
        # SVMç»„
        row = 0
        clf_scroll_layout.addWidget(QLabel("SVM:"), row, 0)
        row += 1
        
        svm_codes = ["svm_linear", "linear_svc", "sgd_svm", "nystroem_svm", 
                     "rbf_sampler_svm", "svm_rbf"]
        for code in svm_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                checkbox = QCheckBox(name)
                checkbox.setChecked(False)
                self.classifier_vars[code] = checkbox
                clf_scroll_layout.addWidget(checkbox, row, 0)
                row += 1
        
        # æ ‘æ¨¡å‹
        clf_scroll_layout.addWidget(QLabel("æ ‘æ¨¡å‹:"), row, 0)
        row += 1
        
        tree_codes = ["rf", "et", "dt", "xgb", "lgb", "gb", "ada"]
        for code in tree_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                checkbox = QCheckBox(name)
                checkbox.setChecked(False)
                self.classifier_vars[code] = checkbox
                clf_scroll_layout.addWidget(checkbox, row, 0)
                row += 1
        
        # å…¶ä»–
        clf_scroll_layout.addWidget(QLabel("å…¶ä»–:"), row, 0)
        row += 1
        
        other_codes = ["knn", "nb", "lr", "mlp"]
        for code in other_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                checkbox = QCheckBox(name)
                checkbox.setChecked(False)
                self.classifier_vars[code] = checkbox
                clf_scroll_layout.addWidget(checkbox, row, 0)
                row += 1
        
        clf_scroll.setWidget(clf_scroll_widget)
        clf_scroll.setFixedHeight(200)
        clf_layout.addWidget(clf_scroll)
        
        clf_group.setLayout(clf_layout)
        scroll_layout.addWidget(clf_group)
        
        # 8. è¿è¡Œæ§åˆ¶
        control_group = QGroupBox("ğŸ® è¿è¡Œæ§åˆ¶")
        control_layout = QVBoxLayout()
        
        # æ§åˆ¶æŒ‰é’®
        btn_control_layout = QHBoxLayout()
        self.start_btn = QPushButton("â–¶ å¼€å§‹åˆ†ç±»")
        self.start_btn.clicked.connect(self.start_classification)
        btn_control_layout.addWidget(self.start_btn)
        
        self.stop_btn = QPushButton("â¸ åœæ­¢")
        self.stop_btn.clicked.connect(self.stop_classification)
        self.stop_btn.setEnabled(False)
        btn_control_layout.addWidget(self.stop_btn)
        
        save_config_btn = QPushButton("ğŸ’¾ ä¿å­˜é…ç½®")
        save_config_btn.clicked.connect(self.save_config)
        btn_control_layout.addWidget(save_config_btn)
        
        load_config_btn = QPushButton("ğŸ“‚ åŠ è½½é…ç½®")
        load_config_btn.clicked.connect(self.load_config)
        btn_control_layout.addWidget(load_config_btn)
        
        open_result_btn = QPushButton("ğŸ“ æ‰“å¼€ç»“æœ")
        open_result_btn.clicked.connect(self.open_result_dir)
        btn_control_layout.addWidget(open_result_btn)
        
        control_layout.addLayout(btn_control_layout)
        
        # è¿›åº¦æ¡
        control_layout.addWidget(QLabel("è¿›åº¦:"))
        self.progress_bar = QProgressBar()
        control_layout.addWidget(self.progress_bar)
        
        # çŠ¶æ€
        self.status_label = QLabel("å°±ç»ª")
        control_layout.addWidget(self.status_label)
        
        control_group.setLayout(control_layout)
        scroll_layout.addWidget(control_group)
        
        scroll_area.setWidget(scroll_widget)
        return scroll_area
    
    def create_right_panel(self):
        """åˆ›å»ºå³ä¾§ç»“æœæ˜¾ç¤ºé¢æ¿"""
        self.tab_widget = QTabWidget()
        
        # æ ‡ç­¾é¡µ1ï¼šè¿è¡Œæ—¥å¿—
        self.log_widget = LogWidget()
        self.tab_widget.addTab(self.log_widget, "ğŸ“ è¿è¡Œæ—¥å¿—")
        
        # æ ‡ç­¾é¡µ2ï¼šç²¾åº¦å¯¹æ¯”
        self.accuracy_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.accuracy_widget, "ğŸ“Š ç²¾åº¦å¯¹æ¯”")
        
        # æ ‡ç­¾é¡µ3ï¼šæ··æ·†çŸ©é˜µ
        self.cm_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.cm_widget, "ğŸ”¥ æ··æ·†çŸ©é˜µ")
        
        # æ ‡ç­¾é¡µ4ï¼šæ—¶é—´å¯¹æ¯”
        self.time_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.time_widget, "â±ï¸ æ—¶é—´å¯¹æ¯”")
        
        # æ ‡ç­¾é¡µ5ï¼šåˆ†ç±»ç»“æœé¢„è§ˆ
        self.result_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.result_widget, "ğŸ—ºï¸ ç»“æœé¢„è§ˆ")
        
        # æ ‡ç­¾é¡µ6ï¼šç‰¹å¾é‡è¦æ€§
        self.feature_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.feature_widget, "ğŸ“ˆ ç‰¹å¾é‡è¦æ€§")
        
        # æ ‡ç­¾é¡µ7ï¼šROCæ›²çº¿
        self.roc_widget = MatplotlibWidget()
        self.tab_widget.addTab(self.roc_widget, "ğŸ“‰ ROCæ›²çº¿")
        
        return self.tab_widget
    
    def toggle_sampling(self):
        """åˆ‡æ¢é‡‡æ ·çŠ¶æ€"""
        self.max_samples.setEnabled(self.enable_sampling.isChecked())
    
    def refresh_fields(self):
        """åˆ·æ–°å­—æ®µåˆ—è¡¨"""
        train_shp = self.train_shp_selector.get_path()
        if not train_shp or not os.path.exists(train_shp):
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è®­ç»ƒæ ·æœ¬æ–‡ä»¶ï¼")
            return
        
        fields = self.backend.get_shapefile_fields(train_shp)
        if fields:
            fields = [f for f in fields if f.lower() != 'geometry']
            
            self.class_attr_combo.clear()
            self.name_attr_combo.clear()
            
            self.class_attr_combo.addItems(fields)
            self.name_attr_combo.addItems(fields)
            
            if 'class' in fields:
                self.class_attr_combo.setCurrentText('class')
            elif 'Class' in fields:
                self.class_attr_combo.setCurrentText('Class')
            elif fields:
                self.class_attr_combo.setCurrentText(fields[0])
            
            if 'name' in fields:
                self.name_attr_combo.setCurrentText('name')
            elif 'Name' in fields:
                self.name_attr_combo.setCurrentText('Name')
            elif len(fields) > 1:
                self.name_attr_combo.setCurrentText(fields[1])
            elif fields:
                self.name_attr_combo.setCurrentText(fields[0])
            
            QMessageBox.information(self, "æˆåŠŸ", f"å·²åŠ è½½ {len(fields)} ä¸ªå­—æ®µ")
        else:
            QMessageBox.critical(self, "é”™è¯¯", "æ— æ³•è¯»å–å­—æ®µåˆ—è¡¨ï¼")
    
    def select_all_classifiers(self):
        """å…¨é€‰åˆ†ç±»å™¨"""
        for checkbox in self.classifier_vars.values():
            checkbox.setChecked(True)
    
    def deselect_all_classifiers(self):
        """å…¨ä¸é€‰åˆ†ç±»å™¨"""
        for checkbox in self.classifier_vars.values():
            checkbox.setChecked(False)
    
    def select_recommended(self):
        """é€‰æ‹©æ¨èåˆ†ç±»å™¨"""
        recommended = ["rf", "xgb", "et", "lgb", "linear_svc", "nystroem_svm"]
        for code, checkbox in self.classifier_vars.items():
            checkbox.setChecked(code in recommended)
    
    def select_fast(self):
        """é€‰æ‹©å¿«é€Ÿåˆ†ç±»å™¨"""
        fast = ["rf", "et", "dt", "xgb", "lgb", "nb", "lr", "sgd_svm", "linear_svc"]
        for code, checkbox in self.classifier_vars.items():
            checkbox.setChecked(code in fast)
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        config = {
            'image_path': self.image_selector.get_path(),
            'train_shp_path': self.train_shp_selector.get_path(),
            'val_shp_path': self.val_shp_selector.get_path(),
            'output_dir': self.output_selector.get_path(),
            'class_attr': self.class_attr_combo.currentText(),
            'name_attr': self.name_attr_combo.currentText(),
            'background_value': self.background_value.value(),
            'ignore_background': self.ignore_background.isChecked(),
            'n_estimators': self.n_estimators.value(),
            'block_size': self.block_size.value(),
            'enable_sampling': self.enable_sampling.isChecked(),
            'max_samples': self.max_samples.value(),
            'fast_mode': self.fast_mode.isChecked(),
            'enable_hyperparameter_optimization': self.enable_hyperparameter_optimization.isChecked(),
            'hyperparameter_optimization_method': self.hyperparameter_optimization_method.currentText(),
            'hyperparameter_iterations': self.hyperparameter_iterations.value(),
            'enable_postprocessing': self.enable_postprocessing.isChecked(),
            'postprocessing_method': self.postprocessing_method.currentText(),
            'postprocessing_size': self.postprocessing_size.value(),
            'enable_feature_importance': self.enable_feature_importance.isChecked(),
            'enable_roc_analysis': self.enable_roc_analysis.isChecked(),
            'enable_model_saving': self.enable_model_saving.isChecked(),
            'selected_classifiers': {code: checkbox.isChecked() for code, checkbox in self.classifier_vars.items()},
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        filename, _ = QFileDialog.getSaveFileName(self, "ä¿å­˜é…ç½®", "", "JSONæ–‡ä»¶ (*.json)")
        if filename:
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                QMessageBox.information(self, "æˆåŠŸ", f"é…ç½®å·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
    
    def load_config(self):
        """åŠ è½½é…ç½®"""
        filename, _ = QFileDialog.getOpenFileName(self, "åŠ è½½é…ç½®", "", "JSONæ–‡ä»¶ (*.json)")
        if filename:
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                # æ¢å¤é…ç½®
                self.image_selector.set_path(config.get('image_path', ''))
                self.train_shp_selector.set_path(config.get('train_shp_path', ''))
                self.val_shp_selector.set_path(config.get('val_shp_path', ''))
                self.output_selector.set_path(config.get('output_dir', './results_gui'))
                self.class_attr_combo.setCurrentText(config.get('class_attr', ''))
                self.name_attr_combo.setCurrentText(config.get('name_attr', ''))
                self.background_value.setValue(config.get('background_value', 0))
                self.ignore_background.setChecked(config.get('ignore_background', True))
                self.n_estimators.setValue(config.get('n_estimators', 100))
                self.block_size.setValue(config.get('block_size', 512))
                self.enable_sampling.setChecked(config.get('enable_sampling', True))
                self.max_samples.setValue(config.get('max_samples', 50000))
                self.fast_mode.setChecked(config.get('fast_mode', False))
                
                # æ–°åŠŸèƒ½é…ç½®
                self.enable_hyperparameter_optimization.setChecked(config.get('enable_hyperparameter_optimization', False))
                self.hyperparameter_optimization_method.setCurrentText(config.get('hyperparameter_optimization_method', 'random'))
                self.hyperparameter_iterations.setValue(config.get('hyperparameter_iterations', 20))
                self.enable_postprocessing.setChecked(config.get('enable_postprocessing', True))
                self.postprocessing_method.setCurrentText(config.get('postprocessing_method', 'majority'))
                self.postprocessing_size.setValue(config.get('postprocessing_size', 3))
                self.enable_feature_importance.setChecked(config.get('enable_feature_importance', True))
                self.enable_roc_analysis.setChecked(config.get('enable_roc_analysis', True))
                self.enable_model_saving.setChecked(config.get('enable_model_saving', True))
                
                # åˆ†ç±»å™¨é€‰æ‹©
                selected_classifiers = config.get('selected_classifiers', {})
                for code, checkbox in self.classifier_vars.items():
                    checkbox.setChecked(selected_classifiers.get(code, False))
                
                QMessageBox.information(self, "æˆåŠŸ", f"é…ç½®å·²ä» {filename} åŠ è½½")
                
            except Exception as e:
                QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
    
    def log(self, message):
        """æ·»åŠ æ—¥å¿—"""
        self.log_widget.append(message)
    
    def update_accuracy_plot(self, comparison_results):
        """æ›´æ–°ç²¾åº¦å¯¹æ¯”å›¾"""
        if not comparison_results:
            return
        
        self.accuracy_widget.clear()
        ax = self.accuracy_widget.axes
        
        df = pd.DataFrame(comparison_results)
        
        # åˆ›å»ºå­å›¾
        ax1 = self.accuracy_widget.figure.add_subplot(121)
        ax2 = self.accuracy_widget.figure.add_subplot(122)
        
        # ç²¾åº¦å¯¹æ¯”
        x = np.arange(len(df))
        width = 0.35
        
        ax1.bar(x - width/2, df['è®­ç»ƒé›†ç²¾åº¦'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax1.bar(x + width/2, df['éªŒè¯é›†ç²¾åº¦'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax1.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax1.set_ylabel('ç²¾åº¦', fontsize=11)
        ax1.set_title('æ€»ä½“ç²¾åº¦å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        ax1.set_ylim([0, 1.05])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (train_acc, val_acc) in enumerate(zip(df['è®­ç»ƒé›†ç²¾åº¦'], df['éªŒè¯é›†ç²¾åº¦'])):
            ax1.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
            ax1.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
        
        # Kappaå¯¹æ¯”
        ax2.bar(x - width/2, df['è®­ç»ƒé›†Kappa'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax2.bar(x + width/2, df['éªŒè¯é›†Kappa'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax2.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax2.set_ylabel('Kappaç³»æ•°', fontsize=11)
        ax2.set_title('Kappaç³»æ•°å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim([0, 1.05])
        
        self.accuracy_widget.figure.tight_layout()
        self.accuracy_widget.canvas.draw()
    
    def update_confusion_matrix(self, y_true, y_pred, class_names):
        """æ›´æ–°æ··æ·†çŸ©é˜µæ˜¾ç¤º"""
        self.cm_widget.clear()
        ax = self.cm_widget.axes
        
        cm = confusion_matrix(y_true, y_pred)
        
        # ç»˜åˆ¶çƒ­å›¾
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=class_names, yticklabels=class_names,
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)
        ax.set_title('æœ€ä½³åˆ†ç±»å™¨æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        
        self.cm_widget.figure.tight_layout()
        self.cm_widget.canvas.draw()
    
    def update_time_plot(self, comparison_results):
        """æ›´æ–°æ—¶é—´å¯¹æ¯”å›¾"""
        if not comparison_results:
            return
        
        self.time_widget.clear()
        ax = self.time_widget.axes
        
        df = pd.DataFrame(comparison_results)
        
        x = np.arange(len(df))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, df['è®­ç»ƒæ—¶é—´(ç§’)'], width, label='è®­ç»ƒæ—¶é—´', 
                      alpha=0.8, color='lightgreen')
        bars2 = ax.bar(x + width/2, df['é¢„æµ‹æ—¶é—´(ç§’)'], width, label='é¢„æµ‹æ—¶é—´', 
                      alpha=0.8, color='lightcoral')
        
        ax.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=11)
        ax.set_title('è®­ç»ƒå’Œé¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}s', ha='center', va='bottom', fontsize=8)
        
        self.time_widget.figure.tight_layout()
        self.time_widget.canvas.draw()
    
    def update_feature_importance_plot(self, feature_importance_data, band_names):
        """æ›´æ–°ç‰¹å¾é‡è¦æ€§å›¾"""
        if not feature_importance_data:
            # ç»˜åˆ¶ç©ºå›¾è¡¨
            self.feature_widget.clear()
            ax = self.feature_widget.axes
            ax.text(0.5, 0.5, 'æ— ç‰¹å¾é‡è¦æ€§æ•°æ®', ha='center', va='center', 
                    transform=ax.transAxes, fontsize=14)
            ax.set_title('ç‰¹å¾é‡è¦æ€§åˆ†æ')
            ax.axis('off')
            self.feature_widget.canvas.draw()
            return
        
        self.feature_widget.clear()
        ax = self.feature_widget.axes
        
        # åªæ˜¾ç¤ºæœ€ä½³åˆ†ç±»å™¨çš„ç‰¹å¾é‡è¦æ€§
        best_clf_code = None
        if self.comparison_results:
            df = pd.DataFrame(self.comparison_results)
            best_idx = df['éªŒè¯é›†ç²¾åº¦'].idxmax()
            best_clf_code = df.loc[best_idx, 'åˆ†ç±»å™¨ä»£ç ']
            clf_name = df.loc[best_idx, 'åˆ†ç±»å™¨åç§°']
        
        if best_clf_code and best_clf_code in feature_importance_data:
            importance_data = feature_importance_data[best_clf_code]
            
            indices = importance_data['indices']
            importances = importance_data['importances']
            
            if len(importances) == 0:
                ax.text(0.5, 0.5, 'ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©º', ha='center', va='center', 
                        transform=ax.transAxes, fontsize=14)
                ax.set_title(f'{clf_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ')
                ax.axis('off')
            else:
                # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
                valid_indices = indices[indices < len(importances)]
                if len(valid_indices) == 0:
                    valid_indices = np.arange(len(importances))
                
                sorted_importances = importances[valid_indices]
                
                # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‰¹å¾åç§°
                if len(band_names) < len(sorted_importances):
                    # è¡¥å……ç‰¹å¾åç§°
                    extra_features = len(sorted_importances) - len(band_names)
                    band_names.extend([f"ç‰¹å¾_{i+1}" for i in range(len(band_names), len(band_names) + extra_features)])
                
                features = [band_names[i] for i in valid_indices if i < len(band_names)]
                
                y_pos = np.arange(len(features))
                
                # å¤„ç†æ ‡å‡†å·®
                if 'std' in importance_data and importance_data['std'] is not None:
                    std = importance_data['std']
                    if len(std) == len(importances):
                        sorted_std = std[valid_indices]
                        ax.barh(y_pos, sorted_importances, xerr=sorted_std, 
                            align='center', alpha=0.7, color='steelblue')
                    else:
                        ax.barh(y_pos, sorted_importances, align='center', 
                            alpha=0.7, color='steelblue')
                else:
                    ax.barh(y_pos, sorted_importances, align='center', 
                        alpha=0.7, color='steelblue')
                
                ax.set_yticks(y_pos)
                ax.set_yticklabels(features)
                ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
                ax.set_title(f'{clf_name} - ç‰¹å¾é‡è¦æ€§åˆ†æ', fontsize=12, fontweight='bold')
                ax.grid(True, alpha=0.3, axis='x')
        
        self.feature_widget.figure.tight_layout()
        self.feature_widget.canvas.draw()
    
    def update_roc_plot(self, roc_data_dict):
        """æ›´æ–°ROCæ›²çº¿å›¾"""
        if not roc_data_dict:
            # ç»˜åˆ¶ç©ºçš„ROCæ›²çº¿
            self.roc_widget.clear()
            ax = self.roc_widget.axes
            ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºåˆ†ç±»å™¨')
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡')
            ax.set_ylabel('çœŸæ­£ç‡')
            ax.set_title('ROCæ›²çº¿')
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            self.roc_widget.figure.tight_layout()
            self.roc_widget.canvas.draw()
            return
        
        # åªæ˜¾ç¤ºæœ€ä½³åˆ†ç±»å™¨çš„ROCæ›²çº¿
        best_clf_code = None
        if self.comparison_results:
            df = pd.DataFrame(self.comparison_results)
            best_idx = df['éªŒè¯é›†ç²¾åº¦'].idxmax()
            best_clf_code = df.loc[best_idx, 'åˆ†ç±»å™¨ä»£ç ']
            clf_name = df.loc[best_idx, 'åˆ†ç±»å™¨åç§°']
        
        if best_clf_code and best_clf_code in roc_data_dict:
            roc_data = roc_data_dict[best_clf_code]
            
            self.roc_widget.clear()
            ax = self.roc_widget.axes
            
            # ä»ä¿å­˜çš„æ•°æ®ä¸­ç»˜åˆ¶ROCæ›²çº¿
            fpr = roc_data.get('fpr', {})
            tpr = roc_data.get('tpr', {})
            auc_scores = roc_data.get('auc', {})
            
            if isinstance(fpr, dict) and isinstance(tpr, dict):
                # å¤šåˆ†ç±»æƒ…å†µ
                colors = plt.cm.Set1(np.linspace(0, 1, len(fpr)))
                
                for i, (key, fpr_val) in enumerate(fpr.items()):
                    if key == 'macro':
                        # å®å¹³å‡ä½¿ç”¨ç‰¹æ®Šæ ·å¼
                        ax.plot(fpr_val, tpr[key], color='navy', linestyle=':', linewidth=4,
                            label=f'å®å¹³å‡ (AUC = {auc_scores.get(key, 0):.2f})')
                    elif key in auc_scores:
                        # å•ä¸ªç±»åˆ«
                        class_name = f'ç±»åˆ«_{key}' if isinstance(key, int) else str(key)
                        ax.plot(fpr_val, tpr[key], color=colors[i % len(colors)], lw=2,
                            label=f'{class_name} (AUC = {auc_scores[key]:.2f})')
                
                # æ·»åŠ éšæœºåˆ†ç±»å™¨çº¿
                ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨', alpha=0.8)
                
            else:
                # äºŒåˆ†ç±»æƒ…å†µ
                ax.plot(fpr, tpr, color='darkorange', lw=2,
                    label=f'ROCæ›²çº¿ (AUC = {auc_scores:.2f})')
                ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                    label='éšæœºåˆ†ç±»å™¨')
            
            ax.set_xlim([0.0, 1.0])
            ax.set_ylim([0.0, 1.05])
            ax.set_xlabel('å‡æ­£ç‡ (False Positive Rate)', fontsize=12)
            ax.set_ylabel('çœŸæ­£ç‡ (True Positive Rate)', fontsize=12)
            ax.set_title(f'{clf_name} - ROCæ›²çº¿', fontsize=14, fontweight='bold')
            ax.legend(loc="lower right", fontsize=10)
            ax.grid(True, alpha=0.3)
            
            self.roc_widget.figure.tight_layout()
            self.roc_widget.canvas.draw()
    
    def update_result_preview(self, image_path, classified_path, class_names, class_colors):
        """æ›´æ–°åˆ†ç±»ç»“æœé¢„è§ˆ"""
        try:
            self.result_widget.clear()
            
            # è¯»å–å½±åƒå’Œåˆ†ç±»ç»“æœ
            img = rxr.open_rasterio(image_path, masked=True)
            classified = rxr.open_rasterio(classified_path)
            
            # åˆ›å»ºå­å›¾
            ax1 = self.result_widget.figure.add_subplot(121)
            ax2 = self.result_widget.figure.add_subplot(122)
            
            # æ˜¾ç¤ºåŸå§‹å½±åƒ
            if img.shape[0] >= 3:
                rgb_data = np.moveaxis(img.values[:3], 0, -1)
                # å¤„ç†å¯èƒ½çš„NaNå€¼
                rgb_data = np.nan_to_num(rgb_data, nan=0.0)
                p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))
                rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)
                ax1.imshow(rgb_display)
            else:
                single_band = np.nan_to_num(img.values[0], nan=0.0)
                ax1.imshow(single_band, cmap='gray')
            
            ax1.set_title('åŸå§‹é¥æ„Ÿå½±åƒ', fontsize=12, fontweight='bold')
            ax1.axis('off')
            
            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            classified_data = classified.values.squeeze()
            
            # è·å–ç±»åˆ«
            classes = np.unique(classified_data)
            classes = classes[classes > 0]  # æ’é™¤èƒŒæ™¯å€¼
            
            if len(classes) > 0:
                # åˆ›å»ºé¢œè‰²æ˜ å°„
                colors = [class_colors.get(c, 'black') for c in classes]
                labels = [class_names.get(c, f'ç±»åˆ«_{c}') for c in classes]
                
                cmap = mcolors.ListedColormap(colors)
                bounds = np.append(classes, classes[-1] + 1) - 0.5
                norm = mcolors.BoundaryNorm(bounds, cmap.N)
                
                # èƒŒæ™¯è®¾ä¸ºé€æ˜
                display_data = classified_data.astype(float)
                display_data[classified_data == 0] = np.nan
                
                im = ax2.imshow(display_data, cmap=cmap, norm=norm)
                ax2.set_title('åˆ†ç±»ç»“æœï¼ˆæœ€ä½³åˆ†ç±»å™¨ï¼‰', fontsize=12, fontweight='bold')
                ax2.axis('off')
                
                # æ·»åŠ å›¾ä¾‹
                from matplotlib.patches import Patch
                legend_elements = [Patch(facecolor=color, label=label) 
                                  for color, label in zip(colors, labels)]
                ax2.legend(handles=legend_elements, loc='upper left', 
                          bbox_to_anchor=(1.05, 1), fontsize=9)
            else:
                ax2.text(0.5, 0.5, 'æ— åˆ†ç±»ç»“æœ', ha='center', va='center', 
                        transform=ax2.transAxes, fontsize=14)
                ax2.set_title('åˆ†ç±»ç»“æœï¼ˆæœ€ä½³åˆ†ç±»å™¨ï¼‰', fontsize=12, fontweight='bold')
                ax2.axis('off')
            
            self.result_widget.figure.tight_layout()
            self.result_widget.canvas.draw()
            
        except Exception as e:
            self.log(f"é¢„è§ˆæ˜¾ç¤ºé”™è¯¯: {str(e)}")
    
    def start_classification(self):
        """å¼€å§‹åˆ†ç±»"""
        # æ£€æŸ¥è¾“å…¥
        if not self.image_selector.get_path():
            QMessageBox.critical(self, "é”™è¯¯", "è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼")
            return
        
        if not self.train_shp_selector.get_path():
            QMessageBox.critical(self, "é”™è¯¯", "è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼")
            return
        
        if not self.class_attr_combo.currentText():
            QMessageBox.critical(self, "é”™è¯¯", "è¯·é€‰æ‹©ç±»åˆ«ç¼–å·å­—æ®µï¼")
            return
        
        selected_classifiers = [code for code, checkbox in self.classifier_vars.items() if checkbox.isChecked()]
        if not selected_classifiers:
            QMessageBox.critical(self, "é”™è¯¯", "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼")
            return
        
        # æ€§èƒ½è­¦å‘Š
        all_classifiers = self.backend.get_all_classifiers()
        very_slow_clfs = []
        
        for code in selected_classifiers:
            if code in all_classifiers:
                speed_tag = all_classifiers[code][5]
                name = all_classifiers[code][1]
                if speed_tag == "very_slow":
                    very_slow_clfs.append(name)
        
        if very_slow_clfs:
            warning_msg = "âš ï¸ ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹éå¸¸æ…¢:\n"
            for clf in very_slow_clfs:
                warning_msg += f"  â€¢ {clf}\n"
            warning_msg += "\næ˜¯å¦ç»§ç»­?"
            
            reply = QMessageBox.question(self, "æ€§èƒ½è­¦å‘Š", warning_msg, 
                                        QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
            if reply == QMessageBox.No:
                return
        
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.is_running = True
        
        # æ¸…ç©ºæ—¥å¿—
        self.log_widget.clear()
        
        self.log("="*80)
        self.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v5.1 - ä¸“ä¸šç‰ˆ (PyQt5)")
        self.log("="*80)
        self.log(f"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª")
        self.log(f"èƒŒæ™¯å€¼: {self.background_value.value()}")
        self.log("")
        
        # åˆ‡æ¢åˆ°æ—¥å¿—æ ‡ç­¾é¡µ
        self.tab_widget.setCurrentIndex(0)
        
        # åˆ›å»ºé…ç½®å­—å…¸
        config = {
            'image_path': self.image_selector.get_path(),
            'train_shp_path': self.train_shp_selector.get_path(),
            'val_shp_path': self.val_shp_selector.get_path(),
            'output_dir': self.output_selector.get_path(),
            'class_attr': self.class_attr_combo.currentText(),
            'name_attr': self.name_attr_combo.currentText(),
            'background_value': self.background_value.value(),
            'ignore_background': self.ignore_background.isChecked(),
            'n_estimators': self.n_estimators.value(),
            'block_size': self.block_size.value(),
            'enable_sampling': self.enable_sampling.isChecked(),
            'max_samples': self.max_samples.value(),
            'fast_mode': self.fast_mode.isChecked(),
            'enable_hyperparameter_optimization': self.enable_hyperparameter_optimization.isChecked(),
            'hyperparameter_optimization_method': self.hyperparameter_optimization_method.currentText(),
            'hyperparameter_iterations': self.hyperparameter_iterations.value(),
            'enable_postprocessing': self.enable_postprocessing.isChecked(),
            'postprocessing_method': self.postprocessing_method.currentText(),
            'postprocessing_size': self.postprocessing_size.value(),
            'enable_feature_importance': self.enable_feature_importance.isChecked(),
            'enable_roc_analysis': self.enable_roc_analysis.isChecked(),
            'enable_model_saving': self.enable_model_saving.isChecked(),
        }
        
        # å¯åŠ¨åˆ†ç±»çº¿ç¨‹
        self.classification_thread = ClassificationThread(self.backend, config, selected_classifiers)
        self.classification_thread.progress_signal.connect(self.progress_bar.setValue)
        self.classification_thread.log_signal.connect(self.log)
        self.classification_thread.status_signal.connect(self.status_label.setText)
        self.classification_thread.finished_signal.connect(self.classification_finished)
        self.classification_thread.start()
    
    def stop_classification(self):
        """åœæ­¢åˆ†ç±»"""
        self.is_running = False
        if self.classification_thread:
            self.classification_thread.stop()
        self.log("\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...")
        self.status_label.setText("å·²åœæ­¢")
    
    def try_generate_result_preview(self):
        """å°è¯•ç”Ÿæˆç»“æœé¢„è§ˆ"""
        if not self.comparison_results or not self.best_result_path:
            return
        
        try:
            # è·å–æœ€ä½³åˆ†ç±»å™¨ç»“æœ
            df = pd.DataFrame(self.comparison_results)
            best_result = df.loc[df['éªŒè¯é›†ç²¾åº¦'].idxmax()]
            best_clf_code = best_result['åˆ†ç±»å™¨ä»£ç ']
            
            # æ„å»ºç»“æœè·¯å¾„
            out_dir = Path(self.output_selector.get_path())
            clf_dir = out_dir / best_clf_code
            classified_path = clf_dir / f"classified_{best_clf_code}.tif"
            
            if not classified_path.exists():
                return
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            class_names, class_colors, _ = self.backend.get_class_info_from_shp(
                self.train_shp_selector.get_path(),
                self.class_attr_combo.currentText(),
                self.name_attr_combo.currentText()
            )
            
            # æ›´æ–°é¢„è§ˆ
            self.update_result_preview(
                self.image_selector.get_path(),
                str(classified_path),
                class_names,
                class_colors
            )
            
        except Exception as e:
            self.log(f"ç”Ÿæˆç»“æœé¢„è§ˆå¤±è´¥: {str(e)}")

    def classification_finished(self, success, message, comparison_results, confusion_data, 
                           feature_importance_data, roc_data_dict, result_preview_data):
        """åˆ†ç±»å®Œæˆ"""
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setValue(0)
        
        if success:
            self.status_label.setText("âœ… å®Œæˆ!")
            self.comparison_results = comparison_results
            self.feature_importance_data = feature_importance_data
            self.roc_data_dict = roc_data_dict
            
            # æ›´æ–°æ‰€æœ‰å›¾è¡¨
            if comparison_results:
                self.update_accuracy_plot(comparison_results)
                self.update_time_plot(comparison_results)
            
            if confusion_data:
                y_true, y_pred, class_names = confusion_data
                self.update_confusion_matrix(y_true, y_pred, class_names)
            
            if feature_importance_data:
                # ä¿®å¤ï¼šä»åˆ†ç±»çº¿ç¨‹è·å–çœŸå®çš„æ³¢æ®µåç§°
                try:
                    # é‡æ–°è¯»å–å½±åƒè·å–æ³¢æ®µä¿¡æ¯
                    img = rxr.open_rasterio(self.image_selector.get_path(), masked=True)
                    band_names = []
                    if hasattr(img, 'long_name') and img.long_name:
                        band_names = img.long_name
                    elif hasattr(img, 'band') and img.band.values is not None:
                        band_names = [f"æ³¢æ®µ_{b}" for b in img.band.values]
                    else:
                        band_names = [f"æ³¢æ®µ_{i+1}" for i in range(img.shape[0])]
                except:
                    band_names = [f"æ³¢æ®µ_{i+1}" for i in range(10)]  # å¤‡ç”¨æ–¹æ¡ˆ
                
                self.update_feature_importance_plot(feature_importance_data, band_names)
            
            if roc_data_dict:
                self.update_roc_plot(roc_data_dict)
            
            # ä¿®å¤ï¼šæ·»åŠ ç»“æœé¢„è§ˆæ›´æ–°
            if result_preview_data:
                image_path, classified_path, class_names, class_colors = result_preview_data
                self.update_result_preview(image_path, classified_path, class_names, class_colors)
            else:
                # å¦‚æœæ²¡æœ‰é¢„è§ˆæ•°æ®ï¼Œå°è¯•ä»æœ€ä½³ç»“æœç”Ÿæˆ
                self.try_generate_result_preview()
            
            QMessageBox.information(self, "å®Œæˆ", message)
        else:
            self.status_label.setText("âŒ é”™è¯¯")
            if "é”™è¯¯" in message:
                QMessageBox.critical(self, "é”™è¯¯", message)
            else:
                QMessageBox.warning(self, "è­¦å‘Š", message)
    
    def open_result_dir(self):
        """æ‰“å¼€ç»“æœç›®å½•"""
        out_dir = Path(self.output_selector.get_path())
        if out_dir.exists():
            import subprocess
            import platform
            
            if platform.system() == "Windows":
                os.startfile(out_dir)
            elif platform.system() == "Darwin":
                subprocess.Popen(["open", out_dir])
            else:
                subprocess.Popen(["xdg-open", out_dir])
        else:
            QMessageBox.warning(self, "è­¦å‘Š", "ç»“æœç›®å½•ä¸å­˜åœ¨ï¼")


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

def main():
    """ç¨‹åºå…¥å£"""
    print("="*80)
    print("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ (PyQt5)")
    print("="*80)
    print("\næ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...")
    
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨ç¨‹åºæ ·å¼
    app.setStyle('Fusion')
    
    # åˆ›å»ºå¹¶æ˜¾ç¤ºä¸»çª—å£
    window = ClassificationGUI()
    window.show()
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    window.log("="*80)
    window.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v1.0 - ä¸“ä¸šç‰ˆ (PyQt5)")
    window.log("                     @ 3S&MLå®éªŒå®¤")
    window.log("="*80)
    window.log("\næ ¸å¿ƒåŠŸèƒ½:")
    window.log("  âœ… å¤šåˆ†ç±»å™¨æ”¯æŒ: é›†æˆ12+ç§æœºå™¨å­¦ä¹ åˆ†ç±»å™¨")
    window.log("  âœ… è¶…å‚æ•°è‡ªåŠ¨ä¼˜åŒ–: è‡ªåŠ¨å¯»æ‰¾æœ€ä½³å‚æ•°ç»„åˆ")
    window.log("  âœ… åå¤„ç†æ»¤æ³¢: æå‡åˆ†ç±»ç»“æœè´¨é‡")
    window.log("  âœ… ROCæ›²çº¿åˆ†æ: ä¸“ä¸šæ¨¡å‹è¯„ä¼°")
    window.log("  âœ… ç‰¹å¾é‡è¦æ€§åˆ†æ: æ³¢æ®µè´¡çŒ®åº¦åˆ†æ")
    window.log("  âœ… æ¨¡å‹ä¿å­˜/åŠ è½½: æ”¯æŒæ¨¡å‹å¤ç”¨")
    window.log("  âœ… æ‰¹é‡å¤„ç†: å¤šåˆ†ç±»å™¨å¹¶è¡Œå¯¹æ¯”")
    window.log("  âœ… å¯è§†åŒ–åˆ†æ: å®æ—¶å›¾è¡¨æ˜¾ç¤º")
    window.log("\nä½¿ç”¨æµç¨‹:")
    window.log("  1. é€‰æ‹©å½±åƒå’Œæ ·æœ¬æ–‡ä»¶")
    window.log("  2. ç‚¹å‡»'åˆ·æ–°å­—æ®µåˆ—è¡¨'é€‰æ‹©ç±»åˆ«å­—æ®µ")
    window.log("  3. è®¾ç½®èƒŒæ™¯å€¼å’Œå…¶ä»–å‚æ•°")
    window.log("  4. é€‰æ‹©åˆ†ç±»å™¨")
    window.log("  5. é…ç½®é«˜çº§åŠŸèƒ½ï¼ˆè¶…å‚æ•°ä¼˜åŒ–ã€åå¤„ç†ç­‰ï¼‰")
    window.log("  6. ç‚¹å‡»'å¼€å§‹åˆ†ç±»'")
    window.log("  7. æŸ¥çœ‹å³ä¾§å®æ—¶å›¾è¡¨å’Œå„åˆ†ç±»å™¨è¯¦ç»†ç»“æœ")
    window.log("="*80)
    window.log("\næŠ€æœ¯ä¼˜åŠ¿:")
    window.log("  ğŸš€ é«˜æ€§èƒ½: æ”¯æŒåˆ†å—å¤„ç†å¤§å½±åƒ")
    window.log("  ğŸ“Š ä¸“ä¸šè¯„ä¼°: æä¾›å®Œæ•´çš„ç²¾åº¦è¯„ä»·æŒ‡æ ‡")
    window.log("  ğŸ’¾ å¤šç§æ ¼å¼: æ”¯æŒå¤šç§æ•°æ®æ ¼å¼è¾“å‡º")
    window.log("  ğŸ”§ çµæ´»é…ç½®: å‚æ•°å¯è°ƒï¼Œé€‚åº”ä¸åŒéœ€æ±‚")
    window.log("")
    
    print("\nâœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!")
    
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()