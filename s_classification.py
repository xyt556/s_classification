#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - ä¸“ä¸šç‰ˆ v4.1
=====================================
æ–°å¢:
- å®Œå–„ç»“æœé¢„è§ˆæ˜¾ç¤º
- Excelæ ¼å¼æŠ¥å‘Šè¾“å‡º
- æ··æ·†çŸ©é˜µå¯è§†åŒ–
- å›¾è¡¨å®æ—¶åˆ·æ–°ä¼˜åŒ–
"""

import os
import sys
import time
import threading
import queue
from pathlib import Path
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.figure import Figure
import matplotlib.colors as mcolors
import seaborn as sns
import geopandas as gpd
import rioxarray as rxr
import xarray as xr
from rasterio import features
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, 
                              AdaBoostClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.kernel_approximation import Nystroem, RBFSampler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, 
                           cohen_kappa_score, precision_score, recall_score, f1_score)
from scipy import ndimage
from skimage import morphology
import warnings
warnings.filterwarnings('ignore')

sns.set_style("whitegrid")

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans", "Arial Unicode MS"]
plt.rcParams["axes.unicode_minus"] = False

# æ£€æŸ¥openpyxl
try:
    import openpyxl
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False
    print("âš ï¸  æœªå®‰è£…openpyxlï¼Œå°†æ— æ³•å¯¼å‡ºExcelæ–‡ä»¶")
    print("   å®‰è£…: pip install openpyxl")

# ==================== åç«¯å¤„ç†ç±» ====================
class ClassificationBackend:
    """åˆ†ç±»å¤„ç†åç«¯"""
    
    def __init__(self):
        self.RANDOM_STATE = 42
        
        # é¢„å®šä¹‰é¢œè‰²
        self.LANDUSE_COLORS = {
            "æ°´ä½“": "lightblue", "æ²³æµ": "blue", "æ¹–æ³Š": "deepskyblue",
            "æ¤è¢«": "forestgreen", "æ£®æ—": "darkgreen", "è‰åœ°": "limegreen",
            "å†œç”°": "yellowgreen", "è€•åœ°": "olivedrab",
            "å»ºç­‘": "gray", "åŸå¸‚": "dimgray", "å±…æ°‘åœ°": "slategray",
            "è£¸åœ°": "tan", "æ²™åœ°": "wheat", "å…¶ä»–": "darkred"
        }
        
        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', 
                             'darkred', 'purple', 'orange', 'pink', 'brown']
        
        # æ£€æŸ¥å¯é€‰åº“
        self.check_optional_libraries()
    
    def check_optional_libraries(self):
        """æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨"""
        self.has_xgboost = False
        self.has_lightgbm = False
        
        try:
            import xgboost
            from xgboost import XGBClassifier
            _ = XGBClassifier(n_estimators=10, verbosity=0)
            self.has_xgboost = True
            print("âœ“ XGBoost å¯ç”¨")
        except Exception:
            print("âœ— XGBoost ä¸å¯ç”¨")
        
        try:
            import lightgbm
            from lightgbm import LGBMClassifier
            _ = LGBMClassifier(n_estimators=10, verbose=-1)
            self.has_lightgbm = True
            print("âœ“ LightGBM å¯ç”¨")
        except Exception:
            print("âœ— LightGBM ä¸å¯ç”¨")
    
    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):
        """è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨"""
        if fast_mode:
            n_est = min(50, n_estimators)
            max_depth = 10
            max_iter = 200
        else:
            n_est = n_estimators
            max_depth = 20
            max_iter = 500
        
        if n_train_samples:
            n_components = min(1000, n_train_samples // 2)
        else:
            n_components = 1000
        
        classifiers = {
            "rf": (RandomForestClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE, 
                                         verbose=0, max_depth=max_depth, min_samples_split=5, 
                                         max_features='sqrt'),
                  "éšæœºæ£®æ—", "Random Forest", False, False, "fast"),
            
            "et": (ExtraTreesClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE,
                                       verbose=0, max_depth=max_depth, min_samples_split=5, max_features='sqrt'),
                  "æç«¯éšæœºæ ‘", "Extra Trees", False, False, "fast"),
            
            "dt": (DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=max_depth,
                                         min_samples_split=5, min_samples_leaf=2),
                  "å†³ç­–æ ‘", "Decision Tree", False, False, "very_fast"),
            
            "svm_linear": (SVC(kernel="linear", C=1.0, cache_size=500, probability=True, 
                             random_state=self.RANDOM_STATE, max_iter=max_iter),
                          "SVM-çº¿æ€§æ ¸", "SVM Linear", False, True, "medium"),
            
            "linear_svc": (CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=max_iter, random_state=self.RANDOM_STATE,
                                                           dual=False, loss='squared_hinge'), cv=3),
                          "çº¿æ€§SVM(å¿«)", "Linear SVM", False, True, "fast"),
            
            "sgd_svm": (SGDClassifier(loss='hinge', penalty='l2', max_iter=max_iter, n_jobs=-1,
                                     random_state=self.RANDOM_STATE, learning_rate='optimal'),
                       "SGD-SVM", "SGD SVM", False, True, "very_fast"),
            
            "nystroem_svm": (Pipeline([
                ("feature_map", Nystroem(kernel='rbf', gamma=0.1, n_components=n_components, 
                                        random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "æ ¸è¿‘ä¼¼SVM", "Nystroem SVM", False, True, "fast"),
            
            "rbf_sampler_svm": (Pipeline([
                ("feature_map", RBFSampler(gamma=0.1, n_components=n_components, random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "RBFé‡‡æ ·SVM", "RBF Sampler", False, True, "fast"),
            
            "svm_rbf": (SVC(kernel="rbf", C=1.0, gamma='scale', cache_size=500, probability=True, 
                          random_state=self.RANDOM_STATE),
                       "SVM-RBFæ ¸âš ï¸", "SVM RBF", False, True, "very_slow"),
            
            "knn": (KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm='ball_tree', leaf_size=30),
                   "Kè¿‘é‚»", "KNN", False, True, "slow"),
            
            "nb": (GaussianNB(), "æœ´ç´ è´å¶æ–¯", "Naive Bayes", False, False, "very_fast"),
            
            "gb": (GradientBoostingClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=5,
                                             random_state=self.RANDOM_STATE, verbose=0, subsample=0.8),
                  "æ¢¯åº¦æå‡", "Gradient Boosting", False, False, "medium"),
            
            "ada": (AdaBoostClassifier(n_estimators=n_est, learning_rate=1.0, 
                                      random_state=self.RANDOM_STATE, algorithm='SAMME.R'),
                   "AdaBoost", "AdaBoost", False, False, "medium"),
            
            "lr": (LogisticRegression(max_iter=max_iter, n_jobs=-1, random_state=self.RANDOM_STATE,
                                     verbose=0, solver='lbfgs', multi_class='multinomial'),
                  "é€»è¾‘å›å½’", "Logistic Regression", False, True, "very_fast"),
            
            "mlp": (MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=max_iter, random_state=self.RANDOM_STATE,
                                 verbose=False, early_stopping=True, validation_fraction=0.1, 
                                 n_iter_no_change=10, learning_rate='adaptive'),
                   "ç¥ç»ç½‘ç»œ", "MLP", False, True, "medium"),
        }
        
        if self.has_xgboost:
            try:
                from xgboost import XGBClassifier
                classifiers["xgb"] = (
                    XGBClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=6, n_jobs=-1,
                                 random_state=self.RANDOM_STATE, verbosity=0, tree_method='hist',
                                 subsample=0.8, colsample_bytree=0.8),
                    "XGBoost", "XGBoost", True, False, "fast"
                )
            except Exception:
                pass
        
        if self.has_lightgbm:
            try:
                from lightgbm import LGBMClassifier
                classifiers["lgb"] = (
                    LGBMClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=max_depth, n_jobs=-1,
                                  random_state=self.RANDOM_STATE, verbose=-1, num_leaves=31,
                                  subsample=0.8, colsample_bytree=0.8, force_col_wise=True),
                    "LightGBM", "LightGBM", False, False, "very_fast"
                )
            except Exception:
                pass
        
        return classifiers
    
    def get_background_mask(self, image, background_value=0):
        """è·å–èƒŒæ™¯æ©è†œ"""
        data = image.values
        if background_value == 0:
            background_mask = np.all(data == 0, axis=0)
        else:
            background_mask = np.all(data == background_value, axis=0)
        return background_mask
    
    def get_shapefile_fields(self, shp_path):
        """è·å–shapefileçš„æ‰€æœ‰å­—æ®µå"""
        try:
            gdf = gpd.read_file(shp_path)
            return list(gdf.columns)
        except Exception as e:
            print(f"è¯»å–shapefileå­—æ®µå¤±è´¥: {e}")
            return []
    
    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):
        """ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯"""
        gdf = gpd.read_file(shp_path)
        
        if name_attr not in gdf.columns or name_attr == class_attr:
            gdf[name_attr] = gdf[class_attr].apply(lambda x: f"ç±»åˆ«_{x}")
        
        class_info = gdf[[class_attr, name_attr]].drop_duplicates()
        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))
        
        class_colors = {}
        for i, (class_id, class_name) in enumerate(class_names.items()):
            color_found = False
            for key, color in self.LANDUSE_COLORS.items():
                if key in str(class_name):
                    class_colors[class_id] = color
                    color_found = True
                    break
            if not color_found:
                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]
        
        return class_names, class_colors, sorted(class_names.keys())
    
    def rasterize_samples(self, shp, ref_img, attr):
        """çŸ¢é‡æ …æ ¼åŒ–"""
        gdf = gpd.read_file(shp)
        gdf = gdf.to_crs(ref_img.rio.crs)
        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))
        
        arr = features.rasterize(shapes=shapes, out_shape=ref_img.shape[1:],
                                transform=ref_img.rio.transform(), fill=0,
                                all_touched=True, dtype="uint16")
        return arr
    
    def extract_samples(self, image, mask, ignore_background=True, background_value=0, max_samples=None):
        """æå–æ ·æœ¬"""
        data = np.moveaxis(image.values, 0, -1)
        valid = mask > 0
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
            valid = valid & (~background_mask)
        
        X = data[valid]
        y = mask[valid]
        
        # æ¸…ç†NaNå’ŒInf
        nan_mask = np.isnan(X).any(axis=1)
        inf_mask = np.isinf(X).any(axis=1)
        bad_mask = nan_mask | inf_mask
        
        n_nan = np.sum(nan_mask)
        n_inf = np.sum(inf_mask)
        
        X = X[~bad_mask]
        y = y[~bad_mask]
        
        # åˆ†å±‚é‡‡æ ·
        n_sampled = 0
        if max_samples is not None and len(y) > max_samples:
            n_original = len(y)
            unique_classes = np.unique(y)
            
            if len(unique_classes) > 1:
                splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_samples, 
                                                 random_state=self.RANDOM_STATE)
                sample_idx, _ = next(splitter.split(X, y))
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
            else:
                np.random.seed(self.RANDOM_STATE)
                sample_idx = np.random.choice(len(y), max_samples, replace=False)
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
        
        return X, y, n_nan, n_inf, n_sampled
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'overall_accuracy': accuracy_score(y_true, y_pred),
            'kappa': cohen_kappa_score(y_true, y_pred),
            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        }
    
    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):
        """ä¼°ç®—é¢„æµ‹æ—¶é—´"""
        time_per_million = {"very_fast": 1, "fast": 3, "medium": 10, "slow": 30, "very_slow": 300}
        base_time = time_per_million.get(speed_tag, 10)
        return (n_pixels / 1_000_000) * base_time
    
    def predict_by_block(self, model, image, out_path, block_size=512, 
                        ignore_background=True, background_value=0, progress_callback=None,
                        label_encoder=None, scaler=None):
        """åˆ†å—é¢„æµ‹"""
        height, width = image.shape[1], image.shape[2]
        prediction = np.zeros((height, width), dtype='uint16')
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
        
        total_blocks = int(np.ceil(height / block_size))
        
        for i, y in enumerate(range(0, height, block_size)):
            h = min(block_size, height - y)
            block_data = image.isel(y=slice(y, y+h)).values
            data = np.moveaxis(block_data, 0, -1)
            original_shape = data.shape
            data_flat = data.reshape(-1, data.shape[-1])
            
            if ignore_background:
                block_bg_mask = background_mask[y:y+h, :].flatten()
                non_bg_indices = ~block_bg_mask
                
                if np.any(non_bg_indices):
                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], 
                                                   nan=0.0, posinf=0.0, neginf=0.0)
                    
                    if scaler is not None:
                        data_to_predict = scaler.transform(data_to_predict)
                    
                    preds_non_bg = model.predict(data_to_predict)
                    
                    if label_encoder is not None:
                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)
                    
                    preds_flat = np.zeros(len(data_flat), dtype='uint16')
                    preds_flat[non_bg_indices] = preds_non_bg
                    preds = preds_flat.reshape(original_shape[0], original_shape[1])
                else:
                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')
            else:
                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)
                
                if scaler is not None:
                    data_flat = scaler.transform(data_flat)
                
                preds = model.predict(data_flat)
                
                if label_encoder is not None:
                    preds = label_encoder.inverse_transform(preds)
                
                preds = preds.reshape(original_shape[0], original_shape[1]).astype("uint16")
            
            prediction[y:y+h, :] = preds
            
            if progress_callback:
                progress_callback((i + 1) / total_blocks * 100)
        
        # ä¿å­˜ç»“æœ
        prediction_da = xr.DataArray(prediction, dims=['y', 'x'],
                                     coords={'y': image.coords['y'], 'x': image.coords['x']})
        
        prediction_da.rio.write_crs(image.rio.crs, inplace=True)
        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)
        prediction_da.rio.write_nodata(background_value, inplace=True)
        
        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', 
                                    compress='lzw', tiled=True)
        return out_path

# ==================== GUIä¸»ç±» ====================
class ClassificationGUI:
    """é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢ï¼ˆä¸“ä¸šç‰ˆï¼‰"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ")
        self.root.geometry("1600x900")
        
        # åç«¯å¤„ç†å¯¹è±¡
        self.backend = ClassificationBackend()
        
        # æ•°æ®å˜é‡
        self.image_path = tk.StringVar()
        self.train_shp_path = tk.StringVar()
        self.val_shp_path = tk.StringVar()
        self.output_dir = tk.StringVar(value=str(Path("./results_gui")))
        
        # å­—æ®µé€‰æ‹©
        self.train_fields = []
        self.class_attr = tk.StringVar()
        self.name_attr = tk.StringVar()
        
        # èƒŒæ™¯å€¼
        self.background_value = tk.IntVar(value=0)
        self.ignore_background = tk.BooleanVar(value=True)
        
        # å…¶ä»–å‚æ•°
        self.n_estimators = tk.IntVar(value=100)
        self.block_size = tk.IntVar(value=512)
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.enable_sampling = tk.BooleanVar(value=True)
        self.max_samples = tk.IntVar(value=50000)
        self.fast_mode = tk.BooleanVar(value=False)
        
        # åˆ†ç±»å™¨é€‰æ‹©
        self.classifier_vars = {}
        all_classifiers = self.backend.get_all_classifiers()
        for code in all_classifiers.keys():
            self.classifier_vars[code] = tk.BooleanVar(value=False)
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.log_queue = queue.Queue()
        
        # å­˜å‚¨ç»“æœæ•°æ®
        self.comparison_results = []
        self.current_confusion_matrix = None
        self.current_y_true = None
        self.current_y_pred = None
        self.class_names_dict = {}
        self.class_colors_dict = {}
        self.best_result_path = None
        
        # æ„å»ºç•Œé¢
        self.build_ui()
        
        # å¯åŠ¨æ—¥å¿—æ›´æ–°
        self.update_log()
    
    def build_ui(self):
        """æ„å»ºç”¨æˆ·ç•Œé¢ï¼ˆå·¦å³åˆ†æ ï¼‰"""
        # åˆ›å»ºä¸»PanedWindow
        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # ===== å·¦ä¾§é¢æ¿ï¼šå‚æ•°è®¾ç½® =====
        left_frame = ttk.Frame(main_paned, width=600)
        main_paned.add(left_frame, weight=1)
        
        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ
        canvas = tk.Canvas(left_frame)
        scrollbar = ttk.Scrollbar(left_frame, orient="vertical", command=canvas.yview)
        scrollable_left = ttk.Frame(canvas)
        
        scrollable_left.bind("<Configure>", 
                            lambda e: canvas.configure(scrollregion=canvas.bbox("all")))
        
        canvas.create_window((0, 0), window=scrollable_left, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # 1. æ–‡ä»¶é€‰æ‹©
        file_frame = ttk.LabelFrame(scrollable_left, text="ğŸ“ æ•°æ®æ–‡ä»¶", padding="10")
        file_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(file_frame, text="å½±åƒæ–‡ä»¶:").grid(row=0, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.image_path, width=40).grid(
            row=0, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_image).grid(row=0, column=2)
        
        ttk.Label(file_frame, text="è®­ç»ƒæ ·æœ¬:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=40).grid(
            row=1, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_train_shp).grid(row=1, column=2)
        
        ttk.Label(file_frame, text="éªŒè¯æ ·æœ¬:").grid(row=2, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=40).grid(
            row=2, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_val_shp).grid(row=2, column=2)
        
        ttk.Label(file_frame, text="è¾“å‡ºç›®å½•:").grid(row=3, column=0, sticky=tk.W, pady=3)
        ttk.Entry(file_frame, textvariable=self.output_dir, width=40).grid(
            row=3, column=1, sticky=(tk.W, tk.E), padx=5
        )
        ttk.Button(file_frame, text="æµè§ˆ", command=self.browse_output).grid(row=3, column=2)
        
        file_frame.columnconfigure(1, weight=1)
        
        # 2. å­—æ®µé€‰æ‹©
        field_frame = ttk.LabelFrame(scrollable_left, text="ğŸ·ï¸ å­—æ®µé…ç½®", padding="10")
        field_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(field_frame, text="ç±»åˆ«ç¼–å·å­—æ®µ:").grid(row=0, column=0, sticky=tk.W, pady=3)
        self.class_attr_combo = ttk.Combobox(field_frame, textvariable=self.class_attr, 
                                            width=20, state="readonly")
        self.class_attr_combo.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=5)
        
        ttk.Label(field_frame, text="ç±»åˆ«åç§°å­—æ®µ:").grid(row=1, column=0, sticky=tk.W, pady=3)
        self.name_attr_combo = ttk.Combobox(field_frame, textvariable=self.name_attr, 
                                           width=20, state="readonly")
        self.name_attr_combo.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5)
        
        ttk.Button(field_frame, text="ğŸ”„ åˆ·æ–°å­—æ®µåˆ—è¡¨", 
                  command=self.refresh_fields).grid(row=0, column=2, rowspan=2, padx=5)
        
        field_frame.columnconfigure(1, weight=1)
        
        # 3. èƒŒæ™¯å€¼è®¾ç½®
        bg_frame = ttk.LabelFrame(scrollable_left, text="ğŸ¨ èƒŒæ™¯å€¼è®¾ç½®", padding="10")
        bg_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Checkbutton(bg_frame, text="å¿½ç•¥èƒŒæ™¯å€¼", 
                       variable=self.ignore_background).grid(row=0, column=0, sticky=tk.W, pady=3)
        
        ttk.Label(bg_frame, text="èƒŒæ™¯å€¼:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(bg_frame, from_=-9999, to=9999, textvariable=self.background_value, 
                   width=15).grid(row=1, column=1, sticky=tk.W, padx=5)
        ttk.Label(bg_frame, text="(é»˜è®¤0, å¸¸è§: -9999, 255)", 
                 font=('', 8), foreground='gray').grid(row=1, column=2, sticky=tk.W)
        
        # 4. åˆ†ç±»å‚æ•°
        param_frame = ttk.LabelFrame(scrollable_left, text="âš™ï¸ åˆ†ç±»å‚æ•°", padding="10")
        param_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(param_frame, text="æ ‘æ¨¡å‹æ•°é‡:").grid(row=0, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, 
                   width=15).grid(row=0, column=1, sticky=tk.W, padx=5)
        
        ttk.Label(param_frame, text="åˆ†å—å¤§å°:").grid(row=1, column=0, sticky=tk.W, pady=3)
        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, 
                   textvariable=self.block_size, width=15).grid(row=1, column=1, sticky=tk.W, padx=5)
        
        # 5. æ€§èƒ½ä¼˜åŒ–
        opt_frame = ttk.LabelFrame(scrollable_left, text="âš¡ æ€§èƒ½ä¼˜åŒ–", padding="10")
        opt_frame.pack(fill=tk.X, padx=5, pady=5)
        
        sample_frame = ttk.Frame(opt_frame)
        sample_frame.pack(fill=tk.X, pady=2)
        
        ttk.Checkbutton(sample_frame, text="å¯ç”¨é‡‡æ ·", 
                       variable=self.enable_sampling,
                       command=self.toggle_sampling).pack(side=tk.LEFT)
        
        ttk.Label(sample_frame, text="æœ€å¤§æ ·æœ¬æ•°:").pack(side=tk.LEFT, padx=(10, 0))
        self.max_samples_spinbox = ttk.Spinbox(sample_frame, from_=10000, to=200000, 
                                              increment=10000, textvariable=self.max_samples, 
                                              width=10)
        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)
        
        ttk.Checkbutton(opt_frame, text="å¿«é€Ÿæ¨¡å¼", 
                       variable=self.fast_mode).pack(anchor=tk.W, pady=2)
        
        # 6. åˆ†ç±»å™¨é€‰æ‹©
        clf_frame = ttk.LabelFrame(scrollable_left, text="ğŸ¤– åˆ†ç±»å™¨é€‰æ‹©", padding="10")
        clf_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # å¿«æ·æŒ‰é’®
        btn_frame = ttk.Frame(clf_frame)
        btn_frame.pack(fill=tk.X, pady=(0, 5))
        
        ttk.Button(btn_frame, text="å…¨é€‰", command=self.select_all_classifiers, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="å…¨ä¸é€‰", command=self.deselect_all_classifiers, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="âœ“æ¨è", command=self.select_recommended, 
                  width=10).pack(side=tk.LEFT, padx=2)
        ttk.Button(btn_frame, text="âš¡å¿«é€Ÿ", command=self.select_fast, 
                  width=10).pack(side=tk.LEFT, padx=2)
        
        # åˆ†ç±»å™¨å¤é€‰æ¡†
        all_classifiers = self.backend.get_all_classifiers()
        
        clf_canvas = tk.Canvas(clf_frame, height=150)
        clf_scrollbar = ttk.Scrollbar(clf_frame, orient="vertical", command=clf_canvas.yview)
        clf_scrollable = ttk.Frame(clf_canvas)
        
        clf_scrollable.bind("<Configure>", 
                           lambda e: clf_canvas.configure(scrollregion=clf_canvas.bbox("all")))
        
        clf_canvas.create_window((0, 0), window=clf_scrollable, anchor="nw")
        clf_canvas.configure(yscrollcommand=clf_scrollbar.set)
        
        # SVMç»„
        ttk.Label(clf_scrollable, text="SVM:", font=('', 9, 'bold')).grid(
            row=0, column=0, sticky=tk.W, pady=2
        )
        row = 1
        svm_codes = ["svm_linear", "linear_svc", "sgd_svm", "nystroem_svm", 
                     "rbf_sampler_svm", "svm_rbf"]
        for code in svm_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name, 
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        # æ ‘æ¨¡å‹
        ttk.Label(clf_scrollable, text="æ ‘æ¨¡å‹:", font=('', 9, 'bold')).grid(
            row=row, column=0, sticky=tk.W, pady=(5, 2)
        )
        row += 1
        tree_codes = ["rf", "et", "dt", "xgb", "lgb", "gb", "ada"]
        for code in tree_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name,
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        # å…¶ä»–
        ttk.Label(clf_scrollable, text="å…¶ä»–:", font=('', 9, 'bold')).grid(
            row=row, column=0, sticky=tk.W, pady=(5, 2)
        )
        row += 1
        other_codes = ["knn", "nb", "lr", "mlp"]
        for code in other_codes:
            if code in all_classifiers:
                _, name, _, _, _, _ = all_classifiers[code]
                ttk.Checkbutton(clf_scrollable, text=name,
                              variable=self.classifier_vars[code]).grid(
                    row=row, column=0, sticky=tk.W, padx=20
                )
                row += 1
        
        clf_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        clf_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # 7. æ§åˆ¶æŒ‰é’®
        control_frame = ttk.LabelFrame(scrollable_left, text="ğŸ® è¿è¡Œæ§åˆ¶", padding="10")
        control_frame.pack(fill=tk.X, padx=5, pady=5)
        
        btn_control_frame = ttk.Frame(control_frame)
        btn_control_frame.pack(fill=tk.X)
        
        self.start_btn = ttk.Button(btn_control_frame, text="â–¶ å¼€å§‹åˆ†ç±»", 
                                    command=self.start_classification, width=15)
        self.start_btn.pack(side=tk.LEFT, padx=5)
        
        self.stop_btn = ttk.Button(btn_control_frame, text="â¸ åœæ­¢", 
                                   command=self.stop_classification, 
                                   state=tk.DISABLED, width=15)
        self.stop_btn.pack(side=tk.LEFT, padx=5)
        
        ttk.Button(btn_control_frame, text="ğŸ“ æ‰“å¼€ç»“æœ", 
                  command=self.open_result_dir, width=15).pack(side=tk.LEFT, padx=5)
        
        # è¿›åº¦æ¡
        ttk.Label(control_frame, text="è¿›åº¦:").pack(anchor=tk.W, pady=(10, 0))
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, 
                                           maximum=100)
        self.progress_bar.pack(fill=tk.X, pady=5)
        
        # çŠ¶æ€
        self.status_var = tk.StringVar(value="å°±ç»ª")
        ttk.Label(control_frame, textvariable=self.status_var, 
                 relief=tk.SUNKEN, anchor=tk.W).pack(fill=tk.X)
        
        # ===== å³ä¾§é¢æ¿ï¼šå›¾ä»¶æ˜¾ç¤º =====
        right_frame = ttk.Frame(main_paned, width=900)
        main_paned.add(right_frame, weight=2)
        
        # åˆ›å»ºNotebook
        self.notebook = ttk.Notebook(right_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        # æ ‡ç­¾é¡µ1ï¼šè¿è¡Œæ—¥å¿—
        log_tab = ttk.Frame(self.notebook)
        self.notebook.add(log_tab, text="ğŸ“ è¿è¡Œæ—¥å¿—")
        
        self.log_text = scrolledtext.ScrolledText(log_tab, wrap=tk.WORD, 
                                                  font=('Consolas', 9))
        self.log_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ ‡ç­¾é¡µ2ï¼šç²¾åº¦å¯¹æ¯”
        accuracy_tab = ttk.Frame(self.notebook)
        self.notebook.add(accuracy_tab, text="ğŸ“Š ç²¾åº¦å¯¹æ¯”")
        
        self.accuracy_fig = Figure(figsize=(10, 6), dpi=100)
        self.accuracy_canvas = FigureCanvasTkAgg(self.accuracy_fig, accuracy_tab)
        self.accuracy_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_acc = ttk.Frame(accuracy_tab)
        toolbar_acc.pack(fill=tk.X)
        NavigationToolbar2Tk(self.accuracy_canvas, toolbar_acc)
        
        # æ ‡ç­¾é¡µ3ï¼šæ··æ·†çŸ©é˜µ
        cm_tab = ttk.Frame(self.notebook)
        self.notebook.add(cm_tab, text="ğŸ”¥ æ··æ·†çŸ©é˜µ")
        
        self.cm_fig = Figure(figsize=(8, 6), dpi=100)
        self.cm_canvas = FigureCanvasTkAgg(self.cm_fig, cm_tab)
        self.cm_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_cm = ttk.Frame(cm_tab)
        toolbar_cm.pack(fill=tk.X)
        NavigationToolbar2Tk(self.cm_canvas, toolbar_cm)
        
        # æ ‡ç­¾é¡µ4ï¼šæ—¶é—´å¯¹æ¯”
        time_tab = ttk.Frame(self.notebook)
        self.notebook.add(time_tab, text="â±ï¸ æ—¶é—´å¯¹æ¯”")
        
        self.time_fig = Figure(figsize=(10, 6), dpi=100)
        self.time_canvas = FigureCanvasTkAgg(self.time_fig, time_tab)
        self.time_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_time = ttk.Frame(time_tab)
        toolbar_time.pack(fill=tk.X)
        NavigationToolbar2Tk(self.time_canvas, toolbar_time)
        
        # æ ‡ç­¾é¡µ5ï¼šåˆ†ç±»ç»“æœé¢„è§ˆ
        result_tab = ttk.Frame(self.notebook)
        self.notebook.add(result_tab, text="ğŸ—ºï¸ ç»“æœé¢„è§ˆ")
        
        self.result_fig = Figure(figsize=(10, 6), dpi=100)
        self.result_canvas = FigureCanvasTkAgg(self.result_fig, result_tab)
        self.result_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        toolbar_result = ttk.Frame(result_tab)
        toolbar_result.pack(fill=tk.X)
        NavigationToolbar2Tk(self.result_canvas, toolbar_result)
    
    # ===== è¾…åŠ©å‡½æ•° =====
    def toggle_sampling(self):
        if self.enable_sampling.get():
            self.max_samples_spinbox.config(state=tk.NORMAL)
        else:
            self.max_samples_spinbox.config(state=tk.DISABLED)
    
    def refresh_fields(self):
        train_shp = self.train_shp_path.get()
        if not train_shp or not os.path.exists(train_shp):
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è®­ç»ƒæ ·æœ¬æ–‡ä»¶ï¼")
            return
        
        fields = self.backend.get_shapefile_fields(train_shp)
        if fields:
            fields = [f for f in fields if f.lower() != 'geometry']
            
            self.class_attr_combo['values'] = fields
            self.name_attr_combo['values'] = fields
            
            if 'class' in fields:
                self.class_attr.set('class')
            elif 'Class' in fields:
                self.class_attr.set('Class')
            elif fields:
                self.class_attr.set(fields[0])
            
            if 'name' in fields:
                self.name_attr.set('name')
            elif 'Name' in fields:
                self.name_attr.set('Name')
            elif len(fields) > 1:
                self.name_attr.set(fields[1])
            elif fields:
                self.name_attr.set(fields[0])
            
            messagebox.showinfo("æˆåŠŸ", f"å·²åŠ è½½ {len(fields)} ä¸ªå­—æ®µ")
        else:
            messagebox.showerror("é”™è¯¯", "æ— æ³•è¯»å–å­—æ®µåˆ—è¡¨ï¼")
    
    def browse_image(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©å½±åƒæ–‡ä»¶",
            filetypes=[("GeoTIFF", "*.tif *.tiff"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.image_path.set(filename)
            self.status_var.set(f"å·²é€‰æ‹©å½±åƒ: {Path(filename).name}")
    
    def browse_train_shp(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©è®­ç»ƒæ ·æœ¬",
            filetypes=[("Shapefile", "*.shp"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.train_shp_path.set(filename)
            self.refresh_fields()
    
    def browse_val_shp(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©éªŒè¯æ ·æœ¬",
            filetypes=[("Shapefile", "*.shp"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.val_shp_path.set(filename)
    
    def browse_output(self):
        dirname = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
        if dirname:
            self.output_dir.set(dirname)
    
    def select_all_classifiers(self):
        for var in self.classifier_vars.values():
            var.set(True)
    
    def deselect_all_classifiers(self):
        for var in self.classifier_vars.values():
            var.set(False)
    
    def select_recommended(self):
        recommended = ["rf", "xgb", "et", "lgb", "linear_svc", "nystroem_svm"]
        for code, var in self.classifier_vars.items():
            var.set(code in recommended)
    
    def select_fast(self):
        fast = ["rf", "et", "dt", "xgb", "lgb", "nb", "lr", "sgd_svm", "linear_svc"]
        for code, var in self.classifier_vars.items():
            var.set(code in fast)
    
    def log(self, message):
        self.log_queue.put(message)
    
    def update_log(self):
        try:
            while True:
                message = self.log_queue.get_nowait()
                self.log_text.insert(tk.END, message + "\n")
                self.log_text.see(tk.END)
        except queue.Empty:
            pass
        self.root.after(100, self.update_log)
    
    def update_accuracy_plot(self):
        """æ›´æ–°ç²¾åº¦å¯¹æ¯”å›¾"""
        if not self.comparison_results:
            return
        
        df = pd.DataFrame(self.comparison_results)
        
        self.accuracy_fig.clear()
        
        # åˆ›å»ºå­å›¾
        ax1 = self.accuracy_fig.add_subplot(121)
        ax2 = self.accuracy_fig.add_subplot(122)
        
        # ç²¾åº¦å¯¹æ¯”
        x = np.arange(len(df))
        width = 0.35
        
        ax1.bar(x - width/2, df['è®­ç»ƒé›†ç²¾åº¦'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax1.bar(x + width/2, df['éªŒè¯é›†ç²¾åº¦'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax1.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax1.set_ylabel('ç²¾åº¦', fontsize=11)
        ax1.set_title('æ€»ä½“ç²¾åº¦å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        ax1.set_ylim([0, 1.05])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (train_acc, val_acc) in enumerate(zip(df['è®­ç»ƒé›†ç²¾åº¦'], df['éªŒè¯é›†ç²¾åº¦'])):
            ax1.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
            ax1.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', 
                    ha='center', va='bottom', fontsize=8)
        
        # Kappaå¯¹æ¯”
        ax2.bar(x - width/2, df['è®­ç»ƒé›†Kappa'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
        ax2.bar(x + width/2, df['éªŒè¯é›†Kappa'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
        
        ax2.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax2.set_ylabel('Kappaç³»æ•°', fontsize=11)
        ax2.set_title('Kappaç³»æ•°å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax2.set_xticks(x)
        ax2.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim([0, 1.05])
        
        self.accuracy_fig.tight_layout()
        self.accuracy_canvas.draw()
    
    def update_confusion_matrix(self, y_true, y_pred, class_names):
        """æ›´æ–°æ··æ·†çŸ©é˜µæ˜¾ç¤º"""
        self.cm_fig.clear()
        ax = self.cm_fig.add_subplot(111)
        
        cm = confusion_matrix(y_true, y_pred)
        
        # ç»˜åˆ¶çƒ­å›¾
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=class_names, yticklabels=class_names,
                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)
        ax.set_title('æœ€ä½³åˆ†ç±»å™¨æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
        
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        
        self.cm_fig.tight_layout()
        self.cm_canvas.draw()
    
    def update_time_plot(self):
        """æ›´æ–°æ—¶é—´å¯¹æ¯”å›¾"""
        if not self.comparison_results:
            return
        
        df = pd.DataFrame(self.comparison_results)
        
        self.time_fig.clear()
        ax = self.time_fig.add_subplot(111)
        
        x = np.arange(len(df))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, df['è®­ç»ƒæ—¶é—´(ç§’)'], width, label='è®­ç»ƒæ—¶é—´', 
                      alpha=0.8, color='lightgreen')
        bars2 = ax.bar(x + width/2, df['é¢„æµ‹æ—¶é—´(ç§’)'], width, label='é¢„æµ‹æ—¶é—´', 
                      alpha=0.8, color='lightcoral')
        
        ax.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
        ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=11)
        ax.set_title('è®­ç»ƒå’Œé¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=12, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}s', ha='center', va='bottom', fontsize=8)
        
        self.time_fig.tight_layout()
        self.time_canvas.draw()
    
    def update_result_preview(self, image_path, classified_path, class_names, class_colors):
        """æ›´æ–°åˆ†ç±»ç»“æœé¢„è§ˆ"""
        try:
            self.result_fig.clear()
            
            # è¯»å–å½±åƒå’Œåˆ†ç±»ç»“æœ
            img = rxr.open_rasterio(image_path, masked=True)
            classified = rxr.open_rasterio(classified_path)
            
            # åˆ›å»ºå­å›¾
            ax1 = self.result_fig.add_subplot(121)
            ax2 = self.result_fig.add_subplot(122)
            
            # æ˜¾ç¤ºåŸå§‹å½±åƒ
            if img.shape[0] >= 3:
                rgb_data = np.moveaxis(img.values[:3], 0, -1)
                p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))
                rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)
                ax1.imshow(rgb_display)
            else:
                ax1.imshow(img.values[0], cmap='gray')
            
            ax1.set_title('åŸå§‹é¥æ„Ÿå½±åƒ', fontsize=12, fontweight='bold')
            ax1.axis('off')
            
            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            classified_data = classified.values.squeeze()
            
            # è·å–ç±»åˆ«
            classes = np.unique(classified_data)
            classes = classes[classes > 0]
            
            # åˆ›å»ºé¢œè‰²æ˜ å°„
            colors = [class_colors.get(c, 'black') for c in classes]
            labels = [class_names.get(c, f'ç±»åˆ«_{c}') for c in classes]
            
            cmap = mcolors.ListedColormap(colors)
            bounds = np.append(classes, classes[-1] + 1) - 0.5
            norm = mcolors.BoundaryNorm(bounds, cmap.N)
            
            # èƒŒæ™¯è®¾ä¸ºé€æ˜
            display_data = classified_data.astype(float)
            display_data[classified_data == 0] = np.nan
            
            im = ax2.imshow(display_data, cmap=cmap, norm=norm)
            ax2.set_title('åˆ†ç±»ç»“æœï¼ˆæœ€ä½³åˆ†ç±»å™¨ï¼‰', fontsize=12, fontweight='bold')
            ax2.axis('off')
            
            # æ·»åŠ å›¾ä¾‹
            from matplotlib.patches import Patch
            legend_elements = [Patch(facecolor=color, label=label) 
                              for color, label in zip(colors, labels)]
            ax2.legend(handles=legend_elements, loc='upper left', 
                      bbox_to_anchor=(1.05, 1), fontsize=9)
            
            self.result_fig.tight_layout()
            self.result_canvas.draw()
            
        except Exception as e:
            self.log(f"é¢„è§ˆæ˜¾ç¤ºé”™è¯¯: {str(e)}")
    
    def export_to_excel(self, out_dir):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        if not HAS_OPENPYXL:
            self.log("âš ï¸  æœªå®‰è£…openpyxlï¼Œæ— æ³•å¯¼å‡ºExcel")
            return
        
        if not self.comparison_results:
            return
        
        try:
            df = pd.DataFrame(self.comparison_results)
            
            excel_path = out_dir / "classification_comparison.xlsx"
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # ä¸»ç»“æœè¡¨
                df.to_excel(writer, sheet_name='åˆ†ç±»å™¨å¯¹æ¯”', index=False)
                
                # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨
                workbook = writer.book
                worksheet = writer.sheets['åˆ†ç±»å™¨å¯¹æ¯”']
                
                # è®¾ç½®åˆ—å®½
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
                
                # æ·»åŠ ç»Ÿè®¡æ‘˜è¦è¡¨
                summary_data = {
                    'æŒ‡æ ‡': ['æœ€é«˜ç²¾åº¦', 'æœ€é«˜Kappa', 'æœ€å¿«è®­ç»ƒ', 'æœ€å¿«é¢„æµ‹'],
                    'åˆ†ç±»å™¨': [
                        df.loc[df['éªŒè¯é›†ç²¾åº¦'].idxmax(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['éªŒè¯é›†Kappa'].idxmax(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['è®­ç»ƒæ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°'],
                        df.loc[df['é¢„æµ‹æ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°']
                    ],
                    'æ•°å€¼': [
                        f"{df['éªŒè¯é›†ç²¾åº¦'].max():.4f}",
                        f"{df['éªŒè¯é›†Kappa'].max():.4f}",
                        f"{df['è®­ç»ƒæ—¶é—´(ç§’)'].min():.2f}ç§’",
                        f"{df['é¢„æµ‹æ—¶é—´(ç§’)'].min():.2f}ç§’"
                    ]
                }
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='æ€§èƒ½æ‘˜è¦', index=False)
            
            self.log(f"âœ“ ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_path}")
            
        except Exception as e:
            self.log(f"Excelå¯¼å‡ºå¤±è´¥: {str(e)}")
    
    def start_classification(self):
        """å¼€å§‹åˆ†ç±»"""
        # æ£€æŸ¥è¾“å…¥
        if not self.image_path.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼")
            return
        
        if not self.train_shp_path.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼")
            return
        
        if not self.class_attr.get():
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©ç±»åˆ«ç¼–å·å­—æ®µï¼")
            return
        
        selected_classifiers = [code for code, var in self.classifier_vars.items() if var.get()]
        if not selected_classifiers:
            messagebox.showerror("é”™è¯¯", "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼")
            return
        
        # æ€§èƒ½è­¦å‘Š
        all_classifiers = self.backend.get_all_classifiers()
        very_slow_clfs = []
        
        for code in selected_classifiers:
            if code in all_classifiers:
                speed_tag = all_classifiers[code][5]
                name = all_classifiers[code][1]
                if speed_tag == "very_slow":
                    very_slow_clfs.append(name)
        
        if very_slow_clfs:
            warning_msg = "âš ï¸ ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹éå¸¸æ…¢:\n"
            for clf in very_slow_clfs:
                warning_msg += f"  â€¢ {clf}\n"
            warning_msg += "\næ˜¯å¦ç»§ç»­?"
            
            if not messagebox.askyesno("æ€§èƒ½è­¦å‘Š", warning_msg, icon='warning'):
                return
        
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        self.is_running = True
        
        # æ¸…ç©º
        self.log_text.delete(1.0, tk.END)
        self.comparison_results = []
        
        self.log("="*80)
        self.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1")
        self.log("="*80)
        self.log(f"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª")
        self.log(f"èƒŒæ™¯å€¼: {self.background_value.get()}")
        self.log("")
        
        # åˆ‡æ¢åˆ°æ—¥å¿—æ ‡ç­¾é¡µ
        self.notebook.select(0)
        
        thread = threading.Thread(target=self.run_classification, args=(selected_classifiers,))
        thread.daemon = True
        thread.start()
    
    def stop_classification(self):
        self.is_running = False
        self.log("\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...")
        self.status_var.set("å·²åœæ­¢")
    
    def run_classification(self, selected_classifiers):
        """æ‰§è¡Œåˆ†ç±»ï¼ˆä¸»æµç¨‹ï¼‰"""
        try:
            out_dir = Path(self.output_dir.get())
            out_dir.mkdir(exist_ok=True)
            
            # è¯»å–å½±åƒ
            self.log(f"ğŸ“ è¯»å–å½±åƒ...")
            self.status_var.set("è¯»å–å½±åƒ...")
            img = rxr.open_rasterio(self.image_path.get(), masked=True)
            n_pixels = img.shape[1] * img.shape[2]
            self.log(f"   å°ºå¯¸: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ")
            
            if not self.is_running:
                return
            
            # è¯»å–ç±»åˆ«ä¿¡æ¯
            self.log(f"\nğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...")
            class_names, class_colors, _ = self.backend.get_class_info_from_shp(
                self.train_shp_path.get(), 
                self.class_attr.get(), 
                self.name_attr.get()
            )
            self.class_names_dict = class_names
            self.class_colors_dict = class_colors
            self.log(f"   ç±»åˆ«: {list(class_names.values())}")
            
            # æå–è®­ç»ƒæ ·æœ¬
            self.log(f"\nğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...")
            self.status_var.set("å¤„ç†è®­ç»ƒæ ·æœ¬...")
            train_mask = self.backend.rasterize_samples(
                self.train_shp_path.get(), img, self.class_attr.get()
            )
            
            max_samples = self.max_samples.get() if self.enable_sampling.get() else None
            
            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(
                img, train_mask, 
                ignore_background=self.ignore_background.get(),
                background_value=self.background_value.get(),
                max_samples=max_samples
            )
            
            self.log(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}")
            if n_nan > 0:
                self.log(f"   â””â”€ ç§»é™¤NaN: {n_nan:,}")
            if n_sampled > 0:
                self.log(f"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}")
            
            if not self.is_running:
                return
            
            # æå–éªŒè¯æ ·æœ¬
            val_exists = os.path.exists(self.val_shp_path.get())
            if val_exists:
                self.log(f"\nâœ… å¤„ç†éªŒè¯æ ·æœ¬...")
                val_mask = self.backend.rasterize_samples(
                    self.val_shp_path.get(), img, self.class_attr.get()
                )
                
                if self.ignore_background.get():
                    background_mask = self.backend.get_background_mask(
                        img, self.background_value.get()
                    )
                    valid_val = (val_mask > 0) & (~background_mask)
                else:
                    valid_val = val_mask > 0
                
                yv_true = val_mask[valid_val]
                self.log(f"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}")
            
            # åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°
            all_classifiers = self.backend.get_all_classifiers(
                self.n_estimators.get(), 
                fast_mode=self.fast_mode.get(),
                n_train_samples=len(y_train)
            )
            
            comparison_results = []
            total_start_time = time.time()
            best_accuracy = 0
            best_clf_code = None
            
            for i, clf_code in enumerate(selected_classifiers):
                if not self.is_running:
                    break
                
                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]
                
                self.log(f"\n{'='*80}")
                self.log(f"[{i+1}/{len(selected_classifiers)}] {clf_name}")
                self.log(f"{'='*80}")
                
                self.status_var.set(f"[{i+1}/{len(selected_classifiers)}] è®­ç»ƒ {clf_name}...")
                
                clf_dir = out_dir / clf_code
                clf_dir.mkdir(exist_ok=True)
                
                try:
                    # æ•°æ®é¢„å¤„ç†
                    label_encoder = None
                    scaler = None
                    X_train_use = X_train.copy()
                    y_train_use = y_train.copy()
                    
                    if needs_encoding:
                        self.log("   ğŸ”„ æ ‡ç­¾ç¼–ç ...")
                        label_encoder = LabelEncoder()
                        y_train_use = label_encoder.fit_transform(y_train)
                    
                    if needs_scaling:
                        self.log("   ğŸ“ ç‰¹å¾ç¼©æ”¾...")
                        scaler = StandardScaler()
                        X_train_use = scaler.fit_transform(X_train_use)
                    
                    # è®­ç»ƒ
                    self.log("   ğŸ”¨ è®­ç»ƒä¸­...")
                    train_start = time.time()
                    clf.fit(X_train_use, y_train_use)
                    train_time = time.time() - train_start
                    self.log(f"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’")
                    
                    # è®­ç»ƒé›†ç²¾åº¦
                    y_train_pred = clf.predict(X_train_use)
                    
                    if label_encoder is not None:
                        y_train_pred = label_encoder.inverse_transform(y_train_pred)
                    
                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)
                    self.log(f"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}")
                    
                    if not self.is_running:
                        break
                    
                    # é¢„æµ‹æ•´å¹…å½±åƒ
                    self.log("   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...")
                    self.status_var.set(f"[{i+1}/{len(selected_classifiers)}] é¢„æµ‹ {clf_name}...")
                    
                    pred_start = time.time()
                    classified_path = clf_dir / f"classified_{clf_code}.tif"
                    
                    def update_progress(progress):
                        self.progress_var.set(progress)
                    
                    self.backend.predict_by_block(
                        clf, img, classified_path, 
                        block_size=self.block_size.get(),
                        ignore_background=self.ignore_background.get(),
                        background_value=self.background_value.get(),
                        progress_callback=update_progress,
                        label_encoder=label_encoder,
                        scaler=scaler
                    )
                    
                    pred_time = time.time() - pred_start
                    self.log(f"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’")
                    
                    # éªŒè¯é›†ç²¾åº¦
                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan}
                    yv_pred = None
                    
                    if val_exists:
                        with rxr.open_rasterio(classified_path) as pred_img:
                            pred_arr = pred_img.values.squeeze()
                        
                        yv_pred = pred_arr[valid_val]
                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)
                        self.log(f"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}")
                        
                        # è®°å½•æœ€ä½³åˆ†ç±»å™¨
                        if val_metrics['overall_accuracy'] > best_accuracy:
                            best_accuracy = val_metrics['overall_accuracy']
                            best_clf_code = clf_code
                            self.best_result_path = classified_path
                            self.current_y_true = yv_true
                            self.current_y_pred = yv_pred
                    
                    # è®°å½•ç»“æœ
                    result = {
                        'åˆ†ç±»å™¨ä»£ç ': clf_code,
                        'åˆ†ç±»å™¨åç§°': clf_name,
                        'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],
                        'è®­ç»ƒé›†Kappa': train_metrics['kappa'],
                        'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],
                        'éªŒè¯é›†Kappa': val_metrics['kappa'],
                        'è®­ç»ƒæ—¶é—´(ç§’)': train_time,
                        'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,
                    }
                    comparison_results.append(result)
                    self.comparison_results = comparison_results
                    
                    # å®æ—¶æ›´æ–°å›¾è¡¨
                    self.root.after(0, self.update_accuracy_plot)
                    self.root.after(0, self.update_time_plot)
                    
                    self.log(f"   âœ… {clf_name} å®Œæˆ!")
                    
                except Exception as e:
                    self.log(f"   âŒ {clf_name} å¤±è´¥: {str(e)}")
                    continue
                
                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)
            
            # ç”ŸæˆæŠ¥å‘Š
            if comparison_results and self.is_running:
                total_time = time.time() - total_start_time
                
                self.log(f"\n{'='*80}")
                self.log("ğŸ“ ç”ŸæˆæŠ¥å‘Š...")
                
                comparison_df = pd.DataFrame(comparison_results)
                
                # ä¿å­˜CSV
                comparison_df.to_csv(out_dir / "classifier_comparison.csv", 
                                   index=False, encoding='utf-8-sig')
                
                # å¯¼å‡ºExcel
                self.export_to_excel(out_dir)
                
                # æ–‡å­—æŠ¥å‘Š
                with open(out_dir / "comparison_summary.txt", 'w', encoding='utf-8') as f:
                    f.write("é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\n")
                    f.write("="*70 + "\n\n")
                    f.write(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"å½±åƒ: {img.shape[1]}Ã—{img.shape[2]}\n")
                    f.write(f"è®­ç»ƒæ ·æœ¬: {len(y_train):,}\n")
                    f.write(f"æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\n")
                    f.write(f"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\n\n")
                    
                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)
                    f.write("éªŒè¯é›†ç²¾åº¦æ’å:\n")
                    f.write("-"*70 + "\n")
                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):
                        f.write(f"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - "
                               f"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}\n")
                
                # æ›´æ–°æ··æ·†çŸ©é˜µ
                if self.current_y_true is not None and self.current_y_pred is not None:
                    val_classes = sorted(np.unique(self.current_y_true))
                    val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]
                    self.root.after(0, lambda: self.update_confusion_matrix(
                        self.current_y_true, self.current_y_pred, val_class_names
                    ))
                
                # æ›´æ–°ç»“æœé¢„è§ˆ
                if self.best_result_path:
                    self.root.after(0, lambda: self.update_result_preview(
                        self.image_path.get(), self.best_result_path, 
                        class_names, class_colors
                    ))
                
                self.log("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
                self.log(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
                
                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]
                self.log(f"\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})")
                
                self.status_var.set(f"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']}")
                
                # åˆ‡æ¢åˆ°ç²¾åº¦å¯¹æ¯”æ ‡ç­¾é¡µ
                self.root.after(0, lambda: self.notebook.select(1))
                
                messagebox.showinfo("ä»»åŠ¡å®Œæˆ", 
                    f"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\n\n"
                    f"âœ… æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\n"
                    f"ğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\n"
                    f"ğŸ“Š ç»“æœå·²å¯¼å‡ºä¸ºExcelå’ŒCSV")
            
        except Exception as e:
            self.log(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            self.log(traceback.format_exc())
            messagebox.showerror("é”™è¯¯", f"å‘ç”Ÿé”™è¯¯:\n{str(e)}")
            self.status_var.set("âŒ é”™è¯¯")
        
        finally:
            self.start_btn.config(state=tk.NORMAL)
            self.stop_btn.config(state=tk.DISABLED)
            self.progress_var.set(0)
            self.is_running = False
    
    def open_result_dir(self):
        """æ‰“å¼€ç»“æœç›®å½•"""
        out_dir = Path(self.output_dir.get())
        if out_dir.exists():
            import subprocess
            import platform
            
            if platform.system() == "Windows":
                os.startfile(out_dir)
            elif platform.system() == "Darwin":
                subprocess.Popen(["open", out_dir])
            else:
                subprocess.Popen(["xdg-open", out_dir])
        else:
            messagebox.showwarning("è­¦å‘Š", "ç»“æœç›®å½•ä¸å­˜åœ¨ï¼")

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
def main():
    """ç¨‹åºå…¥å£"""
    print("="*80)
    print("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ")
    print("="*80)
    print("\næ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...")
    
    root = tk.Tk()
    app = ClassificationGUI(root)
    
    # æ¬¢è¿ä¿¡æ¯
    app.log("="*80)
    app.log("  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ")
    app.log("="*80)
    app.log("\nä¸»è¦ç‰¹æ€§:")
    app.log("  âœ“ è‡ªå®šä¹‰èƒŒæ™¯å€¼è¾“å…¥")
    app.log("  âœ“ å­—æ®µä¸‹æ‹‰æ¡†è‡ªåŠ¨è¯†åˆ«")
    app.log("  âœ“ å®æ—¶ç²¾åº¦å¯¹æ¯”å›¾è¡¨")
    app.log("  âœ“ æ··æ·†çŸ©é˜µå¯è§†åŒ–")
    app.log("  âœ“ åˆ†ç±»ç»“æœé¢„è§ˆ")
    app.log("  âœ“ Excelæ ¼å¼æŠ¥å‘Šå¯¼å‡º")
    app.log("\nä½¿ç”¨æµç¨‹:")
    app.log("  1. é€‰æ‹©å½±åƒå’Œæ ·æœ¬æ–‡ä»¶")
    app.log("  2. ç‚¹å‡»'åˆ·æ–°å­—æ®µåˆ—è¡¨'é€‰æ‹©ç±»åˆ«å­—æ®µ")
    app.log("  3. è®¾ç½®èƒŒæ™¯å€¼å’Œå…¶ä»–å‚æ•°")
    app.log("  4. é€‰æ‹©åˆ†ç±»å™¨")
    app.log("  5. ç‚¹å‡»'å¼€å§‹åˆ†ç±»'")
    app.log("  6. æŸ¥çœ‹å³ä¾§å®æ—¶å›¾è¡¨")
    app.log("="*80)
    app.log("")
    
    print("\nâœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!")
    
    root.mainloop()

if __name__ == "__main__":
    main()