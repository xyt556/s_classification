{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325e179b",
   "metadata": {},
   "source": [
    "# 类别默认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b6cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 14:34:03,665 [INFO] 开始监督分类任务...\n",
      "2025-10-15 14:34:03,666 [INFO] 正在读取类别信息...\n",
      "2025-10-15 14:34:03,673 [INFO] 检测到类别: ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9', 'Class_10', 'Class_11']\n",
      "2025-10-15 14:34:03,683 [INFO] 影像尺寸: (14, 1024, 2098), 波段数: 14\n",
      "2025-10-15 14:34:03,684 [INFO] 正在处理训练样本...\n",
      "2025-10-15 14:34:03,949 [INFO] 训练样本数: 15041\n",
      "2025-10-15 14:34:03,951 [INFO] 使用分类器: RandomForestClassifier\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.2s finished\n",
      "2025-10-15 14:34:05,992 [INFO] 模型训练完成。\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "2025-10-15 14:34:06,800 [INFO] 训练集总体精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-15 14:34:09,438 [INFO] 开始分块预测...\n",
      "Block predicting:   0%|          | 0/2 [00:00<?, ?it/s][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    8.0s finished\n",
      "Block predicting:  50%|█████     | 1/2 [00:08<00:08,  8.29s/it][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    8.0s finished\n",
      "Block predicting: 100%|██████████| 2/2 [00:16<00:00,  8.33s/it]\n",
      "2025-10-15 14:34:26,112 [INFO] 分类结果保存至: results_v2\\classified_result.tif\n",
      "2025-10-15 14:34:26,112 [INFO] 生成分类结果可视化...\n",
      "2025-10-15 14:34:28,832 [INFO] 正在进行验证...\n",
      "2025-10-15 14:34:29,477 [INFO] 验证集总体精度: 0.8824, Kappa: 0.8382\n",
      "2025-10-15 14:34:31,213 [INFO] 生成分类统计报告...\n",
      "2025-10-15 14:34:31,759 [INFO] 全部任务完成，用时 28.1 秒。\n",
      "2025-10-15 14:34:31,760 [INFO] 所有结果已保存至: d:\\code313\\Geo_programe\\rasterio\\RF\\results_v2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用遥感影像监督分类系统\n",
    "-------------------------------------------------\n",
    "功能：\n",
    "1. 自动读取多波段遥感影像；\n",
    "2. 从矢量样本中提取训练/验证数据；\n",
    "3. 支持随机森林 / SVM / XGBoost 分类；\n",
    "4. 采用分块预测模式；\n",
    "5. 输出分类结果 GeoTIFF；\n",
    "6. 自动生成分类报告与混淆矩阵；\n",
    "7. 显示分类影像和精度评价结果。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]  # 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 支持负号显示\n",
    "\n",
    "# ------------------ 参数配置 ------------------\n",
    "IMAGE_PATH = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\2017_09_05_stack.tif\"\n",
    "TRAIN_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\cal.shp\"\n",
    "VAL_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\val.shp\"\n",
    "ATTRIBUTE = \"class\"\n",
    "OUT_DIR = Path(\"./results_v2\")\n",
    "\n",
    "CLASSIFIER = \"rf\"  # 可选: \"rf\", \"svm\", \"xgb\"\n",
    "N_ESTIMATORS = 300\n",
    "BLOCK_SIZE = 512\n",
    "USE_GPU = False\n",
    "\n",
    "# 自动生成颜色配置\n",
    "COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                'darkred', 'purple', 'orange', 'pink', 'brown', \n",
    "                'cyan', 'magenta', 'lime', 'navy', 'teal']\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------ 日志系统 ------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"classification_log.txt\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ------------------ 辅助函数 ------------------\n",
    "def get_class_info_from_shp(shp_path, attribute):\n",
    "    \"\"\"从shp文件中获取类别信息和自动生成的颜色\"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    unique_classes = sorted(gdf[attribute].unique())\n",
    "    \n",
    "    # 生成类别名称映射（直接用class值）\n",
    "    class_names = {cls: f'Class_{cls}' for cls in unique_classes}\n",
    "    \n",
    "    # 生成颜色映射\n",
    "    class_colors = {}\n",
    "    for i, cls in enumerate(unique_classes):\n",
    "        class_colors[cls] = COLOR_PALETTE[i % len(COLOR_PALETTE)]\n",
    "    \n",
    "    return class_names, class_colors, unique_classes\n",
    "\n",
    "def rasterize_samples(shp, ref_img, attr):\n",
    "    \"\"\"将矢量样本栅格化为与影像对齐的数组\"\"\"\n",
    "    import rasterio.features\n",
    "    \n",
    "    gdf = gpd.read_file(shp)\n",
    "    gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "    \n",
    "    arr = rasterio.features.rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=ref_img.shape[1:],\n",
    "        transform=ref_img.rio.transform(),\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=\"uint16\"\n",
    "    )\n",
    "    return arr\n",
    "\n",
    "def extract_samples(image, mask):\n",
    "    \"\"\"根据掩膜提取样本特征与标签\"\"\"\n",
    "    data = np.moveaxis(image.values, 0, -1)  # (bands, rows, cols) → (rows, cols, bands)\n",
    "    valid = mask > 0\n",
    "    X = data[valid]\n",
    "    y = mask[valid]\n",
    "    return X, y\n",
    "\n",
    "def get_classifier(name):\n",
    "    \"\"\"构造分类器\"\"\"\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=N_ESTIMATORS, n_jobs=-1, oob_score=True, verbose=1\n",
    "        )\n",
    "    elif name == \"svm\":\n",
    "        return SVC(kernel=\"rbf\", probability=True)\n",
    "    elif name == \"xgb\":\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            return XGBClassifier(\n",
    "                n_estimators=N_ESTIMATORS, learning_rate=0.1, max_depth=8, n_jobs=-1\n",
    "            )\n",
    "        except ImportError:\n",
    "            raise ImportError(\"未安装 xgboost，请先运行 pip install xgboost\")\n",
    "    else:\n",
    "        raise ValueError(f\"未知分类器类型: {name}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"绘制详细的混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 计算百分比\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建热图\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 同时保存百分比版本\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '百分比 (%)'})\n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵 (百分比)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.png', '_percent.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def comprehensive_evaluation(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"全方位精度评价\"\"\"\n",
    "    # 计算各项指标\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # 创建详细报告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "    \n",
    "    # 创建精度评价表格\n",
    "    eval_df = pd.DataFrame({\n",
    "        '类别': class_names,\n",
    "        '精确率 (Precision)': precision,\n",
    "        '召回率 (Recall)': recall,\n",
    "        'F1分数': f1,\n",
    "        '样本数量': np.bincount(y_true)[1:len(class_names)+1]  # 从1开始计数\n",
    "    })\n",
    "    \n",
    "    # 保存详细报告\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"           遥感影像分类精度评价报告\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"总体精度 (Overall Accuracy): {overall_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Kappa系数: {kappa:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别精度评价:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(eval_df.to_string(index=False, float_format='%.4f'))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"详细分类报告:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 绘制精度指标条形图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, precision, width, label='精确率', alpha=0.8)\n",
    "    plt.bar(x, recall, width, label='召回率', alpha=0.8)\n",
    "    plt.bar(x + width, f1, width, label='F1分数', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('分数')\n",
    "    plt.title('各类别分类精度指标')\n",
    "    plt.xticks(x, class_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.txt', '_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return overall_accuracy, kappa, eval_df\n",
    "\n",
    "def plot_classification_results(original_img, classified_img, class_names, class_colors, save_path):\n",
    "    \"\"\"显示原始影像和分类结果\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 显示原始影像 (使用前3个波段作为RGB)\n",
    "    if original_img.shape[0] >= 3:\n",
    "        rgb_data = np.moveaxis(original_img.values[:3], 0, -1)\n",
    "        # 数据标准化显示\n",
    "        p2, p98 = np.percentile(rgb_data, (2, 98))\n",
    "        rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "        ax1.imshow(rgb_display)\n",
    "    else:\n",
    "        # 单波段影像显示\n",
    "        ax1.imshow(original_img.values[0], cmap='gray')\n",
    "    \n",
    "    ax1.set_title('原始遥感影像', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 显示分类结果\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    \n",
    "    # 创建分类图例\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]  # 排除背景值\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    colors = [class_colors.get(c, 'black') for c in classes]\n",
    "    labels = [class_names.get(c, f'Class_{c}') for c in classes]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax2.imshow(classified_data, cmap=cmap, norm=norm)\n",
    "    ax2.set_title('分类结果', fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 添加图例\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for color, label in zip(colors, labels)]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(clf, feature_names, save_path):\n",
    "    \"\"\"绘制特征重要性图（适用于随机森林和XGBoost）\"\"\"\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('特征重要性排序', fontsize=14, fontweight='bold')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.xlabel('特征波段')\n",
    "        plt.ylabel('重要性')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def predict_by_block(model, image, out_path, block_size=BLOCK_SIZE):\n",
    "    \"\"\"分块预测整幅影像\"\"\"\n",
    "    import rasterio\n",
    "    \n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    \n",
    "    # 修正：正确获取栅格配置文件\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'uint16',\n",
    "        'nodata': 0,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'count': 1,\n",
    "        'crs': image.rio.crs,\n",
    "        'transform': image.rio.transform(),\n",
    "        'compress': 'lzw',\n",
    "        'tiled': True,\n",
    "        'blockxsize': min(block_size, width),\n",
    "        'blockysize': min(block_size, block_size)\n",
    "    }\n",
    "\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        for y in tqdm(range(0, height, block_size), desc=\"Block predicting\"):\n",
    "            h = min(block_size, height - y)\n",
    "            \n",
    "            # 读取当前块的数据\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data = data.reshape(-1, data.shape[-1])\n",
    "            data = np.nan_to_num(data)\n",
    "            \n",
    "            # 预测\n",
    "            preds = model.predict(data).reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            # 写入结果\n",
    "            dst.write(preds, 1, window=rasterio.windows.Window(0, y, width, h))\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    logger.info(\"开始监督分类任务...\")\n",
    "\n",
    "    # 0. 从训练样本shp文件中获取类别信息\n",
    "    logger.info(\"正在读取类别信息...\")\n",
    "    class_names, class_colors, train_classes = get_class_info_from_shp(TRAIN_SHP, ATTRIBUTE)\n",
    "    logger.info(f\"检测到类别: {list(class_names.values())}\")\n",
    "\n",
    "    # 1. 读取影像\n",
    "    img = rxr.open_rasterio(IMAGE_PATH, masked=True)\n",
    "    logger.info(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "\n",
    "    # 2. 训练样本栅格化与提取\n",
    "    logger.info(\"正在处理训练样本...\")\n",
    "    train_mask = rasterize_samples(TRAIN_SHP, img, ATTRIBUTE)\n",
    "    X_train, y_train = extract_samples(img, train_mask)\n",
    "    logger.info(f\"训练样本数: {len(y_train)}\")\n",
    "\n",
    "    # 3. 训练分类器\n",
    "    clf = get_classifier(CLASSIFIER)\n",
    "    logger.info(f\"使用分类器: {clf.__class__.__name__}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    logger.info(\"模型训练完成。\")\n",
    "\n",
    "    # 4. 精度评估（训练集）\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    # 获取实际存在的类别\n",
    "    actual_train_classes = sorted(np.unique(y_train))\n",
    "    train_class_names = [class_names.get(c, f'Class_{c}') for c in actual_train_classes if c > 0]\n",
    "    \n",
    "    # 全方位精度评价\n",
    "    overall_acc, kappa, eval_df = comprehensive_evaluation(\n",
    "        y_train, y_pred_train, train_class_names, OUT_DIR / \"train_evaluation.txt\"\n",
    "    )\n",
    "    logger.info(f\"训练集总体精度: {overall_acc:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 绘制训练集混淆矩阵\n",
    "    plot_confusion_matrix(y_train, y_pred_train, train_class_names, OUT_DIR / \"train_cm.png\")\n",
    "\n",
    "    # 5. 特征重要性分析（如果适用）\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        feature_names = [f'波段{i+1}' for i in range(X_train.shape[1])]\n",
    "        plot_feature_importance(clf, feature_names, OUT_DIR / \"feature_importance.png\")\n",
    "\n",
    "    # 6. 分块预测整幅影像\n",
    "    logger.info(\"开始分块预测...\")\n",
    "    classified_path = OUT_DIR / \"classified_result.tif\"\n",
    "    predict_by_block(clf, img, classified_path)\n",
    "    logger.info(f\"分类结果保存至: {classified_path}\")\n",
    "\n",
    "    # 7. 显示分类结果\n",
    "    logger.info(\"生成分类结果可视化...\")\n",
    "    classified_img = rxr.open_rasterio(classified_path)\n",
    "    plot_classification_results(img, classified_img, class_names, class_colors, OUT_DIR / \"classification_visualization.png\")\n",
    "\n",
    "    # 8. 验证阶段\n",
    "    if os.path.exists(VAL_SHP):\n",
    "        logger.info(\"正在进行验证...\")\n",
    "        val_mask = rasterize_samples(VAL_SHP, img, ATTRIBUTE)\n",
    "        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "            pred_arr = pred_img.values.squeeze()\n",
    "        \n",
    "        Xv = pred_arr[val_mask > 0]\n",
    "        yv = val_mask[val_mask > 0]\n",
    "        \n",
    "        # 验证集全方位精度评价\n",
    "        val_classes = sorted(np.unique(yv))\n",
    "        val_class_names = [class_names.get(c, f'Class_{c}') for c in val_classes if c > 0]\n",
    "        \n",
    "        val_overall_acc, val_kappa, val_eval_df = comprehensive_evaluation(\n",
    "            yv, Xv, val_class_names, OUT_DIR / \"validation_evaluation.txt\"\n",
    "        )\n",
    "        logger.info(f\"验证集总体精度: {val_overall_acc:.4f}, Kappa: {val_kappa:.4f}\")\n",
    "        \n",
    "        # 绘制验证集混淆矩阵\n",
    "        plot_confusion_matrix(yv, Xv, val_class_names, OUT_DIR / \"val_cm.png\")\n",
    "\n",
    "        # 生成综合报告\n",
    "        with open(OUT_DIR / \"comprehensive_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"遥感影像分类综合报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"分类器: {clf.__class__.__name__}\\n\")\n",
    "            f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "            f.write(f\"验证样本数: {len(yv)}\\n\")\n",
    "            f.write(f\"类别属性字段: {ATTRIBUTE}\\n\")\n",
    "            f.write(f\"检测到的类别: {list(class_names.values())}\\n\\n\")\n",
    "            \n",
    "            f.write(\"精度评价汇总:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"训练集总体精度: {overall_acc:.4f}\\n\")\n",
    "            f.write(f\"训练集Kappa系数: {kappa:.4f}\\n\")\n",
    "            f.write(f\"验证集总体精度: {val_overall_acc:.4f}\\n\")\n",
    "            f.write(f\"验证集Kappa系数: {val_kappa:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别验证精度:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(val_eval_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "    # 9. 生成分类统计报告\n",
    "    logger.info(\"生成分类统计报告...\")\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    unique, counts = np.unique(classified_data[classified_data > 0], return_counts=True)\n",
    "    total_pixels = np.sum(counts)\n",
    "    \n",
    "    stats_df = pd.DataFrame({\n",
    "        '类别编号': unique,\n",
    "        '类别名称': [class_names.get(c, f'Class_{c}') for c in unique],\n",
    "        '像元数量': counts,\n",
    "        '面积占比 (%)': (counts / total_pixels * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    stats_df.to_csv(OUT_DIR / \"classification_statistics.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 绘制面积占比饼图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(stats_df['面积占比 (%)'], labels=stats_df['类别名称'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('分类结果面积占比分布', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / \"area_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 10. 保存类别信息\n",
    "    class_info_df = pd.DataFrame({\n",
    "        '类别编号': list(class_names.keys()),\n",
    "        '类别名称': list(class_names.values()),\n",
    "        '显示颜色': [class_colors.get(c, 'black') for c in class_names.keys()]\n",
    "    })\n",
    "    class_info_df.to_csv(OUT_DIR / \"class_information.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    logger.info(f\"全部任务完成，用时 {time.time()-t0:.1f} 秒。\")\n",
    "    logger.info(f\"所有结果已保存至: {OUT_DIR.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42c561",
   "metadata": {},
   "source": [
    "# 类别名称从训练数据读取name字段，同时对分类影像进行后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447371e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 07:58:08,220 [INFO] 开始监督分类任务...\n",
      "2025-10-16 07:58:08,222 [INFO] 正在读取类别信息...\n",
      "2025-10-16 07:58:08,377 [INFO] 检测到类别: ['类1', '类2', '类3', '类4', '类5', '类6', '类7', '类8', '类9', '类10', '类11']\n",
      "2025-10-16 07:58:08,443 [INFO] 影像尺寸: (14, 1024, 2098), 波段数: 14\n",
      "2025-10-16 07:58:08,446 [INFO] 影像坐标系: EPSG:32633\n",
      "2025-10-16 07:58:08,447 [INFO] 影像变换参数: | 0.20, 0.00, 351916.64|\n",
      "| 0.00,-0.20, 5997247.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "2025-10-16 07:58:08,448 [INFO] 单个像元面积: 0.04 平方米 (0.000000 平方千米)\n",
      "2025-10-16 07:58:08,448 [INFO] 正在处理训练样本...\n",
      "2025-10-16 07:58:08,717 [INFO] 训练样本数: 15041\n",
      "2025-10-16 07:58:08,719 [INFO] 使用分类器: RandomForestClassifier\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.4s finished\n",
      "2025-10-16 07:58:10,887 [INFO] 模型训练完成。\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "2025-10-16 07:58:11,753 [INFO] 训练集总体精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 07:58:14,188 [INFO] 开始分块预测...\n",
      "2025-10-16 07:58:14,195 [INFO] GDAL signalled an error: err_no=4, msg='Unable to open results_v2\\\\classified_result.tif to obtain file list.'\n",
      "Block predicting:   0%|          | 0/2 [00:00<?, ?it/s][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    8.2s finished\n",
      "Block predicting:  50%|█████     | 1/2 [00:08<00:08,  8.49s/it][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    8.1s finished\n",
      "Block predicting: 100%|██████████| 2/2 [00:16<00:00,  8.45s/it]\n",
      "2025-10-16 07:58:31,099 [INFO] 分类结果保存至: results_v2\\classified_result.tif\n",
      "2025-10-16 07:58:31,100 [INFO] 生成原始分类结果可视化...\n",
      "2025-10-16 07:58:33,678 [INFO] 计算原始分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3189096214.py:552: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3189096214.py:553: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 07:58:34,695 [INFO] 原始分类总面积: 0.0859 平方千米\n",
      "2025-10-16 07:58:34,697 [INFO] 开始后处理...\n",
      "2025-10-16 07:58:34,698 [INFO] 后处理参数: 最小图斑大小=10, 形态学操作=opening, 核大小=3\n",
      "2025-10-16 07:58:34,699 [INFO] 开始后处理分类结果...\n",
      "2025-10-16 07:58:35,788 [INFO] 后处理完成: 原始非零像元数 2148352, 处理后非零像元数 1619493\n",
      "2025-10-16 07:58:35,789 [INFO] 后处理去除了 528859 个像元 (24.62%)\n",
      "2025-10-16 07:58:35,838 [INFO] 后处理结果保存至: results_v2\\classified_result_postprocessed.tif\n",
      "2025-10-16 07:58:35,839 [INFO] 生成后处理分类结果可视化...\n",
      "2025-10-16 07:58:38,625 [INFO] 计算后处理分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3189096214.py:552: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3189096214.py:553: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 07:58:39,624 [INFO] 后处理分类总面积: 0.0648 平方千米\n",
      "2025-10-16 07:58:39,637 [INFO] 正在进行验证...\n",
      "2025-10-16 07:58:40,309 [INFO] 验证集总体精度: 0.8803, Kappa: 0.8352\n",
      "2025-10-16 07:58:42,063 [INFO] 全部任务完成，用时 33.8 秒。\n",
      "2025-10-16 07:58:42,064 [INFO] 所有结果已保存至: d:\\code313\\Geo_programe\\rasterio\\RF\\results_v2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用遥感影像监督分类系统\n",
    "-------------------------------------------------\n",
    "功能：\n",
    "1. 自动读取多波段遥感影像；\n",
    "2. 从矢量样本中提取训练/验证数据；\n",
    "3. 支持随机森林 / SVM / XGBoost 分类；\n",
    "4. 采用分块预测模式；\n",
    "5. 输出分类结果 GeoTIFF；\n",
    "6. 自动生成分类报告与混淆矩阵；\n",
    "7. 显示分类影像和精度评价结果；\n",
    "8. 分类面积统计（平方千米）；\n",
    "9. 后处理功能（去除小图斑、形态学操作）。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]  # 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 支持负号显示\n",
    "\n",
    "# ------------------ 参数配置 ------------------\n",
    "IMAGE_PATH = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\2017_09_05_stack.tif\"\n",
    "TRAIN_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\cal.shp\"\n",
    "VAL_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\val.shp\"\n",
    "CLASS_ATTRIBUTE = \"class\"  # 类别编号字段\n",
    "NAME_ATTRIBUTE = \"name\"    # 类别名称字段\n",
    "OUT_DIR = Path(\"./results_v2\")\n",
    "\n",
    "CLASSIFIER = \"rf\"  # 可选: \"rf\", \"svm\", \"xgb\"\n",
    "N_ESTIMATORS = 300\n",
    "BLOCK_SIZE = 512\n",
    "USE_GPU = False\n",
    "\n",
    "# 后处理参数\n",
    "POSTPROCESSING = True  # 是否进行后处理\n",
    "MIN_PATCH_SIZE = 10    # 最小图斑大小（像元数），小于此值的图斑将被去除\n",
    "MORPHOLOGY_OPERATION = \"opening\"  # 形态学操作: \"opening\"（开运算）, \"closing\"（闭运算）, \"both\"（两者都）, \"none\"（无）\n",
    "MORPHOLOGY_SIZE = 3     # 形态学操作核大小\n",
    "\n",
    "# 预定义颜色映射（可根据需要扩展）\n",
    "LANDUSE_COLORS = {\n",
    "    # 水体相关\n",
    "    \"水体\": \"lightblue\",\n",
    "    \"河流\": \"blue\",\n",
    "    \"湖泊\": \"deepskyblue\",\n",
    "    \"水库\": \"dodgerblue\",\n",
    "    \"海洋\": \"navy\",\n",
    "    \n",
    "    # 植被相关\n",
    "    \"植被\": \"forestgreen\",\n",
    "    \"森林\": \"darkgreen\",\n",
    "    \"草地\": \"limegreen\",\n",
    "    \"农田\": \"yellowgreen\",\n",
    "    \"耕地\": \"olivedrab\",\n",
    "    \n",
    "    # 建筑相关\n",
    "    \"建筑\": \"gray\",\n",
    "    \"城市\": \"dimgray\",\n",
    "    \"居民地\": \"slategray\",\n",
    "    \"工业区\": \"darkgray\",\n",
    "    \n",
    "    # 其他地物\n",
    "    \"裸地\": \"tan\",\n",
    "    \"沙地\": \"wheat\",\n",
    "    \"岩石\": \"sienna\",\n",
    "    \"雪\": \"white\",\n",
    "    \"云\": \"ghostwhite\",\n",
    "    \n",
    "    # 默认颜色（如果上述未匹配）\n",
    "    \"其他\": \"darkred\"\n",
    "}\n",
    "\n",
    "# 自动生成颜色配置（用于未匹配的类别）\n",
    "COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                'darkred', 'purple', 'orange', 'pink', 'brown', \n",
    "                'cyan', 'magenta', 'lime', 'navy', 'teal']\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------ 日志系统 ------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"classification_log.txt\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ------------------ 辅助函数 ------------------\n",
    "def get_class_info_from_shp(shp_path, class_attr, name_attr):\n",
    "    \"\"\"从shp文件中获取类别信息和自动生成的颜色\"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    \n",
    "    # 检查是否存在名称字段\n",
    "    if name_attr not in gdf.columns:\n",
    "        logger.warning(f\"shp文件中没有找到 '{name_attr}' 字段，将使用类别编号作为名称\")\n",
    "        # 如果没有名称字段，使用类别编号作为名称\n",
    "        gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "    \n",
    "    # 获取唯一的类别编号和对应的名称\n",
    "    class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "    class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "    \n",
    "    # 生成颜色映射\n",
    "    class_colors = {}\n",
    "    for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "        # 尝试从预定义颜色中匹配\n",
    "        color_found = False\n",
    "        for key, color in LANDUSE_COLORS.items():\n",
    "            if key in class_name:\n",
    "                class_colors[class_id] = color\n",
    "                color_found = True\n",
    "                break\n",
    "        \n",
    "        # 如果没有匹配到预定义颜色，使用自动分配的颜色\n",
    "        if not color_found:\n",
    "            class_colors[class_id] = COLOR_PALETTE[i % len(COLOR_PALETTE)]\n",
    "    \n",
    "    unique_classes = sorted(class_names.keys())\n",
    "    \n",
    "    return class_names, class_colors, unique_classes\n",
    "\n",
    "def rasterize_samples(shp, ref_img, attr):\n",
    "    \"\"\"将矢量样本栅格化为与影像对齐的数组\"\"\"\n",
    "    import rasterio.features\n",
    "    \n",
    "    gdf = gpd.read_file(shp)\n",
    "    gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "    \n",
    "    arr = rasterio.features.rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=ref_img.shape[1:],\n",
    "        transform=ref_img.rio.transform(),\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=\"uint16\"\n",
    "    )\n",
    "    return arr\n",
    "\n",
    "def extract_samples(image, mask):\n",
    "    \"\"\"根据掩膜提取样本特征与标签\"\"\"\n",
    "    data = np.moveaxis(image.values, 0, -1)  # (bands, rows, cols) → (rows, cols, bands)\n",
    "    valid = mask > 0\n",
    "    X = data[valid]\n",
    "    y = mask[valid]\n",
    "    return X, y\n",
    "\n",
    "def get_classifier(name):\n",
    "    \"\"\"构造分类器\"\"\"\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=N_ESTIMATORS, n_jobs=-1, oob_score=True, verbose=1\n",
    "        )\n",
    "    elif name == \"svm\":\n",
    "        return SVC(kernel=\"rbf\", probability=True)\n",
    "    elif name == \"xgb\":\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            return XGBClassifier(\n",
    "                n_estimators=N_ESTIMATORS, learning_rate=0.1, max_depth=8, n_jobs=-1\n",
    "            )\n",
    "        except ImportError:\n",
    "            raise ImportError(\"未安装 xgboost，请先运行 pip install xgboost\")\n",
    "    else:\n",
    "        raise ValueError(f\"未知分类器类型: {name}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"绘制详细的混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 计算百分比\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建热图\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 同时保存百分比版本\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '百分比 (%)'})\n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵 (百分比)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.png', '_percent.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def comprehensive_evaluation(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"全方位精度评价\"\"\"\n",
    "    # 计算各项指标\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # 创建详细报告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "    \n",
    "    # 创建精度评价表格\n",
    "    eval_df = pd.DataFrame({\n",
    "        '类别': class_names,\n",
    "        '精确率 (Precision)': precision,\n",
    "        '召回率 (Recall)': recall,\n",
    "        'F1分数': f1,\n",
    "        '样本数量': np.bincount(y_true)[1:len(class_names)+1]  # 从1开始计数\n",
    "    })\n",
    "    \n",
    "    # 保存详细报告\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"           遥感影像分类精度评价报告\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"总体精度 (Overall Accuracy): {overall_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Kappa系数: {kappa:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别精度评价:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(eval_df.to_string(index=False, float_format='%.4f'))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"详细分类报告:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 绘制精度指标条形图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, precision, width, label='精确率', alpha=0.8)\n",
    "    plt.bar(x, recall, width, label='召回率', alpha=0.8)\n",
    "    plt.bar(x + width, f1, width, label='F1分数', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('分数')\n",
    "    plt.title('各类别分类精度指标')\n",
    "    plt.xticks(x, class_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.txt', '_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return overall_accuracy, kappa, eval_df\n",
    "\n",
    "def plot_classification_results(original_img, classified_img, class_names, class_colors, save_path, title_suffix=\"\"):\n",
    "    \"\"\"显示原始影像和分类结果\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 显示原始影像 (使用前3个波段作为RGB)\n",
    "    if original_img.shape[0] >= 3:\n",
    "        rgb_data = np.moveaxis(original_img.values[:3], 0, -1)\n",
    "        # 数据标准化显示\n",
    "        p2, p98 = np.percentile(rgb_data, (2, 98))\n",
    "        rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "        ax1.imshow(rgb_display)\n",
    "    else:\n",
    "        # 单波段影像显示\n",
    "        ax1.imshow(original_img.values[0], cmap='gray')\n",
    "    \n",
    "    ax1.set_title('原始遥感影像', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 显示分类结果\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    \n",
    "    # 创建分类图例\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]  # 排除背景值\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    colors = [class_colors.get(c, 'black') for c in classes]\n",
    "    labels = [class_names.get(c, f'未知类别_{c}') for c in classes]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax2.imshow(classified_data, cmap=cmap, norm=norm)\n",
    "    title = '分类结果' + title_suffix\n",
    "    ax2.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 添加图例\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for color, label in zip(colors, labels)]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(clf, feature_names, save_path):\n",
    "    \"\"\"绘制特征重要性图（适用于随机森林和XGBoost）\"\"\"\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('特征重要性排序', fontsize=14, fontweight='bold')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.xlabel('特征波段')\n",
    "        plt.ylabel('重要性')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def calculate_pixel_area(transform):\n",
    "    \"\"\"计算单个像元的面积（单位：平方米）\"\"\"\n",
    "    # 获取像元尺寸（通常为米）\n",
    "    pixel_width = abs(transform[0])  # x方向分辨率\n",
    "    pixel_height = abs(transform[4])  # y方向分辨率\n",
    "    \n",
    "    # 计算单个像元面积（平方米）\n",
    "    pixel_area = pixel_width * pixel_height\n",
    "    \n",
    "    return pixel_area\n",
    "\n",
    "def predict_by_block(model, image, out_path, block_size=BLOCK_SIZE):\n",
    "    \"\"\"分块预测整幅影像\"\"\"\n",
    "    import rasterio\n",
    "    \n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    \n",
    "    # 修正：正确获取栅格配置文件\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'uint16',\n",
    "        'nodata': 0,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'count': 1,\n",
    "        'crs': image.rio.crs,\n",
    "        'transform': image.rio.transform(),\n",
    "        'compress': 'lzw',\n",
    "        'tiled': True,\n",
    "        'blockxsize': min(block_size, width),\n",
    "        'blockysize': min(block_size, block_size)\n",
    "    }\n",
    "\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        for y in tqdm(range(0, height, block_size), desc=\"Block predicting\"):\n",
    "            h = min(block_size, height - y)\n",
    "            \n",
    "            # 读取当前块的数据\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data = data.reshape(-1, data.shape[-1])\n",
    "            data = np.nan_to_num(data)\n",
    "            \n",
    "            # 预测\n",
    "            preds = model.predict(data).reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            # 写入结果\n",
    "            dst.write(preds, 1, window=rasterio.windows.Window(0, y, width, h))\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "def postprocess_classification(classified_data, min_patch_size=10, morphology_op=\"opening\", morphology_size=3):\n",
    "    \"\"\"\n",
    "    后处理分类结果\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - min_patch_size: 最小图斑大小（像元数）\n",
    "    - morphology_op: 形态学操作类型 (\"opening\", \"closing\", \"both\", \"none\")\n",
    "    - morphology_size: 形态学操作核大小\n",
    "    \n",
    "    返回:\n",
    "    - 后处理后的分类结果\n",
    "    \"\"\"\n",
    "    logger.info(\"开始后处理分类结果...\")\n",
    "    processed_data = classified_data.copy()\n",
    "    \n",
    "    # 获取所有类别（排除背景0）\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]\n",
    "    \n",
    "    # 对每个类别进行后处理\n",
    "    for class_id in classes:\n",
    "        # 创建二值掩膜\n",
    "        binary_mask = (classified_data == class_id).astype(np.uint8)\n",
    "        \n",
    "        # 去除小图斑\n",
    "        if min_patch_size > 0:\n",
    "            # 使用连通组件分析标记图斑\n",
    "            labeled_array, num_features = ndimage.label(binary_mask)\n",
    "            \n",
    "            # 计算每个图斑的大小\n",
    "            component_sizes = np.bincount(labeled_array.ravel())\n",
    "            \n",
    "            # 创建掩膜，只保留大于最小图斑大小的区域\n",
    "            size_mask = component_sizes >= min_patch_size\n",
    "            size_mask[0] = 0  # 背景\n",
    "            \n",
    "            # 应用大小过滤\n",
    "            binary_mask = size_mask[labeled_array]\n",
    "        \n",
    "        # 形态学操作\n",
    "        if morphology_op != \"none\" and morphology_size > 0:\n",
    "            # 创建结构元素\n",
    "            structure = np.ones((morphology_size, morphology_size), dtype=np.uint8)\n",
    "            \n",
    "            if morphology_op == \"opening\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "            elif morphology_op == \"closing\":\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "            elif morphology_op == \"both\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "        \n",
    "        # 更新分类结果\n",
    "        processed_data[binary_mask > 0] = class_id\n",
    "        # 将去除的小图斑区域设为背景（0）\n",
    "        processed_data[(classified_data == class_id) & (binary_mask == 0)] = 0\n",
    "    \n",
    "    # 统计后处理变化\n",
    "    original_nonzero = np.count_nonzero(classified_data)\n",
    "    processed_nonzero = np.count_nonzero(processed_data)\n",
    "    change_percent = (original_nonzero - processed_nonzero) / original_nonzero * 100\n",
    "    \n",
    "    logger.info(f\"后处理完成: 原始非零像元数 {original_nonzero}, 处理后非零像元数 {processed_nonzero}\")\n",
    "    logger.info(f\"后处理去除了 {original_nonzero - processed_nonzero} 个像元 ({change_percent:.2f}%)\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def save_classification_result(data, transform, crs, out_path):\n",
    "    \"\"\"保存分类结果到GeoTIFF文件\"\"\"\n",
    "    import rasterio\n",
    "    \n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'uint16',\n",
    "        'nodata': 0,\n",
    "        'width': data.shape[1],\n",
    "        'height': data.shape[0],\n",
    "        'count': 1,\n",
    "        'crs': crs,\n",
    "        'transform': transform,\n",
    "        'compress': 'lzw',\n",
    "        'tiled': True\n",
    "    }\n",
    "    \n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(data.astype(\"uint16\"), 1)\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "def calculate_area_statistics(classified_data, class_names, class_colors, pixel_area_km2, suffix=\"\"):\n",
    "    \"\"\"\n",
    "    计算分类面积统计\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - class_names: 类别名称字典\n",
    "    - class_colors: 类别颜色字典\n",
    "    - pixel_area_km2: 单个像元面积（平方千米）\n",
    "    - suffix: 文件名后缀\n",
    "    \n",
    "    返回:\n",
    "    - stats_df: 统计DataFrame\n",
    "    - total_area_km2: 总面积\n",
    "    \"\"\"\n",
    "    # 获取类别和数量\n",
    "    unique, counts = np.unique(classified_data[classified_data > 0], return_counts=True)\n",
    "    total_pixels = np.sum(counts)\n",
    "    \n",
    "    # 计算各类别面积\n",
    "    areas_km2 = [count * pixel_area_km2 for count in counts]\n",
    "    total_area_km2 = np.sum(areas_km2)\n",
    "    \n",
    "    # 创建统计表格\n",
    "    stats_df = pd.DataFrame({\n",
    "        '类别编号': unique,\n",
    "        '类别名称': [class_names.get(c, f'未知类别_{c}') for c in unique],\n",
    "        '像元数量': counts,\n",
    "        '面积(km²)': [round(area, 4) for area in areas_km2],\n",
    "        '面积占比 (%)': (counts / total_pixels * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    # 保存统计表格\n",
    "    stats_filename = f\"classification_statistics{suffix}.csv\"\n",
    "    stats_df.to_csv(OUT_DIR / stats_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 绘制面积占比饼图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(stats_df['面积占比 (%)'], labels=stats_df['类别名称'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'分类结果面积占比分布{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_distribution{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制面积柱状图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(stats_df['类别名称'], stats_df['面积(km²)'], \n",
    "            color=[class_colors.get(c, 'gray') for c in unique])\n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('面积 (km²)')\n",
    "    plt.title(f'各类别面积统计{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 在柱状图上添加数值标签\n",
    "    for i, v in enumerate(stats_df['面积(km²)']):\n",
    "        plt.text(i, v + max(areas_km2)*0.01, f'{v:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 生成面积统计摘要\n",
    "    with open(OUT_DIR / f\"area_summary{suffix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"分类面积统计摘要{suffix}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"总分类面积: {total_area_km2:.4f} km²\\n\")\n",
    "        f.write(f\"像元大小: {pixel_area_km2 * 1e6:.2f} 平方米\\n\")\n",
    "        f.write(f\"总像元数: {total_pixels}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别面积统计:\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        for _, row in stats_df.iterrows():\n",
    "            f.write(f\"{row['类别名称']}: {row['面积(km²)']:.4f} km² ({row['面积占比 (%)']}%)\\n\")\n",
    "    \n",
    "    return stats_df, total_area_km2\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    logger.info(\"开始监督分类任务...\")\n",
    "\n",
    "    # 0. 从训练样本shp文件中获取类别信息\n",
    "    logger.info(\"正在读取类别信息...\")\n",
    "    class_names, class_colors, train_classes = get_class_info_from_shp(TRAIN_SHP, CLASS_ATTRIBUTE, NAME_ATTRIBUTE)\n",
    "    logger.info(f\"检测到类别: {list(class_names.values())}\")\n",
    "\n",
    "    # 1. 读取影像\n",
    "    img = rxr.open_rasterio(IMAGE_PATH, masked=True)\n",
    "    logger.info(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "    \n",
    "    # 获取影像的空间参考信息\n",
    "    transform = img.rio.transform()\n",
    "    crs = img.rio.crs\n",
    "    logger.info(f\"影像坐标系: {crs}\")\n",
    "    logger.info(f\"影像变换参数: {transform}\")\n",
    "\n",
    "    # 计算像元面积\n",
    "    pixel_area_m2 = calculate_pixel_area(transform)\n",
    "    pixel_area_km2 = pixel_area_m2 / 1e6  # 转换为平方千米\n",
    "    logger.info(f\"单个像元面积: {pixel_area_m2:.2f} 平方米 ({pixel_area_km2:.6f} 平方千米)\")\n",
    "\n",
    "    # 2. 训练样本栅格化与提取\n",
    "    logger.info(\"正在处理训练样本...\")\n",
    "    train_mask = rasterize_samples(TRAIN_SHP, img, CLASS_ATTRIBUTE)\n",
    "    X_train, y_train = extract_samples(img, train_mask)\n",
    "    logger.info(f\"训练样本数: {len(y_train)}\")\n",
    "\n",
    "    # 3. 训练分类器\n",
    "    clf = get_classifier(CLASSIFIER)\n",
    "    logger.info(f\"使用分类器: {clf.__class__.__name__}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    logger.info(\"模型训练完成。\")\n",
    "\n",
    "    # 4. 精度评估（训练集）\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    # 获取实际存在的类别\n",
    "    actual_train_classes = sorted(np.unique(y_train))\n",
    "    train_class_names = [class_names.get(c, f'未知类别_{c}') for c in actual_train_classes if c > 0]\n",
    "    \n",
    "    # 全方位精度评价\n",
    "    overall_acc, kappa, eval_df = comprehensive_evaluation(\n",
    "        y_train, y_pred_train, train_class_names, OUT_DIR / \"train_evaluation.txt\"\n",
    "    )\n",
    "    logger.info(f\"训练集总体精度: {overall_acc:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 绘制训练集混淆矩阵\n",
    "    plot_confusion_matrix(y_train, y_pred_train, train_class_names, OUT_DIR / \"train_cm.png\")\n",
    "\n",
    "    # 5. 特征重要性分析（如果适用）\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        feature_names = [f'波段{i+1}' for i in range(X_train.shape[1])]\n",
    "        plot_feature_importance(clf, feature_names, OUT_DIR / \"feature_importance.png\")\n",
    "\n",
    "    # 6. 分块预测整幅影像\n",
    "    logger.info(\"开始分块预测...\")\n",
    "    classified_path = OUT_DIR / \"classified_result.tif\"\n",
    "    predict_by_block(clf, img, classified_path)\n",
    "    logger.info(f\"分类结果保存至: {classified_path}\")\n",
    "\n",
    "    # 7. 显示原始分类结果\n",
    "    logger.info(\"生成原始分类结果可视化...\")\n",
    "    classified_img = rxr.open_rasterio(classified_path)\n",
    "    plot_classification_results(img, classified_img, class_names, class_colors, \n",
    "                               OUT_DIR / \"classification_visualization.png\", \" (原始)\")\n",
    "\n",
    "    # 8. 原始分类结果面积统计\n",
    "    logger.info(\"计算原始分类结果面积统计...\")\n",
    "    original_classified_data = classified_img.values.squeeze()\n",
    "    original_stats_df, original_total_area = calculate_area_statistics(\n",
    "        original_classified_data, class_names, class_colors, pixel_area_km2, \"_original\"\n",
    "    )\n",
    "    logger.info(f\"原始分类总面积: {original_total_area:.4f} 平方千米\")\n",
    "\n",
    "    # 9. 后处理\n",
    "    if POSTPROCESSING:\n",
    "        logger.info(\"开始后处理...\")\n",
    "        logger.info(f\"后处理参数: 最小图斑大小={MIN_PATCH_SIZE}, 形态学操作={MORPHOLOGY_OPERATION}, 核大小={MORPHOLOGY_SIZE}\")\n",
    "        \n",
    "        # 进行后处理\n",
    "        processed_data = postprocess_classification(\n",
    "            original_classified_data, \n",
    "            min_patch_size=MIN_PATCH_SIZE,\n",
    "            morphology_op=MORPHOLOGY_OPERATION,\n",
    "            morphology_size=MORPHOLOGY_SIZE\n",
    "        )\n",
    "        \n",
    "        # 保存后处理结果\n",
    "        processed_path = OUT_DIR / \"classified_result_postprocessed.tif\"\n",
    "        save_classification_result(processed_data, transform, crs, processed_path)\n",
    "        logger.info(f\"后处理结果保存至: {processed_path}\")\n",
    "        \n",
    "        # 显示后处理分类结果\n",
    "        logger.info(\"生成后处理分类结果可视化...\")\n",
    "        processed_img = rxr.open_rasterio(processed_path)\n",
    "        plot_classification_results(img, processed_img, class_names, class_colors,\n",
    "                                   OUT_DIR / \"classification_visualization_postprocessed.png\", \" (后处理)\")\n",
    "        \n",
    "        # 后处理分类结果面积统计\n",
    "        logger.info(\"计算后处理分类结果面积统计...\")\n",
    "        processed_stats_df, processed_total_area = calculate_area_statistics(\n",
    "            processed_data, class_names, class_colors, pixel_area_km2, \"_postprocessed\"\n",
    "        )\n",
    "        logger.info(f\"后处理分类总面积: {processed_total_area:.4f} 平方千米\")\n",
    "        \n",
    "        # 生成后处理变化报告\n",
    "        area_change = processed_total_area - original_total_area\n",
    "        area_change_percent = (area_change / original_total_area) * 100\n",
    "        \n",
    "        with open(OUT_DIR / \"postprocessing_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"后处理变化报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"后处理参数:\\n\")\n",
    "            f.write(f\"  最小图斑大小: {MIN_PATCH_SIZE} 像元\\n\")\n",
    "            f.write(f\"  形态学操作: {MORPHOLOGY_OPERATION}\\n\")\n",
    "            f.write(f\"  核大小: {MORPHOLOGY_SIZE}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"面积变化:\\n\")\n",
    "            f.write(f\"  原始总面积: {original_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  后处理总面积: {processed_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  面积变化: {area_change:+.4f} km² ({area_change_percent:+.2f}%)\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别面积变化:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            for class_id in class_names.keys():\n",
    "                if class_id in original_stats_df['类别编号'].values and class_id in processed_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    change = proc_area - orig_area\n",
    "                    change_percent = (change / orig_area) * 100 if orig_area > 0 else 0\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → {proc_area:.4f} km² ({change:+.4f}, {change_percent:+.2f}%)\\n\")\n",
    "                elif class_id in original_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → 0.0000 km² (完全去除)\\n\")\n",
    "                elif class_id in processed_stats_df['类别编号'].values:\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: 0.0000 → {proc_area:.4f} km² (新增)\\n\")\n",
    "\n",
    "    # 10. 验证阶段\n",
    "    if os.path.exists(VAL_SHP):\n",
    "        logger.info(\"正在进行验证...\")\n",
    "        val_mask = rasterize_samples(VAL_SHP, img, CLASS_ATTRIBUTE)\n",
    "        \n",
    "        # 使用原始分类结果进行验证\n",
    "        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "            pred_arr = pred_img.values.squeeze()\n",
    "        \n",
    "        Xv = pred_arr[val_mask > 0]\n",
    "        yv = val_mask[val_mask > 0]\n",
    "        \n",
    "        # 验证集全方位精度评价\n",
    "        val_classes = sorted(np.unique(yv))\n",
    "        val_class_names = [class_names.get(c, f'未知类别_{c}') for c in val_classes if c > 0]\n",
    "        \n",
    "        val_overall_acc, val_kappa, val_eval_df = comprehensive_evaluation(\n",
    "            yv, Xv, val_class_names, OUT_DIR / \"validation_evaluation.txt\"\n",
    "        )\n",
    "        logger.info(f\"验证集总体精度: {val_overall_acc:.4f}, Kappa: {val_kappa:.4f}\")\n",
    "        \n",
    "        # 绘制验证集混淆矩阵\n",
    "        plot_confusion_matrix(yv, Xv, val_class_names, OUT_DIR / \"val_cm.png\")\n",
    "\n",
    "        # 生成综合报告\n",
    "        with open(OUT_DIR / \"comprehensive_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"遥感影像分类综合报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"分类器: {clf.__class__.__name__}\\n\")\n",
    "            f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "            f.write(f\"验证样本数: {len(yv)}\\n\")\n",
    "            f.write(f\"类别编号字段: {CLASS_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"类别名称字段: {NAME_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"检测到的类别: {list(class_names.values())}\\n\")\n",
    "            f.write(f\"像元面积: {pixel_area_m2:.2f} 平方米\\n\")\n",
    "            f.write(f\"后处理: {'是' if POSTPROCESSING else '否'}\\n\\n\")\n",
    "            \n",
    "            f.write(\"精度评价汇总:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"训练集总体精度: {overall_acc:.4f}\\n\")\n",
    "            f.write(f\"训练集Kappa系数: {kappa:.4f}\\n\")\n",
    "            f.write(f\"验证集总体精度: {val_overall_acc:.4f}\\n\")\n",
    "            f.write(f\"验证集Kappa系数: {val_kappa:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别验证精度:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(val_eval_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "    # 11. 保存类别信息\n",
    "    class_info_df = pd.DataFrame({\n",
    "        '类别编号': list(class_names.keys()),\n",
    "        '类别名称': list(class_names.values()),\n",
    "        '显示颜色': [class_colors.get(c, 'black') for c in class_names.keys()]\n",
    "    })\n",
    "    class_info_df.to_csv(OUT_DIR / \"class_information.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    logger.info(f\"全部任务完成，用时 {time.time()-t0:.1f} 秒。\")\n",
    "    logger.info(f\"所有结果已保存至: {OUT_DIR.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2aaf4",
   "metadata": {},
   "source": [
    "## 主要改进内容：\n",
    "\n",
    "### 1. **新增名称字段配置**\n",
    "- 添加了 `NAME_ATTRIBUTE = \"name\"` 参数，用于指定包含用地类型名称的字段\n",
    "- 保留了 `CLASS_ATTRIBUTE = \"class\"` 用于类别编号\n",
    "\n",
    "### 2. **智能颜色分配系统**\n",
    "- 创建了 `LANDUSE_COLORS` 字典，包含常见用地类型的预定义颜色\n",
    "- 系统会尝试根据类别名称中的关键词匹配预定义颜色\n",
    "- 如果无法匹配，则使用自动分配的颜色\n",
    "\n",
    "### 3. **改进的类别信息获取**\n",
    "- `get_class_info_from_shp()` 函数现在同时读取类别编号和名称\n",
    "- 如果shp文件中没有名称字段，会使用类别编号作为名称并发出警告\n",
    "- 确保每个类别编号对应唯一的名称\n",
    "\n",
    "### 4. **预定义用地类型颜色**\n",
    "系统包含以下用地类型的预定义颜色：\n",
    "- **水体相关**：水体(浅蓝)、河流(蓝色)、湖泊(深天蓝)、水库(道奇蓝)、海洋(海军蓝)\n",
    "- **植被相关**：植被(森林绿)、森林(深绿)、草地(酸橙绿)、农田(黄绿)、耕地(橄榄绿)\n",
    "- **建筑相关**：建筑(灰色)、城市(暗灰)、居民地(石板灰)、工业区(深灰)\n",
    "- **其他地物**：裸地(棕褐色)、沙地(小麦色)、岩石(赭色)、雪(白色)、云(幽灵白)\n",
    "\n",
    "### 5. **增强的日志和报告**\n",
    "- 在综合报告中显示类别名称字段信息\n",
    "- 更清晰的类别信息输出\n",
    "\n",
    "## 使用说明：\n",
    "\n",
    "1. **配置参数**：确保 `CLASS_ATTRIBUTE` 和 `NAME_ATTRIBUTE` 与您的shp文件字段匹配\n",
    "2. **自定义颜色**：如果需要，可以扩展 `LANDUSE_COLORS` 字典添加更多用地类型和颜色\n",
    "3. **运行脚本**：系统会自动从shp文件的\"name\"字段读取用地类型名称\n",
    "\n",
    "现在系统会根据您的shp文件中的\"name\"字段显示用地类型名称，并为每种用地类型分配语义化的颜色，使分类结果更加直观易懂。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f9c62",
   "metadata": {},
   "source": [
    "# 用rioxarray读写栅格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fdf172",
   "metadata": {},
   "source": [
    "## cloude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a673b59",
   "metadata": {},
   "source": [
    "### 程序1 可以切换3分类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba90eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 08:47:41,251 [INFO] 开始监督分类任务...\n",
      "2025-10-16 08:47:41,252 [INFO] 背景值处理: 启用\n",
      "2025-10-16 08:47:41,253 [INFO] 正在读取类别信息...\n",
      "2025-10-16 08:47:41,263 [INFO] 检测到类别: ['类1', '类2', '类3', '类4', '类5', '类6', '类7', '类8', '类9', '类10', '类11']\n",
      "2025-10-16 08:47:41,263 [INFO] 正在读取遥感影像...\n",
      "2025-10-16 08:47:41,273 [INFO] 影像尺寸: (14, 1024, 2098), 波段数: 14\n",
      "2025-10-16 08:47:41,276 [INFO] 影像坐标系: EPSG:32633\n",
      "2025-10-16 08:47:41,278 [INFO] 影像变换参数: | 0.20, 0.00, 351916.64|\n",
      "| 0.00,-0.20, 5997247.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "2025-10-16 08:47:41,279 [INFO] 单个像元面积: 0.04 平方米 (0.000000 平方千米)\n",
      "2025-10-16 08:47:41,546 [INFO] 影像背景像元数: 614034 / 2148352 (28.58%)\n",
      "2025-10-16 08:47:41,547 [INFO] 正在处理训练样本...\n",
      "2025-10-16 08:47:41,613 [INFO] 训练样本数: 15041\n",
      "2025-10-16 08:47:41,615 [INFO] 使用分类器: RandomForestClassifier\n",
      "2025-10-16 08:47:41,616 [INFO] 开始训练模型...\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.3s finished\n",
      "2025-10-16 08:47:43,807 [INFO] 模型训练完成。\n",
      "2025-10-16 08:47:43,809 [INFO] 正在评估训练集精度...\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "2025-10-16 08:47:44,632 [INFO] 训练集总体精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 08:47:46,374 [INFO] 正在分析特征重要性...\n",
      "2025-10-16 08:47:47,326 [INFO] 开始分块预测整幅影像...\n",
      "2025-10-16 08:47:47,328 [INFO] 计算背景掩膜...\n",
      "2025-10-16 08:47:47,353 [INFO] 背景像元数: 614034 (28.58%)\n",
      "分块预测:   0%|          | 0/2 [00:00<?, ?it/s][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    5.7s finished\n",
      "分块预测:  50%|█████     | 1/2 [00:06<00:06,  6.02s/it][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    6.0s finished\n",
      "分块预测: 100%|██████████| 2/2 [00:12<00:00,  6.17s/it]\n",
      "2025-10-16 08:47:59,752 [INFO] 预测结果已保存至: results_v2\\classified_result.tif\n",
      "2025-10-16 08:47:59,757 [INFO] 生成原始分类结果可视化...\n",
      "2025-10-16 08:48:02,377 [INFO] 计算原始分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\911118632.py:670: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\911118632.py:671: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 08:48:03,447 [INFO] 原始分类总面积: 0.0614 平方千米\n",
      "2025-10-16 08:48:03,448 [INFO] ============================================================\n",
      "2025-10-16 08:48:03,449 [INFO] 开始后处理...\n",
      "2025-10-16 08:48:03,450 [INFO] 后处理参数: 最小图斑大小=10, 形态学操作=opening, 核大小=3\n",
      "2025-10-16 08:48:03,451 [INFO] 开始后处理分类结果...\n",
      "2025-10-16 08:48:04,554 [INFO] 后处理完成: 原始非零像元数 1534318, 处理后非零像元数 1007156\n",
      "2025-10-16 08:48:04,555 [INFO] 后处理去除了 527162 个像元 (34.36%)\n",
      "2025-10-16 08:48:04,613 [INFO] 分类结果已保存至: results_v2\\classified_result_postprocessed.tif\n",
      "2025-10-16 08:48:04,615 [INFO] 生成后处理分类结果可视化...\n",
      "2025-10-16 08:48:07,221 [INFO] 计算后处理分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\911118632.py:670: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\911118632.py:671: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 08:48:08,238 [INFO] 后处理分类总面积: 0.0403 平方千米\n",
      "2025-10-16 08:48:08,250 [INFO] ============================================================\n",
      "2025-10-16 08:48:08,251 [INFO] 开始验证阶段...\n",
      "2025-10-16 08:48:08,327 [INFO] 验证集中排除了 2 个背景像元\n",
      "2025-10-16 08:48:08,329 [INFO] 验证样本数: 11757\n",
      "2025-10-16 08:48:08,914 [INFO] 验证集总体精度: 0.8807, Kappa: 0.8357\n",
      "2025-10-16 08:48:10,637 [INFO] 生成综合报告...\n",
      "2025-10-16 08:48:10,642 [INFO] 保存类别信息...\n",
      "2025-10-16 08:48:10,647 [INFO] ============================================================\n",
      "2025-10-16 08:48:10,647 [INFO] 全部任务完成，用时 29.4 秒。\n",
      "2025-10-16 08:48:10,648 [INFO] 所有结果已保存至: d:\\code313\\Geo_programe\\rasterio\\RF\\results_v2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用遥感影像监督分类系统 (纯rioxarray版本 - 支持背景值处理)\n",
    "-------------------------------------------------\n",
    "功能：\n",
    "1. 自动读取多波段遥感影像；\n",
    "2. 从矢量样本中提取训练/验证数据；\n",
    "3. 支持随机森林 / SVM / XGBoost 分类；\n",
    "4. 采用分块预测模式；\n",
    "5. 输出分类结果 GeoTIFF；\n",
    "6. 自动生成分类报告与混淆矩阵；\n",
    "7. 显示分类影像和精度评价结果；\n",
    "8. 分类面积统计（平方千米）；\n",
    "9. 后处理功能（去除小图斑、形态学操作）；\n",
    "10. 忽略背景值（所有波段值为0的像元）。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features  # 仅用于矢量栅格化\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]  # 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 支持负号显示\n",
    "\n",
    "# ------------------ 参数配置 ------------------\n",
    "IMAGE_PATH = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\2017_09_05_stack.tif\"\n",
    "TRAIN_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\cal.shp\"\n",
    "VAL_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\val.shp\"\n",
    "CLASS_ATTRIBUTE = \"class\"  # 类别编号字段\n",
    "NAME_ATTRIBUTE = \"name\"    # 类别名称字段\n",
    "OUT_DIR = Path(\"./results_v2\")\n",
    "\n",
    "CLASSIFIER = \"rf\"  # 可选: \"rf\", \"svm\", \"xgb\"\n",
    "N_ESTIMATORS = 300\n",
    "BLOCK_SIZE = 512\n",
    "USE_GPU = False\n",
    "\n",
    "# 后处理参数\n",
    "POSTPROCESSING = True  # 是否进行后处理\n",
    "MIN_PATCH_SIZE = 10    # 最小图斑大小（像元数），小于此值的图斑将被去除\n",
    "MORPHOLOGY_OPERATION = \"opening\"  # 形态学操作: \"opening\"（开运算）, \"closing\"（闭运算）, \"both\"（两者都）, \"none\"（无）\n",
    "MORPHOLOGY_SIZE = 3     # 形态学操作核大小\n",
    "\n",
    "# 背景值处理\n",
    "BACKGROUND_VALUE = 0  # 分类结果中的背景值\n",
    "IGNORE_BACKGROUND = True  # 是否忽略所有波段值为0的像元\n",
    "\n",
    "# 预定义颜色映射（可根据需要扩展）\n",
    "LANDUSE_COLORS = {\n",
    "    # 水体相关\n",
    "    \"水体\": \"lightblue\",\n",
    "    \"河流\": \"blue\",\n",
    "    \"湖泊\": \"deepskyblue\",\n",
    "    \"水库\": \"dodgerblue\",\n",
    "    \"海洋\": \"navy\",\n",
    "    \n",
    "    # 植被相关\n",
    "    \"植被\": \"forestgreen\",\n",
    "    \"森林\": \"darkgreen\",\n",
    "    \"草地\": \"limegreen\",\n",
    "    \"农田\": \"yellowgreen\",\n",
    "    \"耕地\": \"olivedrab\",\n",
    "    \n",
    "    # 建筑相关\n",
    "    \"建筑\": \"gray\",\n",
    "    \"城市\": \"dimgray\",\n",
    "    \"居民地\": \"slategray\",\n",
    "    \"工业区\": \"darkgray\",\n",
    "    \n",
    "    # 其他地物\n",
    "    \"裸地\": \"tan\",\n",
    "    \"沙地\": \"wheat\",\n",
    "    \"岩石\": \"sienna\",\n",
    "    \"雪\": \"white\",\n",
    "    \"云\": \"ghostwhite\",\n",
    "    \n",
    "    # 默认颜色（如果上述未匹配）\n",
    "    \"其他\": \"darkred\"\n",
    "}\n",
    "\n",
    "# 自动生成颜色配置（用于未匹配的类别）\n",
    "COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                'darkred', 'purple', 'orange', 'pink', 'brown', \n",
    "                'cyan', 'magenta', 'lime', 'navy', 'teal']\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------ 日志系统 ------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"classification_log.txt\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ------------------ 辅助函数 ------------------\n",
    "def get_background_mask(image):\n",
    "    \"\"\"\n",
    "    获取背景掩膜（所有波段值为0的像元）\n",
    "    \n",
    "    参数:\n",
    "    - image: xarray DataArray，形状为 (bands, rows, cols)\n",
    "    \n",
    "    返回:\n",
    "    - background_mask: numpy array，形状为 (rows, cols)，True表示背景\n",
    "    \"\"\"\n",
    "    # 检查所有波段是否都为0\n",
    "    data = image.values  # (bands, rows, cols)\n",
    "    background_mask = np.all(data == 0, axis=0)  # (rows, cols)\n",
    "    \n",
    "    return background_mask\n",
    "\n",
    "def get_class_info_from_shp(shp_path, class_attr, name_attr):\n",
    "    \"\"\"从shp文件中获取类别信息和自动生成的颜色\"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    \n",
    "    # 检查是否存在名称字段\n",
    "    if name_attr not in gdf.columns:\n",
    "        logger.warning(f\"shp文件中没有找到 '{name_attr}' 字段，将使用类别编号作为名称\")\n",
    "        # 如果没有名称字段，使用类别编号作为名称\n",
    "        gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "    \n",
    "    # 获取唯一的类别编号和对应的名称\n",
    "    class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "    class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "    \n",
    "    # 生成颜色映射\n",
    "    class_colors = {}\n",
    "    for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "        # 尝试从预定义颜色中匹配\n",
    "        color_found = False\n",
    "        for key, color in LANDUSE_COLORS.items():\n",
    "            if key in class_name:\n",
    "                class_colors[class_id] = color\n",
    "                color_found = True\n",
    "                break\n",
    "        \n",
    "        # 如果没有匹配到预定义颜色，使用自动分配的颜色\n",
    "        if not color_found:\n",
    "            class_colors[class_id] = COLOR_PALETTE[i % len(COLOR_PALETTE)]\n",
    "    \n",
    "    unique_classes = sorted(class_names.keys())\n",
    "    \n",
    "    return class_names, class_colors, unique_classes\n",
    "\n",
    "def rasterize_samples(shp, ref_img, attr):\n",
    "    \"\"\"将矢量样本栅格化为与影像对齐的数组\"\"\"\n",
    "    gdf = gpd.read_file(shp)\n",
    "    gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "    \n",
    "    arr = features.rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=ref_img.shape[1:],\n",
    "        transform=ref_img.rio.transform(),\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=\"uint16\"\n",
    "    )\n",
    "    return arr\n",
    "\n",
    "def extract_samples(image, mask, ignore_background=True):\n",
    "    \"\"\"\n",
    "    根据掩膜提取样本特征与标签，可选忽略背景\n",
    "    \n",
    "    参数:\n",
    "    - image: xarray DataArray，影像数据\n",
    "    - mask: numpy array，样本掩膜\n",
    "    - ignore_background: 是否忽略背景（所有波段值为0的像元）\n",
    "    \n",
    "    返回:\n",
    "    - X: 特征数组\n",
    "    - y: 标签数组\n",
    "    \"\"\"\n",
    "    data = np.moveaxis(image.values, 0, -1)  # (bands, rows, cols) → (rows, cols, bands)\n",
    "    valid = mask > 0\n",
    "    \n",
    "    if ignore_background:\n",
    "        # 获取背景掩膜\n",
    "        background_mask = get_background_mask(image)\n",
    "        # 排除背景像元\n",
    "        valid = valid & (~background_mask)\n",
    "        n_background = np.sum(mask > 0) - np.sum(valid)\n",
    "        if n_background > 0:\n",
    "            logger.info(f\"排除了 {n_background} 个背景像元\")\n",
    "    \n",
    "    X = data[valid]\n",
    "    y = mask[valid]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def get_classifier(name):\n",
    "    \"\"\"构造分类器\"\"\"\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=N_ESTIMATORS, n_jobs=-1, oob_score=True, verbose=1\n",
    "        )\n",
    "    elif name == \"svm\":\n",
    "        return SVC(kernel=\"rbf\", probability=True)\n",
    "    elif name == \"xgb\":\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            return XGBClassifier(\n",
    "                n_estimators=N_ESTIMATORS, learning_rate=0.1, max_depth=8, n_jobs=-1\n",
    "            )\n",
    "        except ImportError:\n",
    "            raise ImportError(\"未安装 xgboost，请先运行 pip install xgboost\")\n",
    "    else:\n",
    "        raise ValueError(f\"未知分类器类型: {name}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"绘制详细的混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 计算百分比\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建热图\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 同时保存百分比版本\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '百分比 (%)'})\n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵 (百分比)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.png', '_percent.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def comprehensive_evaluation(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"全方位精度评价\"\"\"\n",
    "    # 计算各项指标\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # 创建详细报告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "    \n",
    "    # 创建精度评价表格\n",
    "    eval_df = pd.DataFrame({\n",
    "        '类别': class_names,\n",
    "        '精确率 (Precision)': precision,\n",
    "        '召回率 (Recall)': recall,\n",
    "        'F1分数': f1,\n",
    "        '样本数量': np.bincount(y_true)[1:len(class_names)+1]  # 从1开始计数\n",
    "    })\n",
    "    \n",
    "    # 保存详细报告\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"           遥感影像分类精度评价报告\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"总体精度 (Overall Accuracy): {overall_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Kappa系数: {kappa:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别精度评价:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(eval_df.to_string(index=False, float_format='%.4f'))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"详细分类报告:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 绘制精度指标条形图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, precision, width, label='精确率', alpha=0.8)\n",
    "    plt.bar(x, recall, width, label='召回率', alpha=0.8)\n",
    "    plt.bar(x + width, f1, width, label='F1分数', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('分数')\n",
    "    plt.title('各类别分类精度指标')\n",
    "    plt.xticks(x, class_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.txt', '_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return overall_accuracy, kappa, eval_df\n",
    "\n",
    "def plot_classification_results(original_img, classified_img, class_names, class_colors, save_path, title_suffix=\"\"):\n",
    "    \"\"\"显示原始影像和分类结果\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 显示原始影像 (使用前3个波段作为RGB)\n",
    "    if original_img.shape[0] >= 3:\n",
    "        rgb_data = np.moveaxis(original_img.values[:3], 0, -1)\n",
    "        # 数据标准化显示\n",
    "        p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))  # 排除0值\n",
    "        rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "        ax1.imshow(rgb_display)\n",
    "    else:\n",
    "        # 单波段影像显示\n",
    "        ax1.imshow(original_img.values[0], cmap='gray')\n",
    "    \n",
    "    ax1.set_title('原始遥感影像', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 显示分类结果\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    \n",
    "    # 创建分类图例\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]  # 排除背景值\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    colors = [class_colors.get(c, 'black') for c in classes]\n",
    "    labels = [class_names.get(c, f'未知类别_{c}') for c in classes]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # 创建显示数据，背景值设为NaN以便透明显示\n",
    "    display_data = classified_data.astype(float)\n",
    "    display_data[classified_data == 0] = np.nan\n",
    "    \n",
    "    im = ax2.imshow(display_data, cmap=cmap, norm=norm)\n",
    "    title = '分类结果' + title_suffix\n",
    "    ax2.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 添加图例\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for color, label in zip(colors, labels)]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(clf, feature_names, save_path):\n",
    "    \"\"\"绘制特征重要性图（适用于随机森林和XGBoost）\"\"\"\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('特征重要性排序', fontsize=14, fontweight='bold')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.xlabel('特征波段')\n",
    "        plt.ylabel('重要性')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def calculate_pixel_area(transform):\n",
    "    \"\"\"计算单个像元的面积（单位：平方米）\"\"\"\n",
    "    # 获取像元尺寸（通常为米）\n",
    "    pixel_width = abs(transform[0])  # x方向分辨率\n",
    "    pixel_height = abs(transform[4])  # y方向分辨率\n",
    "    \n",
    "    # 计算单个像元面积（平方米）\n",
    "    pixel_area = pixel_width * pixel_height\n",
    "    \n",
    "    return pixel_area\n",
    "\n",
    "def predict_by_block(model, image, out_path, block_size=BLOCK_SIZE, ignore_background=True):\n",
    "    \"\"\"\n",
    "    分块预测整幅影像（使用rioxarray），忽略背景值\n",
    "    \n",
    "    参数:\n",
    "    - model: 训练好的分类器\n",
    "    - image: xarray DataArray，输入影像\n",
    "    - out_path: 输出路径\n",
    "    - block_size: 块大小\n",
    "    - ignore_background: 是否忽略背景（所有波段值为0的像元）\n",
    "    \"\"\"\n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    n_bands = image.shape[0]\n",
    "    \n",
    "    # 创建空的预测结果数组，初始化为背景值\n",
    "    prediction = np.zeros((height, width), dtype='uint16')\n",
    "    \n",
    "    # 如果需要忽略背景，获取背景掩膜\n",
    "    if ignore_background:\n",
    "        logger.info(\"计算背景掩膜...\")\n",
    "        background_mask = get_background_mask(image)\n",
    "        n_background = np.sum(background_mask)\n",
    "        n_total = height * width\n",
    "        logger.info(f\"背景像元数: {n_background} ({n_background/n_total*100:.2f}%)\")\n",
    "    \n",
    "    # 分块预测\n",
    "    total_blocks = int(np.ceil(height / block_size))\n",
    "    \n",
    "    for y in tqdm(range(0, height, block_size), desc=\"分块预测\"):\n",
    "        h = min(block_size, height - y)\n",
    "        \n",
    "        # 读取当前块的数据\n",
    "        block_data = image.isel(y=slice(y, y+h)).values\n",
    "        data = np.moveaxis(block_data, 0, -1)  # (bands, h, width) → (h, width, bands)\n",
    "        original_shape = data.shape\n",
    "        \n",
    "        # 重塑为 (n_pixels, n_bands)\n",
    "        data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if ignore_background:\n",
    "            # 获取当前块的背景掩膜\n",
    "            block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "            \n",
    "            # 只预测非背景像元\n",
    "            non_bg_indices = ~block_bg_mask\n",
    "            \n",
    "            if np.any(non_bg_indices):\n",
    "                # 预测非背景像元\n",
    "                data_to_predict = np.nan_to_num(data_flat[non_bg_indices])\n",
    "                preds_non_bg = model.predict(data_to_predict)\n",
    "                \n",
    "                # 创建完整的预测结果（背景为0）\n",
    "                preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                preds_flat[non_bg_indices] = preds_non_bg\n",
    "                \n",
    "                preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "            else:\n",
    "                # 整个块都是背景\n",
    "                preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "        else:\n",
    "            # 预测所有像元\n",
    "            data_flat = np.nan_to_num(data_flat)\n",
    "            preds = model.predict(data_flat).reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "        \n",
    "        # 存储结果\n",
    "        prediction[y:y+h, :] = preds\n",
    "    \n",
    "    # 创建xarray DataArray\n",
    "    prediction_da = xr.DataArray(\n",
    "        prediction,\n",
    "        dims=['y', 'x'],\n",
    "        coords={\n",
    "            'y': image.coords['y'],\n",
    "            'x': image.coords['x']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 设置空间参考信息\n",
    "    prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "    prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "    prediction_da.rio.write_nodata(BACKGROUND_VALUE, inplace=True)\n",
    "    \n",
    "    # 保存为GeoTIFF\n",
    "    prediction_da.rio.to_raster(\n",
    "        out_path,\n",
    "        driver='GTiff',\n",
    "        dtype='uint16',\n",
    "        compress='lzw',\n",
    "        tiled=True\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"预测结果已保存至: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def save_classification_result(data, ref_image, out_path):\n",
    "    \"\"\"\n",
    "    保存分类结果到GeoTIFF文件（使用rioxarray）\n",
    "    \n",
    "    参数:\n",
    "    - data: numpy array，分类结果\n",
    "    - ref_image: xarray DataArray，参考影像（用于获取空间参考信息）\n",
    "    - out_path: 输出路径\n",
    "    \"\"\"\n",
    "    # 创建xarray DataArray\n",
    "    result_da = xr.DataArray(\n",
    "        data,\n",
    "        dims=['y', 'x'],\n",
    "        coords={\n",
    "            'y': ref_image.coords['y'],\n",
    "            'x': ref_image.coords['x']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 设置空间参考信息\n",
    "    result_da.rio.write_crs(ref_image.rio.crs, inplace=True)\n",
    "    result_da.rio.write_transform(ref_image.rio.transform(), inplace=True)\n",
    "    result_da.rio.write_nodata(BACKGROUND_VALUE, inplace=True)\n",
    "    \n",
    "    # 保存为GeoTIFF\n",
    "    result_da.rio.to_raster(\n",
    "        out_path,\n",
    "        driver='GTiff',\n",
    "        dtype='uint16',\n",
    "        compress='lzw',\n",
    "        tiled=True\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"分类结果已保存至: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def postprocess_classification(classified_data, min_patch_size=10, morphology_op=\"opening\", morphology_size=3):\n",
    "    \"\"\"\n",
    "    后处理分类结果（不处理背景值0）\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - min_patch_size: 最小图斑大小（像元数）\n",
    "    - morphology_op: 形态学操作类型 (\"opening\", \"closing\", \"both\", \"none\")\n",
    "    - morphology_size: 形态学操作核大小\n",
    "    \n",
    "    返回:\n",
    "    - 后处理后的分类结果\n",
    "    \"\"\"\n",
    "    logger.info(\"开始后处理分类结果...\")\n",
    "    processed_data = classified_data.copy()\n",
    "    \n",
    "    # 获取所有类别（排除背景0）\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]\n",
    "    \n",
    "    # 对每个类别进行后处理\n",
    "    for class_id in classes:\n",
    "        # 创建二值掩膜\n",
    "        binary_mask = (classified_data == class_id).astype(np.uint8)\n",
    "        \n",
    "        # 去除小图斑\n",
    "        if min_patch_size > 0:\n",
    "            # 使用连通组件分析标记图斑\n",
    "            labeled_array, num_features = ndimage.label(binary_mask)\n",
    "            \n",
    "            # 计算每个图斑的大小\n",
    "            component_sizes = np.bincount(labeled_array.ravel())\n",
    "            \n",
    "            # 创建掩膜，只保留大于最小图斑大小的区域\n",
    "            size_mask = component_sizes >= min_patch_size\n",
    "            size_mask[0] = 0  # 背景\n",
    "            \n",
    "            # 应用大小过滤\n",
    "            binary_mask = size_mask[labeled_array]\n",
    "        \n",
    "        # 形态学操作\n",
    "        if morphology_op != \"none\" and morphology_size > 0:\n",
    "            # 创建结构元素\n",
    "            structure = np.ones((morphology_size, morphology_size), dtype=np.uint8)\n",
    "            \n",
    "            if morphology_op == \"opening\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "            elif morphology_op == \"closing\":\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "            elif morphology_op == \"both\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "        \n",
    "        # 更新分类结果\n",
    "        processed_data[binary_mask > 0] = class_id\n",
    "        # 将去除的小图斑区域设为背景（0）\n",
    "        processed_data[(classified_data == class_id) & (binary_mask == 0)] = BACKGROUND_VALUE\n",
    "    \n",
    "    # 统计后处理变化\n",
    "    original_nonzero = np.count_nonzero(classified_data)\n",
    "    processed_nonzero = np.count_nonzero(processed_data)\n",
    "    change_percent = (original_nonzero - processed_nonzero) / original_nonzero * 100 if original_nonzero > 0 else 0\n",
    "    \n",
    "    logger.info(f\"后处理完成: 原始非零像元数 {original_nonzero}, 处理后非零像元数 {processed_nonzero}\")\n",
    "    logger.info(f\"后处理去除了 {original_nonzero - processed_nonzero} 个像元 ({change_percent:.2f}%)\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def calculate_area_statistics(classified_data, class_names, class_colors, pixel_area_km2, suffix=\"\"):\n",
    "    \"\"\"\n",
    "    计算分类面积统计（排除背景值0）\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - class_names: 类别名称字典\n",
    "    - class_colors: 类别颜色字典\n",
    "    - pixel_area_km2: 单个像元面积（平方千米）\n",
    "    - suffix: 文件名后缀\n",
    "    \n",
    "    返回:\n",
    "    - stats_df: 统计DataFrame\n",
    "    - total_area_km2: 总面积\n",
    "    \"\"\"\n",
    "    # 获取类别和数量（排除背景0）\n",
    "    unique, counts = np.unique(classified_data[classified_data > 0], return_counts=True)\n",
    "    \n",
    "    if len(unique) == 0:\n",
    "        logger.warning(\"分类结果中没有有效类别（非背景）！\")\n",
    "        return pd.DataFrame(), 0.0\n",
    "    \n",
    "    total_pixels = np.sum(counts)\n",
    "    \n",
    "    # 计算各类别面积\n",
    "    areas_km2 = [count * pixel_area_km2 for count in counts]\n",
    "    total_area_km2 = np.sum(areas_km2)\n",
    "    \n",
    "    # 创建统计表格\n",
    "    stats_df = pd.DataFrame({\n",
    "        '类别编号': unique,\n",
    "        '类别名称': [class_names.get(c, f'未知类别_{c}') for c in unique],\n",
    "        '像元数量': counts,\n",
    "        '面积(km²)': [round(area, 4) for area in areas_km2],\n",
    "        '面积占比 (%)': (counts / total_pixels * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    # 保存统计表格\n",
    "    stats_filename = f\"classification_statistics{suffix}.csv\"\n",
    "    stats_df.to_csv(OUT_DIR / stats_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 绘制面积占比饼图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(stats_df['面积占比 (%)'], labels=stats_df['类别名称'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'分类结果面积占比分布{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_distribution{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制面积柱状图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(stats_df['类别名称'], stats_df['面积(km²)'], \n",
    "            color=[class_colors.get(c, 'gray') for c in unique])\n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('面积 (km²)')\n",
    "    plt.title(f'各类别面积统计{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 在柱状图上添加数值标签\n",
    "    for i, v in enumerate(stats_df['面积(km²)']):\n",
    "        plt.text(i, v + max(areas_km2)*0.01, f'{v:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 统计背景信息\n",
    "    n_background = np.sum(classified_data == 0)\n",
    "    n_total = classified_data.size\n",
    "    background_area_km2 = n_background * pixel_area_km2\n",
    "    \n",
    "    # 生成面积统计摘要\n",
    "    with open(OUT_DIR / f\"area_summary{suffix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"分类面积统计摘要{suffix}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"总分类面积: {total_area_km2:.4f} km²\\n\")\n",
    "        f.write(f\"背景面积: {background_area_km2:.4f} km²\\n\")\n",
    "        f.write(f\"总影像面积: {(total_area_km2 + background_area_km2):.4f} km²\\n\")\n",
    "        f.write(f\"像元大小: {pixel_area_km2 * 1e6:.2f} 平方米\\n\")\n",
    "        f.write(f\"分类像元数: {total_pixels}\\n\")\n",
    "        f.write(f\"背景像元数: {n_background}\\n\")\n",
    "        f.write(f\"总像元数: {n_total}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别面积统计:\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        for _, row in stats_df.iterrows():\n",
    "            f.write(f\"{row['类别名称']}: {row['面积(km²)']:.4f} km² ({row['面积占比 (%)']}%)\\n\")\n",
    "    \n",
    "    return stats_df, total_area_km2\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    logger.info(\"开始监督分类任务...\")\n",
    "    logger.info(f\"背景值处理: {'启用' if IGNORE_BACKGROUND else '禁用'}\")\n",
    "\n",
    "    # 0. 从训练样本shp文件中获取类别信息\n",
    "    logger.info(\"正在读取类别信息...\")\n",
    "    class_names, class_colors, train_classes = get_class_info_from_shp(TRAIN_SHP, CLASS_ATTRIBUTE, NAME_ATTRIBUTE)\n",
    "    logger.info(f\"检测到类别: {list(class_names.values())}\")\n",
    "\n",
    "    # 1. 读取影像（使用rioxarray）\n",
    "    logger.info(\"正在读取遥感影像...\")\n",
    "    img = rxr.open_rasterio(IMAGE_PATH, masked=True)\n",
    "    logger.info(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "    \n",
    "    # 获取影像的空间参考信息\n",
    "    transform = img.rio.transform()\n",
    "    crs = img.rio.crs\n",
    "    logger.info(f\"影像坐标系: {crs}\")\n",
    "    logger.info(f\"影像变换参数: {transform}\")\n",
    "\n",
    "    # 计算像元面积\n",
    "    pixel_area_m2 = calculate_pixel_area(transform)\n",
    "    pixel_area_km2 = pixel_area_m2 / 1e6  # 转换为平方千米\n",
    "    logger.info(f\"单个像元面积: {pixel_area_m2:.2f} 平方米 ({pixel_area_km2:.6f} 平方千米)\")\n",
    "\n",
    "    # 统计背景信息\n",
    "    if IGNORE_BACKGROUND:\n",
    "        background_mask = get_background_mask(img)\n",
    "        n_background = np.sum(background_mask)\n",
    "        n_total = img.shape[1] * img.shape[2]\n",
    "        logger.info(f\"影像背景像元数: {n_background} / {n_total} ({n_background/n_total*100:.2f}%)\")\n",
    "\n",
    "    # 2. 训练样本栅格化与提取\n",
    "    logger.info(\"正在处理训练样本...\")\n",
    "    train_mask = rasterize_samples(TRAIN_SHP, img, CLASS_ATTRIBUTE)\n",
    "    X_train, y_train = extract_samples(img, train_mask, ignore_background=IGNORE_BACKGROUND)\n",
    "    logger.info(f\"训练样本数: {len(y_train)}\")\n",
    "\n",
    "    # 3. 训练分类器\n",
    "    clf = get_classifier(CLASSIFIER)\n",
    "    logger.info(f\"使用分类器: {clf.__class__.__name__}\")\n",
    "    logger.info(\"开始训练模型...\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    logger.info(\"模型训练完成。\")\n",
    "\n",
    "    # 4. 精度评估（训练集）\n",
    "    logger.info(\"正在评估训练集精度...\")\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    # 获取实际存在的类别\n",
    "    actual_train_classes = sorted(np.unique(y_train))\n",
    "    train_class_names = [class_names.get(c, f'未知类别_{c}') for c in actual_train_classes if c > 0]\n",
    "    \n",
    "    # 全方位精度评价\n",
    "    overall_acc, kappa, eval_df = comprehensive_evaluation(\n",
    "        y_train, y_pred_train, train_class_names, OUT_DIR / \"train_evaluation.txt\"\n",
    "    )\n",
    "    logger.info(f\"训练集总体精度: {overall_acc:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 绘制训练集混淆矩阵\n",
    "    plot_confusion_matrix(y_train, y_pred_train, train_class_names, OUT_DIR / \"train_cm.png\")\n",
    "\n",
    "    # 5. 特征重要性分析（如果适用）\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        logger.info(\"正在分析特征重要性...\")\n",
    "        feature_names = [f'波段{i+1}' for i in range(X_train.shape[1])]\n",
    "        plot_feature_importance(clf, feature_names, OUT_DIR / \"feature_importance.png\")\n",
    "\n",
    "    # 6. 分块预测整幅影像\n",
    "    logger.info(\"开始分块预测整幅影像...\")\n",
    "    classified_path = OUT_DIR / \"classified_result.tif\"\n",
    "    predict_by_block(clf, img, classified_path, ignore_background=IGNORE_BACKGROUND)\n",
    "\n",
    "    # 7. 显示原始分类结果\n",
    "    logger.info(\"生成原始分类结果可视化...\")\n",
    "    classified_img = rxr.open_rasterio(classified_path)\n",
    "    plot_classification_results(img, classified_img, class_names, class_colors, \n",
    "                               OUT_DIR / \"classification_visualization.png\", \" (原始)\")\n",
    "\n",
    "    # 8. 原始分类结果面积统计\n",
    "    logger.info(\"计算原始分类结果面积统计...\")\n",
    "    original_classified_data = classified_img.values.squeeze()\n",
    "    original_stats_df, original_total_area = calculate_area_statistics(\n",
    "        original_classified_data, class_names, class_colors, pixel_area_km2, \"_original\"\n",
    "    )\n",
    "    logger.info(f\"原始分类总面积: {original_total_area:.4f} 平方千米\")\n",
    "\n",
    "    # 9. 后处理\n",
    "    if POSTPROCESSING:\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"开始后处理...\")\n",
    "        logger.info(f\"后处理参数: 最小图斑大小={MIN_PATCH_SIZE}, 形态学操作={MORPHOLOGY_OPERATION}, 核大小={MORPHOLOGY_SIZE}\")\n",
    "        \n",
    "        # 进行后处理\n",
    "        processed_data = postprocess_classification(\n",
    "            original_classified_data, \n",
    "            min_patch_size=MIN_PATCH_SIZE,\n",
    "            morphology_op=MORPHOLOGY_OPERATION,\n",
    "            morphology_size=MORPHOLOGY_SIZE\n",
    "        )\n",
    "        \n",
    "        # 保存后处理结果（使用rioxarray）\n",
    "        processed_path = OUT_DIR / \"classified_result_postprocessed.tif\"\n",
    "        save_classification_result(processed_data, img, processed_path)\n",
    "        \n",
    "        # 显示后处理分类结果\n",
    "        logger.info(\"生成后处理分类结果可视化...\")\n",
    "        processed_img = rxr.open_rasterio(processed_path)\n",
    "        plot_classification_results(img, processed_img, class_names, class_colors,\n",
    "                                   OUT_DIR / \"classification_visualization_postprocessed.png\", \" (后处理)\")\n",
    "        \n",
    "        # 后处理分类结果面积统计\n",
    "        logger.info(\"计算后处理分类结果面积统计...\")\n",
    "        processed_stats_df, processed_total_area = calculate_area_statistics(\n",
    "            processed_data, class_names, class_colors, pixel_area_km2, \"_postprocessed\"\n",
    "        )\n",
    "        logger.info(f\"后处理分类总面积: {processed_total_area:.4f} 平方千米\")\n",
    "        \n",
    "        # 生成后处理变化报告\n",
    "        area_change = processed_total_area - original_total_area\n",
    "        area_change_percent = (area_change / original_total_area) * 100 if original_total_area > 0 else 0\n",
    "        \n",
    "        with open(OUT_DIR / \"postprocessing_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"后处理变化报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"后处理参数:\\n\")\n",
    "            f.write(f\"  最小图斑大小: {MIN_PATCH_SIZE} 像元\\n\")\n",
    "            f.write(f\"  形态学操作: {MORPHOLOGY_OPERATION}\\n\")\n",
    "            f.write(f\"  核大小: {MORPHOLOGY_SIZE}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"面积变化:\\n\")\n",
    "            f.write(f\"  原始总面积: {original_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  后处理总面积: {processed_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  面积变化: {area_change:+.4f} km² ({area_change_percent:+.2f}%)\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别面积变化:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            for class_id in class_names.keys():\n",
    "                if class_id in original_stats_df['类别编号'].values and class_id in processed_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    change = proc_area - orig_area\n",
    "                    change_percent = (change / orig_area) * 100 if orig_area > 0 else 0\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → {proc_area:.4f} km² ({change:+.4f}, {change_percent:+.2f}%)\\n\")\n",
    "                elif class_id in original_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → 0.0000 km² (完全去除)\\n\")\n",
    "                elif class_id in processed_stats_df['类别编号'].values:\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: 0.0000 → {proc_area:.4f} km² (新增)\\n\")\n",
    "\n",
    "    # 10. 验证阶段\n",
    "    if os.path.exists(VAL_SHP):\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"开始验证阶段...\")\n",
    "        val_mask = rasterize_samples(VAL_SHP, img, CLASS_ATTRIBUTE)\n",
    "        \n",
    "        # 使用原始分类结果进行验证\n",
    "        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "            pred_arr = pred_img.values.squeeze()\n",
    "        \n",
    "        # 提取验证样本（忽略背景）\n",
    "        if IGNORE_BACKGROUND:\n",
    "            background_mask = get_background_mask(img)\n",
    "            valid_val = (val_mask > 0) & (~background_mask)\n",
    "            n_excluded = np.sum(val_mask > 0) - np.sum(valid_val)\n",
    "            if n_excluded > 0:\n",
    "                logger.info(f\"验证集中排除了 {n_excluded} 个背景像元\")\n",
    "        else:\n",
    "            valid_val = val_mask > 0\n",
    "        \n",
    "        Xv = pred_arr[valid_val]\n",
    "        yv = val_mask[valid_val]\n",
    "        \n",
    "        logger.info(f\"验证样本数: {len(yv)}\")\n",
    "        \n",
    "        # 验证集全方位精度评价\n",
    "        val_classes = sorted(np.unique(yv))\n",
    "        val_class_names = [class_names.get(c, f'未知类别_{c}') for c in val_classes if c > 0]\n",
    "        \n",
    "        val_overall_acc, val_kappa, val_eval_df = comprehensive_evaluation(\n",
    "            yv, Xv, val_class_names, OUT_DIR / \"validation_evaluation.txt\"\n",
    "        )\n",
    "        logger.info(f\"验证集总体精度: {val_overall_acc:.4f}, Kappa: {val_kappa:.4f}\")\n",
    "        \n",
    "        # 绘制验证集混淆矩阵\n",
    "        plot_confusion_matrix(yv, Xv, val_class_names, OUT_DIR / \"val_cm.png\")\n",
    "\n",
    "        # 生成综合报告\n",
    "        logger.info(\"生成综合报告...\")\n",
    "        with open(OUT_DIR / \"comprehensive_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"遥感影像分类综合报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"分类器: {clf.__class__.__name__}\\n\")\n",
    "            f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "            f.write(f\"验证样本数: {len(yv)}\\n\")\n",
    "            f.write(f\"类别编号字段: {CLASS_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"类别名称字段: {NAME_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"检测到的类别: {list(class_names.values())}\\n\")\n",
    "            f.write(f\"像元面积: {pixel_area_m2:.2f} 平方米\\n\")\n",
    "            f.write(f\"背景值处理: {'启用' if IGNORE_BACKGROUND else '禁用'}\\n\")\n",
    "            f.write(f\"后处理: {'是' if POSTPROCESSING else '否'}\\n\\n\")\n",
    "            \n",
    "            f.write(\"精度评价汇总:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"训练集总体精度: {overall_acc:.4f}\\n\")\n",
    "            f.write(f\"训练集Kappa系数: {kappa:.4f}\\n\")\n",
    "            f.write(f\"验证集总体精度: {val_overall_acc:.4f}\\n\")\n",
    "            f.write(f\"验证集Kappa系数: {val_kappa:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别验证精度:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(val_eval_df.to_string(index=False, float_format='%.4f'))\n",
    "    else:\n",
    "        logger.warning(f\"验证集文件不存在: {VAL_SHP}\")\n",
    "\n",
    "    # 11. 保存类别信息\n",
    "    logger.info(\"保存类别信息...\")\n",
    "    class_info_df = pd.DataFrame({\n",
    "        '类别编号': list(class_names.keys()),\n",
    "        '类别名称': list(class_names.values()),\n",
    "        '显示颜色': [class_colors.get(c, 'black') for c in class_names.keys()]\n",
    "    })\n",
    "    class_info_df.to_csv(OUT_DIR / \"class_information.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    logger.info(\"=\"*60)\n",
    "    logger.info(f\"全部任务完成，用时 {time.time()-t0:.1f} 秒。\")\n",
    "    logger.info(f\"所有结果已保存至: {OUT_DIR.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1d9fa",
   "metadata": {},
   "source": [
    "### 程序2 增加更多分类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64781e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 08:58:59,117 [INFO] ================================================================================\n",
      "2025-10-16 08:58:59,118 [INFO] 开始多分类器对比实验...\n",
      "2025-10-16 08:58:59,119 [INFO] ================================================================================\n",
      "2025-10-16 08:59:01,247 [INFO] 将对比 12 个分类器:\n",
      "2025-10-16 08:59:01,249 [INFO]   - 随机森林 (rf): Random Forest - 集成学习方法，适合高维数据\n",
      "2025-10-16 08:59:01,251 [INFO]   - 支持向量机 (svm): Support Vector Machine - 基于核函数的分类器\n",
      "2025-10-16 08:59:01,252 [INFO]   - 决策树 (dt): Decision Tree - 简单直观的树形分类器\n",
      "2025-10-16 08:59:01,252 [INFO]   - K近邻 (knn): K-Nearest Neighbors - 基于距离的分类器\n",
      "2025-10-16 08:59:01,253 [INFO]   - 朴素贝叶斯 (nb): Naive Bayes - 基于概率的快速分类器\n",
      "2025-10-16 08:59:01,254 [INFO]   - 梯度提升 (gb): Gradient Boosting - 强大的集成学习方法\n",
      "2025-10-16 08:59:01,255 [INFO]   - AdaBoost (ada): AdaBoost - 自适应提升集成方法\n",
      "2025-10-16 08:59:01,255 [INFO]   - 极端随机树 (et): Extra Trees - 极端随机化的森林方法\n",
      "2025-10-16 08:59:01,256 [INFO]   - 逻辑回归 (lr): Logistic Regression - 经典的线性分类器\n",
      "2025-10-16 08:59:01,256 [INFO]   - 神经网络 (mlp): Multi-layer Perceptron - 前馈神经网络\n",
      "2025-10-16 08:59:01,257 [INFO]   - XGBoost (xgb): XGBoost - 高性能梯度提升框架\n",
      "2025-10-16 08:59:01,257 [INFO]   - LightGBM (lgb): LightGBM - 轻量级梯度提升框架\n",
      "2025-10-16 08:59:01,258 [INFO] \n",
      "正在读取类别信息...\n",
      "2025-10-16 08:59:01,268 [INFO] 检测到类别: ['类1', '类2', '类3', '类4', '类5', '类6', '类7', '类8', '类9', '类10', '类11']\n",
      "2025-10-16 08:59:01,270 [INFO] \n",
      "正在读取遥感影像...\n",
      "2025-10-16 08:59:01,281 [INFO] 影像尺寸: (14, 1024, 2098), 波段数: 14\n",
      "2025-10-16 08:59:01,283 [INFO] \n",
      "正在处理训练样本...\n",
      "2025-10-16 08:59:01,581 [INFO] 训练样本数: 15041\n",
      "2025-10-16 08:59:01,583 [INFO] 正在处理验证样本...\n",
      "2025-10-16 08:59:01,631 [INFO] 验证样本数: 11757\n",
      "2025-10-16 08:59:01,632 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:01,633 [INFO] 正在测试分类器: 随机森林 (rf)\n",
      "2025-10-16 08:59:01,634 [INFO] ================================================================================\n",
      "2025-10-16 08:59:01,637 [INFO] 开始训练...\n",
      "2025-10-16 08:59:02,266 [INFO] 训练完成，耗时: 0.63 秒\n",
      "2025-10-16 08:59:02,268 [INFO] 评估训练集...\n",
      "2025-10-16 08:59:02,390 [INFO] 训练集精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 08:59:03,250 [INFO] 开始预测整幅影像...\n",
      "2025-10-16 08:59:07,820 [INFO] 预测完成，耗时: 4.57 秒         \n",
      "2025-10-16 08:59:07,821 [INFO] 评估验证集...\n",
      "2025-10-16 08:59:07,879 [INFO] 验证集精度: 0.8809, Kappa: 0.8361\n",
      "2025-10-16 08:59:08,914 [INFO] 生成可视化结果...\n",
      "2025-10-16 08:59:11,557 [INFO] ✓ 随机森林 测试完成\n",
      "2025-10-16 08:59:11,559 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:11,560 [INFO] 正在测试分类器: 支持向量机 (svm)\n",
      "2025-10-16 08:59:11,561 [INFO] ================================================================================\n",
      "2025-10-16 08:59:11,563 [INFO] 开始训练...\n",
      "2025-10-16 08:59:11,566 [ERROR] ✗ 支持向量机 测试失败: Input X contains NaN.\n",
      "SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:11,628 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 197, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "SVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:11,629 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:11,630 [INFO] 正在测试分类器: 决策树 (dt)\n",
      "2025-10-16 08:59:11,631 [INFO] ================================================================================\n",
      "2025-10-16 08:59:11,634 [INFO] 开始训练...\n",
      "2025-10-16 08:59:11,980 [INFO] 训练完成，耗时: 0.34 秒\n",
      "2025-10-16 08:59:11,981 [INFO] 评估训练集...\n",
      "2025-10-16 08:59:12,014 [INFO] 训练集精度: 0.9987, Kappa: 0.9983\n",
      "2025-10-16 08:59:12,856 [INFO] 开始预测整幅影像...\n",
      "2025-10-16 08:59:13,396 [INFO] 预测完成，耗时: 0.54 秒         \n",
      "2025-10-16 08:59:13,398 [INFO] 评估验证集...\n",
      "2025-10-16 08:59:13,462 [INFO] 验证集精度: 0.8121, Kappa: 0.7447\n",
      "2025-10-16 08:59:14,367 [INFO] 生成可视化结果...\n",
      "2025-10-16 08:59:16,990 [INFO] ✓ 决策树 测试完成\n",
      "2025-10-16 08:59:16,991 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:16,992 [INFO] 正在测试分类器: K近邻 (knn)\n",
      "2025-10-16 08:59:16,993 [INFO] ================================================================================\n",
      "2025-10-16 08:59:16,995 [INFO] 开始训练...\n",
      "2025-10-16 08:59:16,997 [ERROR] ✗ K近邻 测试失败: Input X contains NaN.\n",
      "KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:17,030 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:17,031 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:17,032 [INFO] 正在测试分类器: 朴素贝叶斯 (nb)\n",
      "2025-10-16 08:59:17,033 [INFO] ================================================================================\n",
      "2025-10-16 08:59:17,035 [INFO] 开始训练...\n",
      "2025-10-16 08:59:17,037 [ERROR] ✗ 朴素贝叶斯 测试失败: Input X contains NaN.\n",
      "GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:17,058 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 266, in fit\n",
      "    return self._partial_fit(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 426, in _partial_fit\n",
      "    X, y = validate_data(self, X, y, reset=first_call)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GaussianNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:17,059 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:17,060 [INFO] 正在测试分类器: 梯度提升 (gb)\n",
      "2025-10-16 08:59:17,061 [INFO] ================================================================================\n",
      "2025-10-16 08:59:17,063 [INFO] 开始训练...\n",
      "2025-10-16 08:59:17,065 [ERROR] ✗ 梯度提升 测试失败: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:17,085 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 658, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:17,086 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:17,087 [INFO] 正在测试分类器: AdaBoost (ada)\n",
      "2025-10-16 08:59:17,088 [INFO] ================================================================================\n",
      "2025-10-16 08:59:17,090 [INFO] 开始训练...\n",
      "2025-10-16 08:59:17,092 [ERROR] ✗ AdaBoost 测试失败: Input X contains NaN.\n",
      "AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:17,112 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 130, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:17,113 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:17,114 [INFO] 正在测试分类器: 极端随机树 (et)\n",
      "2025-10-16 08:59:17,115 [INFO] ================================================================================\n",
      "2025-10-16 08:59:17,117 [INFO] 开始训练...\n",
      "2025-10-16 08:59:17,369 [INFO] 训练完成，耗时: 0.25 秒\n",
      "2025-10-16 08:59:17,370 [INFO] 评估训练集...\n",
      "2025-10-16 08:59:17,493 [INFO] 训练集精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 08:59:18,333 [INFO] 开始预测整幅影像...\n",
      "2025-10-16 08:59:23,114 [INFO] 预测完成，耗时: 4.78 秒         \n",
      "2025-10-16 08:59:23,115 [INFO] 评估验证集...\n",
      "2025-10-16 08:59:23,171 [INFO] 验证集精度: 0.8819, Kappa: 0.8349\n",
      "2025-10-16 08:59:24,032 [INFO] 生成可视化结果...\n",
      "2025-10-16 08:59:26,659 [INFO] ✓ 极端随机树 测试完成\n",
      "2025-10-16 08:59:26,660 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:26,661 [INFO] 正在测试分类器: 逻辑回归 (lr)\n",
      "2025-10-16 08:59:26,662 [INFO] ================================================================================\n",
      "2025-10-16 08:59:26,664 [INFO] 开始训练...\n",
      "2025-10-16 08:59:26,667 [ERROR] ✗ 逻辑回归 测试失败: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:26,692 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1222, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:26,693 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:26,694 [INFO] 正在测试分类器: 神经网络 (mlp)\n",
      "2025-10-16 08:59:26,695 [INFO] ================================================================================\n",
      "2025-10-16 08:59:26,697 [INFO] 开始训练...\n",
      "2025-10-16 08:59:26,699 [ERROR] ✗ 神经网络 测试失败: Input X contains NaN.\n",
      "MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-10-16 08:59:26,721 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 754, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 442, in _fit\n",
      "    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1114, in _validate_input\n",
      "    X, y = validate_data(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "MLPClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "2025-10-16 08:59:26,722 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:26,723 [INFO] 正在测试分类器: XGBoost (xgb)\n",
      "2025-10-16 08:59:26,724 [INFO] ================================================================================\n",
      "2025-10-16 08:59:26,726 [INFO] 开始训练...\n",
      "2025-10-16 08:59:26,728 [ERROR] ✗ XGBoost 测试失败: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10], got [ 1  2  3  4  5  6  7  8  9 10 11]\n",
      "2025-10-16 08:59:26,731 [ERROR] Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3901964353.py\", line 820, in main\n",
      "    clf.fit(X_train, y_train)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\xgboost\\sklearn.py\", line 1640, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10], got [ 1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "2025-10-16 08:59:26,732 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:26,732 [INFO] 正在测试分类器: LightGBM (lgb)\n",
      "2025-10-16 08:59:26,733 [INFO] ================================================================================\n",
      "2025-10-16 08:59:26,735 [INFO] 开始训练...\n",
      "2025-10-16 08:59:40,769 [INFO] 训练完成，耗时: 14.03 秒\n",
      "2025-10-16 08:59:40,771 [INFO] 评估训练集...\n",
      "2025-10-16 08:59:40,936 [INFO] 训练集精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 08:59:41,969 [INFO] 开始预测整幅影像...\n",
      "2025-10-16 08:59:48,428 [INFO] 预测完成，耗时: 6.46 秒         \n",
      "2025-10-16 08:59:48,429 [INFO] 评估验证集...\n",
      "2025-10-16 08:59:48,483 [INFO] 验证集精度: 0.8768, Kappa: 0.8321\n",
      "2025-10-16 08:59:49,317 [INFO] 生成可视化结果...\n",
      "2025-10-16 08:59:52,004 [INFO] ✓ LightGBM 测试完成\n",
      "2025-10-16 08:59:52,005 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:52,006 [INFO] 生成对比分析报告...\n",
      "2025-10-16 08:59:52,007 [INFO] ================================================================================\n",
      "2025-10-16 08:59:52,012 [INFO] 对比表格已保存\n",
      "2025-10-16 08:59:52,013 [INFO] 生成对比图表...\n",
      "2025-10-16 08:59:55,790 [INFO] 生成文字报告...\n",
      "2025-10-16 08:59:55,802 [INFO] \n",
      "================================================================================\n",
      "2025-10-16 08:59:55,803 [INFO] 对比实验完成！\n",
      "2025-10-16 08:59:55,803 [INFO] ================================================================================\n",
      "2025-10-16 08:59:55,804 [INFO] \n",
      "总耗时: 56.7 秒\n",
      "2025-10-16 08:59:55,805 [INFO] 结果保存路径: d:\\code313\\Geo_programe\\rasterio\\RF\\results_comparison\n",
      "\n",
      "2025-10-16 08:59:55,806 [INFO] 【验证集精度 Top 3】\n",
      "2025-10-16 08:59:55,809 [INFO]   1. 极端随机树        - 精度: 0.8819, Kappa: 0.8349, 训练时间: 0.25s\n",
      "2025-10-16 08:59:55,810 [INFO]   2. 随机森林         - 精度: 0.8809, Kappa: 0.8361, 训练时间: 0.63s\n",
      "2025-10-16 08:59:55,811 [INFO]   3. LightGBM     - 精度: 0.8768, Kappa: 0.8321, 训练时间: 14.03s\n",
      "2025-10-16 08:59:55,812 [INFO] \n",
      "所有对比图表和报告已生成！\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用遥感影像监督分类系统 (多分类器对比版本)\n",
    "-------------------------------------------------\n",
    "功能：\n",
    "1. 自动读取多波段遥感影像；\n",
    "2. 从矢量样本中提取训练/验证数据；\n",
    "3. 支持12种分类器对比；\n",
    "4. 采用分块预测模式；\n",
    "5. 输出分类结果 GeoTIFF；\n",
    "6. 自动生成分类报告与混淆矩阵；\n",
    "7. 显示分类影像和精度评价结果；\n",
    "8. 分类面积统计（平方千米）；\n",
    "9. 后处理功能（去除小图斑、形态学操作）；\n",
    "10. 忽略背景值（所有波段值为0的像元）；\n",
    "11. 多分类器性能对比分析。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ------------------ 参数配置 ------------------\n",
    "IMAGE_PATH = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\2017_09_05_stack.tif\"\n",
    "TRAIN_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\cal.shp\"\n",
    "VAL_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\val.shp\"\n",
    "CLASS_ATTRIBUTE = \"class\"\n",
    "NAME_ATTRIBUTE = \"name\"\n",
    "OUT_DIR = Path(\"./results_comparison\")\n",
    "\n",
    "# 选择要对比的分类器（可以选择部分或全部）\n",
    "CLASSIFIERS_TO_RUN = [\n",
    "    \"rf\",           # Random Forest\n",
    "    \"svm\",          # Support Vector Machine\n",
    "    \"xgb\",          # XGBoost\n",
    "    \"dt\",           # Decision Tree\n",
    "    \"knn\",          # K-Nearest Neighbors\n",
    "    \"nb\",           # Naive Bayes\n",
    "    \"gb\",           # Gradient Boosting\n",
    "    \"ada\",          # AdaBoost\n",
    "    \"et\",           # Extra Trees\n",
    "    \"lr\",           # Logistic Regression\n",
    "    \"mlp\",          # Multi-layer Perceptron\n",
    "    \"lgb\"           # LightGBM\n",
    "]\n",
    "\n",
    "# 分类器参数\n",
    "N_ESTIMATORS = 100  # 减少到100以加快速度\n",
    "BLOCK_SIZE = 512\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 后处理参数\n",
    "POSTPROCESSING = False  # 对比时可暂时关闭后处理以加快速度\n",
    "MIN_PATCH_SIZE = 10\n",
    "MORPHOLOGY_OPERATION = \"opening\"\n",
    "MORPHOLOGY_SIZE = 3\n",
    "\n",
    "# 背景值处理\n",
    "BACKGROUND_VALUE = 0\n",
    "IGNORE_BACKGROUND = True\n",
    "\n",
    "# 预定义颜色映射\n",
    "LANDUSE_COLORS = {\n",
    "    \"水体\": \"lightblue\", \"河流\": \"blue\", \"湖泊\": \"deepskyblue\",\n",
    "    \"植被\": \"forestgreen\", \"森林\": \"darkgreen\", \"草地\": \"limegreen\",\n",
    "    \"农田\": \"yellowgreen\", \"耕地\": \"olivedrab\",\n",
    "    \"建筑\": \"gray\", \"城市\": \"dimgray\", \"居民地\": \"slategray\",\n",
    "    \"裸地\": \"tan\", \"沙地\": \"wheat\", \"其他\": \"darkred\"\n",
    "}\n",
    "\n",
    "COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                'darkred', 'purple', 'orange', 'pink', 'brown', \n",
    "                'cyan', 'magenta', 'lime', 'navy', 'teal']\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------ 日志系统 ------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"classification_comparison_log.txt\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ------------------ 分类器配置 ------------------\n",
    "def get_all_classifiers():\n",
    "    \"\"\"\n",
    "    获取所有分类器的配置\n",
    "    返回: {分类器代码: (分类器对象, 分类器名称, 分类器描述)}\n",
    "    \"\"\"\n",
    "    classifiers = {\n",
    "        \"rf\": (\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=N_ESTIMATORS, \n",
    "                n_jobs=-1, \n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=0\n",
    "            ),\n",
    "            \"随机森林\",\n",
    "            \"Random Forest - 集成学习方法，适合高维数据\"\n",
    "        ),\n",
    "        \"svm\": (\n",
    "            SVC(\n",
    "                kernel=\"rbf\", \n",
    "                probability=True, \n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=False\n",
    "            ),\n",
    "            \"支持向量机\",\n",
    "            \"Support Vector Machine - 基于核函数的分类器\"\n",
    "        ),\n",
    "        \"dt\": (\n",
    "            DecisionTreeClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                max_depth=20\n",
    "            ),\n",
    "            \"决策树\",\n",
    "            \"Decision Tree - 简单直观的树形分类器\"\n",
    "        ),\n",
    "        \"knn\": (\n",
    "            KNeighborsClassifier(\n",
    "                n_neighbors=5,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            \"K近邻\",\n",
    "            \"K-Nearest Neighbors - 基于距离的分类器\"\n",
    "        ),\n",
    "        \"nb\": (\n",
    "            GaussianNB(),\n",
    "            \"朴素贝叶斯\",\n",
    "            \"Naive Bayes - 基于概率的快速分类器\"\n",
    "        ),\n",
    "        \"gb\": (\n",
    "            GradientBoostingClassifier(\n",
    "                n_estimators=N_ESTIMATORS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=0\n",
    "            ),\n",
    "            \"梯度提升\",\n",
    "            \"Gradient Boosting - 强大的集成学习方法\"\n",
    "        ),\n",
    "        \"ada\": (\n",
    "            AdaBoostClassifier(\n",
    "                n_estimators=N_ESTIMATORS,\n",
    "                random_state=RANDOM_STATE\n",
    "            ),\n",
    "            \"AdaBoost\",\n",
    "            \"AdaBoost - 自适应提升集成方法\"\n",
    "        ),\n",
    "        \"et\": (\n",
    "            ExtraTreesClassifier(\n",
    "                n_estimators=N_ESTIMATORS,\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=0\n",
    "            ),\n",
    "            \"极端随机树\",\n",
    "            \"Extra Trees - 极端随机化的森林方法\"\n",
    "        ),\n",
    "        \"lr\": (\n",
    "            LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=0\n",
    "            ),\n",
    "            \"逻辑回归\",\n",
    "            \"Logistic Regression - 经典的线性分类器\"\n",
    "        ),\n",
    "        \"mlp\": (\n",
    "            MLPClassifier(\n",
    "                hidden_layer_sizes=(100, 50),\n",
    "                max_iter=300,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=False,\n",
    "                early_stopping=True\n",
    "            ),\n",
    "            \"神经网络\",\n",
    "            \"Multi-layer Perceptron - 前馈神经网络\"\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    # 尝试添加XGBoost\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        classifiers[\"xgb\"] = (\n",
    "            XGBClassifier(\n",
    "                n_estimators=N_ESTIMATORS,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=8,\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbosity=0\n",
    "            ),\n",
    "            \"XGBoost\",\n",
    "            \"XGBoost - 高性能梯度提升框架\"\n",
    "        )\n",
    "    except ImportError:\n",
    "        logger.warning(\"未安装 xgboost，跳过XGBoost分类器\")\n",
    "    \n",
    "    # 尝试添加LightGBM\n",
    "    try:\n",
    "        from lightgbm import LGBMClassifier\n",
    "        classifiers[\"lgb\"] = (\n",
    "            LGBMClassifier(\n",
    "                n_estimators=N_ESTIMATORS,\n",
    "                learning_rate=0.1,\n",
    "                n_jobs=-1,\n",
    "                random_state=RANDOM_STATE,\n",
    "                verbose=-1\n",
    "            ),\n",
    "            \"LightGBM\",\n",
    "            \"LightGBM - 轻量级梯度提升框架\"\n",
    "        )\n",
    "    except ImportError:\n",
    "        logger.warning(\"未安装 lightgbm，跳过LightGBM分类器\")\n",
    "    \n",
    "    return classifiers\n",
    "\n",
    "# ------------------ 辅助函数 ------------------\n",
    "def get_background_mask(image):\n",
    "    \"\"\"获取背景掩膜（所有波段值为0的像元）\"\"\"\n",
    "    data = image.values\n",
    "    background_mask = np.all(data == 0, axis=0)\n",
    "    return background_mask\n",
    "\n",
    "def get_class_info_from_shp(shp_path, class_attr, name_attr):\n",
    "    \"\"\"从shp文件中获取类别信息和自动生成的颜色\"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    \n",
    "    if name_attr not in gdf.columns:\n",
    "        logger.warning(f\"shp文件中没有找到 '{name_attr}' 字段，将使用类别编号作为名称\")\n",
    "        gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "    \n",
    "    class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "    class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "    \n",
    "    class_colors = {}\n",
    "    for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "        color_found = False\n",
    "        for key, color in LANDUSE_COLORS.items():\n",
    "            if key in class_name:\n",
    "                class_colors[class_id] = color\n",
    "                color_found = True\n",
    "                break\n",
    "        if not color_found:\n",
    "            class_colors[class_id] = COLOR_PALETTE[i % len(COLOR_PALETTE)]\n",
    "    \n",
    "    unique_classes = sorted(class_names.keys())\n",
    "    return class_names, class_colors, unique_classes\n",
    "\n",
    "def rasterize_samples(shp, ref_img, attr):\n",
    "    \"\"\"将矢量样本栅格化为与影像对齐的数组\"\"\"\n",
    "    gdf = gpd.read_file(shp)\n",
    "    gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "    \n",
    "    arr = features.rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=ref_img.shape[1:],\n",
    "        transform=ref_img.rio.transform(),\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=\"uint16\"\n",
    "    )\n",
    "    return arr\n",
    "\n",
    "def extract_samples(image, mask, ignore_background=True):\n",
    "    \"\"\"根据掩膜提取样本特征与标签\"\"\"\n",
    "    data = np.moveaxis(image.values, 0, -1)\n",
    "    valid = mask > 0\n",
    "    \n",
    "    if ignore_background:\n",
    "        background_mask = get_background_mask(image)\n",
    "        valid = valid & (~background_mask)\n",
    "        n_background = np.sum(mask > 0) - np.sum(valid)\n",
    "        if n_background > 0:\n",
    "            logger.debug(f\"排除了 {n_background} 个背景像元\")\n",
    "    \n",
    "    X = data[valid]\n",
    "    y = mask[valid]\n",
    "    return X, y\n",
    "\n",
    "def calculate_pixel_area(transform):\n",
    "    \"\"\"计算单个像元的面积（单位：平方米）\"\"\"\n",
    "    pixel_width = abs(transform[0])\n",
    "    pixel_height = abs(transform[4])\n",
    "    pixel_area = pixel_width * pixel_height\n",
    "    return pixel_area\n",
    "\n",
    "def predict_by_block(model, image, out_path, block_size=BLOCK_SIZE, ignore_background=True):\n",
    "    \"\"\"分块预测整幅影像\"\"\"\n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    prediction = np.zeros((height, width), dtype='uint16')\n",
    "    \n",
    "    if ignore_background:\n",
    "        background_mask = get_background_mask(image)\n",
    "    \n",
    "    for y in tqdm(range(0, height, block_size), desc=\"分块预测\", leave=False):\n",
    "        h = min(block_size, height - y)\n",
    "        block_data = image.isel(y=slice(y, y+h)).values\n",
    "        data = np.moveaxis(block_data, 0, -1)\n",
    "        original_shape = data.shape\n",
    "        data_flat = data.reshape(-1, data.shape[-1])\n",
    "        \n",
    "        if ignore_background:\n",
    "            block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "            non_bg_indices = ~block_bg_mask\n",
    "            \n",
    "            if np.any(non_bg_indices):\n",
    "                data_to_predict = np.nan_to_num(data_flat[non_bg_indices])\n",
    "                preds_non_bg = model.predict(data_to_predict)\n",
    "                preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                preds_flat[non_bg_indices] = preds_non_bg\n",
    "                preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "            else:\n",
    "                preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "        else:\n",
    "            data_flat = np.nan_to_num(data_flat)\n",
    "            preds = model.predict(data_flat).reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "        \n",
    "        prediction[y:y+h, :] = preds\n",
    "    \n",
    "    # 创建xarray DataArray\n",
    "    prediction_da = xr.DataArray(\n",
    "        prediction,\n",
    "        dims=['y', 'x'],\n",
    "        coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "    )\n",
    "    \n",
    "    prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "    prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "    prediction_da.rio.write_nodata(BACKGROUND_VALUE, inplace=True)\n",
    "    \n",
    "    prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', compress='lzw', tiled=True)\n",
    "    return out_path\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"计算分类指标\"\"\"\n",
    "    metrics = {\n",
    "        'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "        'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'precision_weighted': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'recall_weighted': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"绘制混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_classification_result(original_img, classified_img, class_names, class_colors, \n",
    "                               save_path, title_suffix=\"\"):\n",
    "    \"\"\"显示分类结果\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 原始影像\n",
    "    if original_img.shape[0] >= 3:\n",
    "        rgb_data = np.moveaxis(original_img.values[:3], 0, -1)\n",
    "        p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))\n",
    "        rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "        ax1.imshow(rgb_display)\n",
    "    else:\n",
    "        ax1.imshow(original_img.values[0], cmap='gray')\n",
    "    \n",
    "    ax1.set_title('原始遥感影像', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 分类结果\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]\n",
    "    \n",
    "    colors = [class_colors.get(c, 'black') for c in classes]\n",
    "    labels = [class_names.get(c, f'未知类别_{c}') for c in classes]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    display_data = classified_data.astype(float)\n",
    "    display_data[classified_data == 0] = np.nan\n",
    "    \n",
    "    ax2.imshow(display_data, cmap=cmap, norm=norm)\n",
    "    ax2.set_title(f'分类结果{title_suffix}', fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for color, label in zip(colors, labels)]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ 对比分析函数 ------------------\n",
    "def plot_classifier_comparison(comparison_df, save_dir):\n",
    "    \"\"\"绘制分类器性能对比图表\"\"\"\n",
    "    \n",
    "    # 1. 总体精度和Kappa系数对比\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 总体精度对比\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(comparison_df)))\n",
    "    bars1 = ax1.barh(comparison_df['分类器名称'], comparison_df['训练集精度'], \n",
    "                     color=colors, alpha=0.7, label='训练集')\n",
    "    bars2 = ax1.barh(comparison_df['分类器名称'], comparison_df['验证集精度'], \n",
    "                     color=colors, alpha=0.4, label='验证集')\n",
    "    \n",
    "    ax1.set_xlabel('总体精度', fontsize=12)\n",
    "    ax1.set_title('各分类器总体精度对比', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    ax1.set_xlim([0, 1])\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for i, (train_acc, val_acc) in enumerate(zip(comparison_df['训练集精度'], \n",
    "                                                   comparison_df['验证集精度'])):\n",
    "        ax1.text(train_acc + 0.01, i, f'{train_acc:.4f}', va='center', fontsize=9)\n",
    "        ax1.text(val_acc + 0.01, i, f'{val_acc:.4f}', va='center', fontsize=9)\n",
    "    \n",
    "    # Kappa系数对比\n",
    "    bars3 = ax2.barh(comparison_df['分类器名称'], comparison_df['训练集Kappa'], \n",
    "                     color=colors, alpha=0.7, label='训练集')\n",
    "    bars4 = ax2.barh(comparison_df['分类器名称'], comparison_df['验证集Kappa'], \n",
    "                     color=colors, alpha=0.4, label='验证集')\n",
    "    \n",
    "    ax2.set_xlabel('Kappa系数', fontsize=12)\n",
    "    ax2.set_title('各分类器Kappa系数对比', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    ax2.set_xlim([0, 1])\n",
    "    \n",
    "    for i, (train_kappa, val_kappa) in enumerate(zip(comparison_df['训练集Kappa'], \n",
    "                                                       comparison_df['验证集Kappa'])):\n",
    "        ax2.text(train_kappa + 0.01, i, f'{train_kappa:.4f}', va='center', fontsize=9)\n",
    "        ax2.text(val_kappa + 0.01, i, f'{val_kappa:.4f}', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_accuracy_kappa.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. F1分数对比\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(comparison_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, comparison_df['训练集F1'], width, label='训练集F1', alpha=0.8)\n",
    "    plt.bar(x + width/2, comparison_df['验证集F1'], width, label='验证集F1', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('分类器')\n",
    "    plt.ylabel('F1分数')\n",
    "    plt.title('各分类器F1分数对比', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, comparison_df['分类器名称'], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_f1.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 训练时间对比\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors_time = plt.cm.plasma(np.linspace(0, 1, len(comparison_df)))\n",
    "    bars = plt.bar(comparison_df['分类器名称'], comparison_df['训练时间(秒)'], \n",
    "                   color=colors_time, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('分类器')\n",
    "    plt.ylabel('训练时间 (秒)')\n",
    "    plt.title('各分类器训练时间对比', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for i, (bar, time_val) in enumerate(zip(bars, comparison_df['训练时间(秒)'])):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{time_val:.2f}s', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_training_time.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 预测时间对比\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(comparison_df['分类器名称'], comparison_df['预测时间(秒)'], \n",
    "                   color=colors_time, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('分类器')\n",
    "    plt.ylabel('预测时间 (秒)')\n",
    "    plt.title('各分类器预测时间对比', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (bar, time_val) in enumerate(zip(bars, comparison_df['预测时间(秒)'])):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{time_val:.2f}s', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_prediction_time.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. 综合性能雷达图\n",
    "    plot_radar_chart(comparison_df, save_dir)\n",
    "    \n",
    "    # 6. 散点图：精度 vs 速度\n",
    "    plot_accuracy_speed_scatter(comparison_df, save_dir)\n",
    "\n",
    "def plot_radar_chart(comparison_df, save_dir):\n",
    "    \"\"\"绘制性能雷达图\"\"\"\n",
    "    from math import pi\n",
    "    \n",
    "    # 选择前5个分类器\n",
    "    top_n = min(5, len(comparison_df))\n",
    "    top_df = comparison_df.nlargest(top_n, '验证集精度')\n",
    "    \n",
    "    categories = ['验证集精度', '验证集Kappa', '验证集F1', \n",
    "                  '训练速度*', '预测速度*']\n",
    "    N = len(categories)\n",
    "    \n",
    "    # 准备数据（归一化）\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    \n",
    "    colors_radar = plt.cm.Set2(np.linspace(0, 1, top_n))\n",
    "    \n",
    "    for idx, (_, row) in enumerate(top_df.iterrows()):\n",
    "        # 归一化数据（速度取倒数并归一化）\n",
    "        max_train_time = comparison_df['训练时间(秒)'].max()\n",
    "        max_pred_time = comparison_df['预测时间(秒)'].max()\n",
    "        \n",
    "        values = [\n",
    "            row['验证集精度'],\n",
    "            row['验证集Kappa'],\n",
    "            row['验证集F1'],\n",
    "            1 - (row['训练时间(秒)'] / max_train_time),  # 速度越快越好\n",
    "            1 - (row['预测时间(秒)'] / max_pred_time)\n",
    "        ]\n",
    "        values += values[:1]\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=row['分类器名称'], \n",
    "                color=colors_radar[idx])\n",
    "        ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])\n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax.set_title('分类器综合性能雷达图\\n(*速度指标已归一化，越大越好)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_radar.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_accuracy_speed_scatter(comparison_df, save_dir):\n",
    "    \"\"\"绘制精度-速度散点图\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 精度 vs 训练时间\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(comparison_df)))\n",
    "    \n",
    "    for idx, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        ax1.scatter(row['训练时间(秒)'], row['验证集精度'], \n",
    "                   s=200, c=[colors[idx]], alpha=0.7, edgecolors='black', linewidth=1)\n",
    "        ax1.annotate(row['分类器名称'], \n",
    "                    (row['训练时间(秒)'], row['验证集精度']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    ax1.set_xlabel('训练时间 (秒)', fontsize=12)\n",
    "    ax1.set_ylabel('验证集精度', fontsize=12)\n",
    "    ax1.set_title('精度 vs 训练时间', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 精度 vs 预测时间\n",
    "    for idx, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "        ax2.scatter(row['预测时间(秒)'], row['验证集精度'], \n",
    "                   s=200, c=[colors[idx]], alpha=0.7, edgecolors='black', linewidth=1)\n",
    "        ax2.annotate(row['分类器名称'], \n",
    "                    (row['预测时间(秒)'], row['验证集精度']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    ax2.set_xlabel('预测时间 (秒)', fontsize=12)\n",
    "    ax2.set_ylabel('验证集精度', fontsize=12)\n",
    "    ax2.set_title('精度 vs 预测时间', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"comparison_accuracy_speed.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def generate_comparison_report(comparison_df, save_path):\n",
    "    \"\"\"生成对比分析报告\"\"\"\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"          遥感影像分类器性能对比分析报告\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"分类器数量: {len(comparison_df)}\\n\")\n",
    "        f.write(f\"测试日期: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(\"一、验证集精度排名 (Total Accuracy)\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        sorted_by_acc = comparison_df.sort_values('验证集精度', ascending=False)\n",
    "        for idx, (_, row) in enumerate(sorted_by_acc.iterrows(), 1):\n",
    "            f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"精度: {row['验证集精度']:.4f}, \"\n",
    "                   f\"Kappa: {row['验证集Kappa']:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"二、Kappa系数排名\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        sorted_by_kappa = comparison_df.sort_values('验证集Kappa', ascending=False)\n",
    "        for idx, (_, row) in enumerate(sorted_by_kappa.iterrows(), 1):\n",
    "            f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"Kappa: {row['验证集Kappa']:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"三、F1分数排名\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        sorted_by_f1 = comparison_df.sort_values('验证集F1', ascending=False)\n",
    "        for idx, (_, row) in enumerate(sorted_by_f1.iterrows(), 1):\n",
    "            f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"F1: {row['验证集F1']:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"四、训练速度排名 (从快到慢)\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        sorted_by_train_time = comparison_df.sort_values('训练时间(秒)')\n",
    "        for idx, (_, row) in enumerate(sorted_by_train_time.iterrows(), 1):\n",
    "            f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"训练时间: {row['训练时间(秒)']:.2f} 秒\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"五、预测速度排名 (从快到慢)\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        sorted_by_pred_time = comparison_df.sort_values('预测时间(秒)')\n",
    "        for idx, (_, row) in enumerate(sorted_by_pred_time.iterrows(), 1):\n",
    "            f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"预测时间: {row['预测时间(秒)']:.2f} 秒\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"六、综合评价\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        \n",
    "        # 最佳精度\n",
    "        best_acc_row = comparison_df.loc[comparison_df['验证集精度'].idxmax()]\n",
    "        f.write(f\"\\n【最佳精度】 {best_acc_row['分类器名称']}\\n\")\n",
    "        f.write(f\"  验证集精度: {best_acc_row['验证集精度']:.4f}\\n\")\n",
    "        f.write(f\"  Kappa系数: {best_acc_row['验证集Kappa']:.4f}\\n\")\n",
    "        f.write(f\"  训练时间: {best_acc_row['训练时间(秒)']:.2f} 秒\\n\")\n",
    "        \n",
    "        # 最快速度\n",
    "        best_speed_row = comparison_df.loc[comparison_df['训练时间(秒)'].idxmin()]\n",
    "        f.write(f\"\\n【最快训练】 {best_speed_row['分类器名称']}\\n\")\n",
    "        f.write(f\"  训练时间: {best_speed_row['训练时间(秒)']:.2f} 秒\\n\")\n",
    "        f.write(f\"  验证集精度: {best_speed_row['验证集精度']:.4f}\\n\")\n",
    "        \n",
    "        # 综合性能（精度和速度的平衡）\n",
    "        comparison_df['综合得分'] = (\n",
    "            comparison_df['验证集精度'] * 0.6 + \n",
    "            (1 - comparison_df['训练时间(秒)'] / comparison_df['训练时间(秒)'].max()) * 0.2 +\n",
    "            (1 - comparison_df['预测时间(秒)'] / comparison_df['预测时间(秒)'].max()) * 0.2\n",
    "        )\n",
    "        best_overall_row = comparison_df.loc[comparison_df['综合得分'].idxmax()]\n",
    "        f.write(f\"\\n【综合最佳】 {best_overall_row['分类器名称']}\\n\")\n",
    "        f.write(f\"  综合得分: {best_overall_row['综合得分']:.4f}\\n\")\n",
    "        f.write(f\"  验证集精度: {best_overall_row['验证集精度']:.4f}\\n\")\n",
    "        f.write(f\"  训练时间: {best_overall_row['训练时间(秒)']:.2f} 秒\\n\")\n",
    "        f.write(f\"  预测时间: {best_overall_row['预测时间(秒)']:.2f} 秒\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"七、详细对比表格\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\\n\")\n",
    "        f.write(comparison_df.to_string(index=False))\n",
    "        \n",
    "        f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\")\n",
    "        f.write(\"注：综合得分 = 验证集精度×0.6 + 训练速度得分×0.2 + 预测速度得分×0.2\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"开始多分类器对比实验...\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    # 0. 获取所有可用分类器\n",
    "    all_classifiers = get_all_classifiers()\n",
    "    \n",
    "    # 筛选要运行的分类器\n",
    "    classifiers_to_run = {k: v for k, v in all_classifiers.items() \n",
    "                         if k in CLASSIFIERS_TO_RUN}\n",
    "    \n",
    "    if not classifiers_to_run:\n",
    "        logger.error(\"没有可用的分类器！请检查配置。\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"将对比 {len(classifiers_to_run)} 个分类器:\")\n",
    "    for code, (_, name, desc) in classifiers_to_run.items():\n",
    "        logger.info(f\"  - {name} ({code}): {desc}\")\n",
    "    \n",
    "    # 1. 读取类别信息\n",
    "    logger.info(\"\\n正在读取类别信息...\")\n",
    "    class_names, class_colors, train_classes = get_class_info_from_shp(\n",
    "        TRAIN_SHP, CLASS_ATTRIBUTE, NAME_ATTRIBUTE\n",
    "    )\n",
    "    logger.info(f\"检测到类别: {list(class_names.values())}\")\n",
    "    \n",
    "    # 2. 读取影像\n",
    "    logger.info(\"\\n正在读取遥感影像...\")\n",
    "    img = rxr.open_rasterio(IMAGE_PATH, masked=True)\n",
    "    logger.info(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "    \n",
    "    transform = img.rio.transform()\n",
    "    crs = img.rio.crs\n",
    "    pixel_area_m2 = calculate_pixel_area(transform)\n",
    "    pixel_area_km2 = pixel_area_m2 / 1e6\n",
    "    \n",
    "    # 3. 提取训练样本\n",
    "    logger.info(\"\\n正在处理训练样本...\")\n",
    "    train_mask = rasterize_samples(TRAIN_SHP, img, CLASS_ATTRIBUTE)\n",
    "    X_train, y_train = extract_samples(img, train_mask, ignore_background=IGNORE_BACKGROUND)\n",
    "    logger.info(f\"训练样本数: {len(y_train)}\")\n",
    "    \n",
    "    # 4. 提取验证样本\n",
    "    val_exists = os.path.exists(VAL_SHP)\n",
    "    if val_exists:\n",
    "        logger.info(\"正在处理验证样本...\")\n",
    "        val_mask = rasterize_samples(VAL_SHP, img, CLASS_ATTRIBUTE)\n",
    "        \n",
    "        if IGNORE_BACKGROUND:\n",
    "            background_mask = get_background_mask(img)\n",
    "            valid_val = (val_mask > 0) & (~background_mask)\n",
    "        else:\n",
    "            valid_val = val_mask > 0\n",
    "        \n",
    "        yv_true = val_mask[valid_val]\n",
    "        logger.info(f\"验证样本数: {len(yv_true)}\")\n",
    "    else:\n",
    "        logger.warning(f\"验证集文件不存在: {VAL_SHP}\")\n",
    "    \n",
    "    # 5. 对每个分类器进行训练和评估\n",
    "    comparison_results = []\n",
    "    \n",
    "    for clf_code, (clf, clf_name, clf_desc) in classifiers_to_run.items():\n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(f\"正在测试分类器: {clf_name} ({clf_code})\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        # 创建分类器专属目录\n",
    "        clf_dir = OUT_DIR / clf_code\n",
    "        clf_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # 训练\n",
    "            logger.info(\"开始训练...\")\n",
    "            train_start = time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time = time.time() - train_start\n",
    "            logger.info(f\"训练完成，耗时: {train_time:.2f} 秒\")\n",
    "            \n",
    "            # 训练集精度\n",
    "            logger.info(\"评估训练集...\")\n",
    "            y_train_pred = clf.predict(X_train)\n",
    "            train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "            logger.info(f\"训练集精度: {train_metrics['overall_accuracy']:.4f}, \"\n",
    "                       f\"Kappa: {train_metrics['kappa']:.4f}\")\n",
    "            \n",
    "            # 绘制训练集混淆矩阵\n",
    "            train_class_names = [class_names.get(c, f'Class_{c}') \n",
    "                               for c in sorted(np.unique(y_train))]\n",
    "            plot_confusion_matrix(y_train, y_train_pred, train_class_names,\n",
    "                                clf_dir / \"train_confusion_matrix.png\")\n",
    "            \n",
    "            # 预测整幅影像\n",
    "            logger.info(\"开始预测整幅影像...\")\n",
    "            pred_start = time.time()\n",
    "            classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "            predict_by_block(clf, img, classified_path, ignore_background=IGNORE_BACKGROUND)\n",
    "            pred_time = time.time() - pred_start\n",
    "            logger.info(f\"预测完成，耗时: {pred_time:.2f} 秒\")\n",
    "            \n",
    "            # 验证集精度\n",
    "            val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "            if val_exists:\n",
    "                logger.info(\"评估验证集...\")\n",
    "                with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                    pred_arr = pred_img.values.squeeze()\n",
    "                \n",
    "                yv_pred = pred_arr[valid_val]\n",
    "                val_metrics = calculate_metrics(yv_true, yv_pred)\n",
    "                logger.info(f\"验证集精度: {val_metrics['overall_accuracy']:.4f}, \"\n",
    "                           f\"Kappa: {val_metrics['kappa']:.4f}\")\n",
    "                \n",
    "                # 绘制验证集混淆矩阵\n",
    "                val_class_names = [class_names.get(c, f'Class_{c}') \n",
    "                                 for c in sorted(np.unique(yv_true))]\n",
    "                plot_confusion_matrix(yv_true, yv_pred, val_class_names,\n",
    "                                    clf_dir / \"val_confusion_matrix.png\")\n",
    "            \n",
    "            # 可视化分类结果\n",
    "            logger.info(\"生成可视化结果...\")\n",
    "            classified_img = rxr.open_rasterio(classified_path)\n",
    "            plot_classification_result(img, classified_img, class_names, class_colors,\n",
    "                                      clf_dir / f\"result_{clf_code}.png\",\n",
    "                                      f\" ({clf_name})\")\n",
    "            \n",
    "            # 记录结果\n",
    "            result = {\n",
    "                '分类器代码': clf_code,\n",
    "                '分类器名称': clf_name,\n",
    "                '描述': clf_desc,\n",
    "                '训练集精度': train_metrics['overall_accuracy'],\n",
    "                '训练集Kappa': train_metrics['kappa'],\n",
    "                '训练集F1': train_metrics['f1_macro'],\n",
    "                '验证集精度': val_metrics['overall_accuracy'],\n",
    "                '验证集Kappa': val_metrics['kappa'],\n",
    "                '验证集F1': val_metrics['f1_macro'],\n",
    "                '训练时间(秒)': train_time,\n",
    "                '预测时间(秒)': pred_time,\n",
    "                '总时间(秒)': train_time + pred_time\n",
    "            }\n",
    "            comparison_results.append(result)\n",
    "            \n",
    "            logger.info(f\"✓ {clf_name} 测试完成\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"✗ {clf_name} 测试失败: {str(e)}\")\n",
    "            import traceback\n",
    "            logger.error(traceback.format_exc())\n",
    "            continue\n",
    "    \n",
    "    # 6. 生成对比分析\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"生成对比分析报告...\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # 保存对比表格\n",
    "    comparison_df.to_csv(OUT_DIR / \"classifier_comparison.csv\", \n",
    "                        index=False, encoding='utf-8-sig')\n",
    "    logger.info(f\"对比表格已保存\")\n",
    "    \n",
    "    # 生成对比图表\n",
    "    logger.info(\"生成对比图表...\")\n",
    "    plot_classifier_comparison(comparison_df, OUT_DIR)\n",
    "    \n",
    "    # 生成文字报告\n",
    "    logger.info(\"生成文字报告...\")\n",
    "    generate_comparison_report(comparison_df, OUT_DIR / \"comparison_report.txt\")\n",
    "    \n",
    "    # 7. 输出摘要\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"对比实验完成！\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"\\n总耗时: {time.time() - t0:.1f} 秒\")\n",
    "    logger.info(f\"结果保存路径: {OUT_DIR.absolute()}\\n\")\n",
    "    \n",
    "    # 显示Top 3\n",
    "    logger.info(\"【验证集精度 Top 3】\")\n",
    "    top3 = comparison_df.nlargest(3, '验证集精度')\n",
    "    for idx, (_, row) in enumerate(top3.iterrows(), 1):\n",
    "        logger.info(f\"  {idx}. {row['分类器名称']:12s} - \"\n",
    "                   f\"精度: {row['验证集精度']:.4f}, \"\n",
    "                   f\"Kappa: {row['验证集Kappa']:.4f}, \"\n",
    "                   f\"训练时间: {row['训练时间(秒)']:.2f}s\")\n",
    "    \n",
    "    logger.info(\"\\n所有对比图表和报告已生成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e08312",
   "metadata": {},
   "source": [
    "## 主要特性\n",
    "\n",
    "### 1. **支持的分类器（12种）**\n",
    "- ✅ Random Forest (随机森林)\n",
    "- ✅ SVM (支持向量机)\n",
    "- ✅ XGBoost (极端梯度提升)\n",
    "- ✅ Decision Tree (决策树)\n",
    "- ✅ K-Nearest Neighbors (K近邻)\n",
    "- ✅ Naive Bayes (朴素贝叶斯)\n",
    "- ✅ Gradient Boosting (梯度提升)\n",
    "- ✅ AdaBoost (自适应提升)\n",
    "- ✅ Extra Trees (极端随机树)\n",
    "- ✅ Logistic Regression (逻辑回归)\n",
    "- ✅ Multi-layer Perceptron (神经网络)\n",
    "- ✅ LightGBM (轻量级梯度提升)\n",
    "\n",
    "### 2. **对比分析功能**\n",
    "\n",
    "#### 生成的对比图表：\n",
    "1. **总体精度和Kappa系数对比图** - 横向条形图\n",
    "2. **F1分数对比图** - 柱状图\n",
    "3. **训练时间对比图** - 柱状图\n",
    "4. **预测时间对比图** - 柱状图\n",
    "5. **综合性能雷达图** - 显示Top 5分类器\n",
    "6. **精度-速度散点图** - 展示性能权衡\n",
    "\n",
    "#### 生成的报告：\n",
    "- **comparison_report.txt** - 详细的文字对比报告\n",
    "- **classifier_comparison.csv** - Excel格式对比表格\n",
    "- 包含排名、最佳分类器推荐等\n",
    "\n",
    "### 3. **评价指标**\n",
    "- 总体精度 (Overall Accuracy)\n",
    "- Kappa系数\n",
    "- F1分数（宏平均和加权平均）\n",
    "- 精确率和召回率\n",
    "- 训练时间\n",
    "- 预测时间\n",
    "- 综合得分\n",
    "\n",
    "### 4. **使用方法**\n",
    "\n",
    "```python\n",
    "# 修改配置选择要对比的分类器\n",
    "CLASSIFIERS_TO_RUN = [\n",
    "    \"rf\",    # 随机森林\n",
    "    \"svm\",   # SVM\n",
    "    \"xgb\",   # XGBoost\n",
    "    \"dt\",    # 决策树\n",
    "    \"knn\",   # K近邻\n",
    "    \"nb\",    # 朴素贝叶斯\n",
    "    # ... 可以选择任意组合\n",
    "]\n",
    "\n",
    "# 运行程序\n",
    "python script.py\n",
    "```\n",
    "\n",
    "### 5. **输出结构**\n",
    "```\n",
    "results_comparison/\n",
    "├── rf/\n",
    "│   ├── classified_rf.tif\n",
    "│   ├── train_confusion_matrix.png\n",
    "│   ├── val_confusion_matrix.png\n",
    "│   └── result_rf.png\n",
    "├── svm/\n",
    "│   └── ...\n",
    "├── xgb/\n",
    "│   └── ...\n",
    "├── classifier_comparison.csv\n",
    "├── comparison_report.txt\n",
    "├── comparison_accuracy_kappa.png\n",
    "├── comparison_f1.png\n",
    "├── comparison_training_time.png\n",
    "├── comparison_prediction_time.png\n",
    "├── comparison_radar.png\n",
    "└── comparison_accuracy_speed.png\n",
    "```\n",
    "\n",
    "### 6. **性能优化建议**\n",
    "\n",
    "如果数据量很大，可以：\n",
    "1. 减少 `N_ESTIMATORS` (如设为50)\n",
    "2. 只选择部分分类器对比\n",
    "3. 使用样本采样加快训练\n",
    "4. 临时关闭后处理 `POSTPROCESSING = False`\n",
    "\n",
    "### 7. **报告示例内容**\n",
    "\n",
    "```\n",
    "一、验证集精度排名\n",
    "1. 随机森林     - 精度: 0.9245, Kappa: 0.9012\n",
    "2. XGBoost      - 精度: 0.9198, Kappa: 0.8956\n",
    "3. Extra Trees  - 精度: 0.9102, Kappa: 0.8845\n",
    "...\n",
    "\n",
    "【最佳精度】 随机森林\n",
    "  验证集精度: 0.9245\n",
    "  Kappa系数: 0.9012\n",
    "  训练时间: 45.32 秒\n",
    "\n",
    "【最快训练】 朴素贝叶斯\n",
    "  训练时间: 2.15 秒\n",
    "  验证集精度: 0.8234\n",
    "\n",
    "【综合最佳】 XGBoost\n",
    "  综合得分: 0.8956\n",
    "  验证集精度: 0.9198\n",
    "  训练时间: 52.18 秒\n",
    "```\n",
    "\n",
    "这个版本可以全面对比不同分类器的性能，帮助选择最适合您数据的方法！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a0eb7",
   "metadata": {},
   "source": [
    "## 交互界面\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126874b",
   "metadata": {},
   "source": [
    "### 基础版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038bb167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 09:45:36,101 [INFO] GDAL signalled an error: err_no=1, msg='Deleting results_gui\\\\et\\\\classified_et.tif failed:\\nPermission denied'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "遥感影像监督分类系统 - GUI版本 (修复版)\n",
    "支持多分类器对比和可视化\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ==================== 后端处理类 ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"分类处理后端\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.BACKGROUND_VALUE = 0\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # 预定义颜色\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"水体\": \"lightblue\", \"河流\": \"blue\", \"湖泊\": \"deepskyblue\",\n",
    "            \"植被\": \"forestgreen\", \"森林\": \"darkgreen\", \"草地\": \"limegreen\",\n",
    "            \"农田\": \"yellowgreen\", \"耕地\": \"olivedrab\",\n",
    "            \"建筑\": \"gray\", \"城市\": \"dimgray\", \"居民地\": \"slategray\",\n",
    "            \"裸地\": \"tan\", \"沙地\": \"wheat\", \"其他\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100):\n",
    "        \"\"\"获取所有分类器\"\"\"\n",
    "        classifiers = {\n",
    "            \"rf\": (\n",
    "                RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1, \n",
    "                                      random_state=self.RANDOM_STATE, verbose=0),\n",
    "                \"随机森林\", \"Random Forest - 集成学习方法\", False\n",
    "            ),\n",
    "            \"svm\": (\n",
    "                SVC(kernel=\"rbf\", probability=True, random_state=self.RANDOM_STATE),\n",
    "                \"支持向量机\", \"Support Vector Machine\", False\n",
    "            ),\n",
    "            \"dt\": (\n",
    "                DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=20),\n",
    "                \"决策树\", \"Decision Tree\", False\n",
    "            ),\n",
    "            \"knn\": (\n",
    "                KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "                \"K近邻\", \"K-Nearest Neighbors\", False\n",
    "            ),\n",
    "            \"nb\": (\n",
    "                GaussianNB(),\n",
    "                \"朴素贝叶斯\", \"Naive Bayes\", False\n",
    "            ),\n",
    "            \"gb\": (\n",
    "                GradientBoostingClassifier(n_estimators=n_estimators, \n",
    "                                          random_state=self.RANDOM_STATE, verbose=0),\n",
    "                \"梯度提升\", \"Gradient Boosting\", False\n",
    "            ),\n",
    "            \"ada\": (\n",
    "                AdaBoostClassifier(n_estimators=n_estimators, random_state=self.RANDOM_STATE),\n",
    "                \"AdaBoost\", \"AdaBoost\", False\n",
    "            ),\n",
    "            \"et\": (\n",
    "                ExtraTreesClassifier(n_estimators=n_estimators, n_jobs=-1, \n",
    "                                    random_state=self.RANDOM_STATE, verbose=0),\n",
    "                \"极端随机树\", \"Extra Trees\", False\n",
    "            ),\n",
    "            \"lr\": (\n",
    "                LogisticRegression(max_iter=1000, n_jobs=-1, \n",
    "                                  random_state=self.RANDOM_STATE, verbose=0),\n",
    "                \"逻辑回归\", \"Logistic Regression\", False\n",
    "            ),\n",
    "            \"mlp\": (\n",
    "                MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300,\n",
    "                            random_state=self.RANDOM_STATE, verbose=False, early_stopping=True),\n",
    "                \"神经网络\", \"Neural Network\", False\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            classifiers[\"xgb\"] = (\n",
    "                XGBClassifier(n_estimators=n_estimators, learning_rate=0.1, max_depth=8,\n",
    "                            n_jobs=-1, random_state=self.RANDOM_STATE, verbosity=0),\n",
    "                \"XGBoost\", \"XGBoost\", True  # 需要标签编码\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "            classifiers[\"lgb\"] = (\n",
    "                LGBMClassifier(n_estimators=n_estimators, learning_rate=0.1,\n",
    "                             n_jobs=-1, random_state=self.RANDOM_STATE, verbose=-1),\n",
    "                \"LightGBM\", \"LightGBM\", False\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image):\n",
    "        \"\"\"获取背景掩膜\"\"\"\n",
    "        data = image.values\n",
    "        background_mask = np.all(data == 0, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"从shp文件获取类别信息\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in class_name:\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"矢量栅格化\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=ref_img.shape[1:],\n",
    "            transform=ref_img.rio.transform(),\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint16\"\n",
    "        )\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True):\n",
    "        \"\"\"提取样本并清理NaN值\"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # ===== 关键修复：处理NaN值 =====\n",
    "        # 检查是否有NaN\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        n_nan = np.sum(nan_mask)\n",
    "        \n",
    "        if n_nan > 0:\n",
    "            # 方法1: 删除包含NaN的样本（推荐）\n",
    "            X = X[~nan_mask]\n",
    "            y = y[~nan_mask]\n",
    "            # 方法2: 也可以用0填充NaN\n",
    "            # X = np.nan_to_num(X, nan=0.0)\n",
    "        \n",
    "        # 再次检查是否还有无穷值\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        if n_inf > 0:\n",
    "            X = X[~inf_mask]\n",
    "            y = y[~inf_mask]\n",
    "        \n",
    "        return X, y, n_nan, n_inf\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"计算评价指标\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, progress_callback=None,\n",
    "                        label_encoder=None):\n",
    "        \"\"\"分块预测\"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], nan=0.0, \n",
    "                                                   posinf=0.0, neginf=0.0)\n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    # 如果使用了标签编码，需要反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # 保存结果\n",
    "        prediction_da = xr.DataArray(\n",
    "            prediction,\n",
    "            dims=['y', 'x'],\n",
    "            coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "        )\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(self.BACKGROUND_VALUE, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUI主类 ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"遥感影像分类GUI主界面\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"遥感影像监督分类系统 v2.1\")\n",
    "        self.root.geometry(\"1400x900\")\n",
    "        \n",
    "        # 后端处理对象\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # 数据变量\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        self.class_attr = tk.StringVar(value=\"class\")\n",
    "        self.name_attr = tk.StringVar(value=\"name\")\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # 分类器选择\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code, (_, name, _, _) in all_classifiers.items():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # 运行状态\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # 构建界面\n",
    "        self.build_ui()\n",
    "        \n",
    "        # 启动日志更新\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"构建用户界面\"\"\"\n",
    "        # 创建主框架\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.rowconfigure(0, weight=1)\n",
    "        main_frame.columnconfigure(1, weight=1)\n",
    "        main_frame.rowconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 1. 文件选择区 =====\n",
    "        file_frame = ttk.LabelFrame(main_frame, text=\"1. 数据输入\", padding=\"10\")\n",
    "        file_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)\n",
    "        \n",
    "        # 影像文件\n",
    "        ttk.Label(file_frame, text=\"影像文件:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=60).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_image).grid(\n",
    "            row=0, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 训练样本\n",
    "        ttk.Label(file_frame, text=\"训练样本:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=60).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_train_shp).grid(\n",
    "            row=1, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 验证样本\n",
    "        ttk.Label(file_frame, text=\"验证样本:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=60).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_val_shp).grid(\n",
    "            row=2, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 输出目录\n",
    "        ttk.Label(file_frame, text=\"输出目录:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=60).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_output).grid(\n",
    "            row=3, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # ===== 2. 参数设置区 =====\n",
    "        param_frame = ttk.LabelFrame(main_frame, text=\"2. 参数配置\", padding=\"10\")\n",
    "        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N), pady=5, padx=(0, 5))\n",
    "        \n",
    "        # 属性字段\n",
    "        ttk.Label(param_frame, text=\"类别编号字段:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.class_attr, width=15).grid(\n",
    "            row=0, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"类别名称字段:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.name_attr, width=15).grid(\n",
    "            row=1, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # 其他参数\n",
    "        ttk.Label(param_frame, text=\"树模型数量:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=13).grid(row=2, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"分块大小:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=13).grid(\n",
    "            row=3, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"忽略背景值（所有波段为0）\", \n",
    "                       variable=self.ignore_background).grid(\n",
    "            row=4, column=0, columnspan=2, sticky=tk.W, pady=5\n",
    "        )\n",
    "        \n",
    "        # ===== 3. 分类器选择区 =====\n",
    "        clf_frame = ttk.LabelFrame(main_frame, text=\"3. 分类器选择\", padding=\"10\")\n",
    "        clf_frame.grid(row=1, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        # 快捷按钮\n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 5))\n",
    "        ttk.Button(btn_frame, text=\"全选\", command=self.select_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"全不选\", command=self.deselect_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"推荐选择\", command=self.select_recommended).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        \n",
    "        # 分类器复选框\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        row = 1\n",
    "        col = 0\n",
    "        for code, (_, name, desc, _) in all_classifiers.items():\n",
    "            cb = ttk.Checkbutton(clf_frame, text=f\"{name} ({code})\", \n",
    "                               variable=self.classifier_vars[code])\n",
    "            cb.grid(row=row, column=col, sticky=tk.W, pady=2, padx=5)\n",
    "            \n",
    "            col += 1\n",
    "            if col >= 3:\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        # ===== 4. 控制按钮区 =====\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"4. 运行控制\", padding=\"10\")\n",
    "        control_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5, padx=(0, 5))\n",
    "        \n",
    "        self.start_btn = ttk.Button(control_frame, text=\"开始分类\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"停止\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"打开结果目录\", \n",
    "                  command=self.open_result_dir, width=15).grid(\n",
    "            row=0, column=2, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"查看对比报告\", \n",
    "                  command=self.view_report, width=15).grid(\n",
    "            row=0, column=3, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        # 进度条\n",
    "        ttk.Label(control_frame, text=\"进度:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100, length=400)\n",
    "        self.progress_bar.grid(row=1, column=1, columnspan=3, sticky=(tk.W, tk.E), \n",
    "                              padx=5, pady=2)\n",
    "        \n",
    "        control_frame.columnconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 5. 日志输出区 =====\n",
    "        log_frame = ttk.LabelFrame(main_frame, text=\"5. 运行日志\", padding=\"10\")\n",
    "        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, \n",
    "                                                  height=20, width=100)\n",
    "        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        log_frame.columnconfigure(0, weight=1)\n",
    "        log_frame.rowconfigure(0, weight=1)\n",
    "        \n",
    "        # 状态栏\n",
    "        self.status_var = tk.StringVar(value=\"就绪\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))\n",
    "    \n",
    "    # ===== 文件浏览函数 =====\n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择影像文件\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择训练样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择验证样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"选择输出目录\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "    \n",
    "    # ===== 分类器选择函数 =====\n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        \"\"\"选择推荐的分类器\"\"\"\n",
    "        recommended = [\"rf\", \"xgb\", \"svm\", \"et\", \"gb\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "    \n",
    "    # ===== 日志相关函数 =====\n",
    "    def log(self, message):\n",
    "        \"\"\"添加日志消息\"\"\"\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        \"\"\"更新日志显示\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        \n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    # ===== 主要功能函数 =====\n",
    "    def start_classification(self):\n",
    "        \"\"\"开始分类\"\"\"\n",
    "        # 检查输入\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择影像文件！\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择训练样本！\")\n",
    "            return\n",
    "        \n",
    "        # 检查是否至少选择了一个分类器\n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() \n",
    "                               if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"错误\", \"请至少选择一个分类器！\")\n",
    "            return\n",
    "        \n",
    "        # 禁用开始按钮，启用停止按钮\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        # 清空日志\n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"开始分类任务...\")\n",
    "        self.log(\"=\"*80)\n",
    "        \n",
    "        # 在新线程中运行分类\n",
    "        thread = threading.Thread(target=self.run_classification, \n",
    "                                 args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        \"\"\"停止分类\"\"\"\n",
    "        self.is_running = False\n",
    "        self.log(\"\\n用户请求停止...\")\n",
    "        self.status_var.set(\"已停止\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"执行分类（在后台线程中运行）\"\"\"\n",
    "        try:\n",
    "            # 创建输出目录\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # 1. 读取影像\n",
    "            self.log(f\"\\n正在读取影像: {self.image_path.get()}\")\n",
    "            self.status_var.set(\"读取影像...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            self.log(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 2. 读取类别信息\n",
    "            self.log(\"\\n正在读取类别信息...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), \n",
    "                self.class_attr.get(), \n",
    "                self.name_attr.get()\n",
    "            )\n",
    "            self.log(f\"检测到类别: {list(class_names.values())}\")\n",
    "            \n",
    "            # 3. 提取训练样本\n",
    "            self.log(\"\\n正在处理训练样本...\")\n",
    "            self.status_var.set(\"处理训练样本...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            X_train, y_train, n_nan, n_inf = self.backend.extract_samples(\n",
    "                img, train_mask, ignore_background=self.ignore_background.get()\n",
    "            )\n",
    "            self.log(f\"训练样本数: {len(y_train)}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"  已移除 {n_nan} 个包含NaN的样本\")\n",
    "            if n_inf > 0:\n",
    "                self.log(f\"  已移除 {n_inf} 个包含Inf的样本\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 4. 提取验证样本（如果有）\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(\"\\n正在处理验证样本...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(img)\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"验证样本数: {len(yv_true)}\")\n",
    "            \n",
    "            # 5. 对每个选择的分类器进行训练和评估\n",
    "            all_classifiers = self.backend.get_all_classifiers(self.n_estimators.get())\n",
    "            comparison_results = []\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] 正在测试: {clf_name} ({clf_code})\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                self.status_var.set(f\"训练 {clf_name}...\")\n",
    "                \n",
    "                # 创建分类器目录\n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # ===== 标签编码（如果需要）=====\n",
    "                    label_encoder = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    if needs_encoding:\n",
    "                        self.log(\"  使用标签编码...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    # 训练\n",
    "                    self.log(\"开始训练...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"训练完成，耗时: {train_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 训练集精度\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    # 如果使用了标签编码，需要反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"训练集精度: {train_metrics['overall_accuracy']:.4f}, \"\n",
    "                           f\"Kappa: {train_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # 预测整幅影像\n",
    "                    self.log(\"开始预测整幅影像...\")\n",
    "                    self.status_var.set(f\"预测 {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"预测完成，耗时: {pred_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 验证集精度\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "                    if val_exists:\n",
    "                        self.log(\"评估验证集...\")\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"验证集精度: {val_metrics['overall_accuracy']:.4f}, \"\n",
    "                               f\"Kappa: {val_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    # 记录结果\n",
    "                    result = {\n",
    "                        '分类器代码': clf_code,\n",
    "                        '分类器名称': clf_name,\n",
    "                        '训练集精度': train_metrics['overall_accuracy'],\n",
    "                        '训练集Kappa': train_metrics['kappa'],\n",
    "                        '训练集F1': train_metrics['f1_macro'],\n",
    "                        '验证集精度': val_metrics['overall_accuracy'],\n",
    "                        '验证集Kappa': val_metrics['kappa'],\n",
    "                        '验证集F1': val_metrics['f1_macro'],\n",
    "                        '训练时间(秒)': train_time,\n",
    "                        '预测时间(秒)': pred_time,\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    \n",
    "                    self.log(f\"✓ {clf_name} 完成\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"✗ {clf_name} 失败: {str(e)}\")\n",
    "                    import traceback\n",
    "                    self.log(traceback.format_exc())\n",
    "                    continue\n",
    "                \n",
    "                # 更新总进度\n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # 6. 生成对比报告\n",
    "            if comparison_results and self.is_running:\n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"生成对比报告...\")\n",
    "                self.status_var.set(\"生成报告...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # 生成简要报告\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"分类器性能对比摘要\\n\")\n",
    "                    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(f\"成功完成: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\\n\\n\")\n",
    "                    \n",
    "                    sorted_df = comparison_df.sort_values('验证集精度', ascending=False)\n",
    "                    f.write(\"验证集精度排名:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"精度: {row['验证集精度']:.4f}, \"\n",
    "                               f\"Kappa: {row['验证集Kappa']:.4f}, \"\n",
    "                               f\"F1: {row['验证集F1']:.4f}\\n\")\n",
    "                    \n",
    "                    f.write(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "                    f.write(\"训练时间排名:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    sorted_time = comparison_df.sort_values('训练时间(秒)')\n",
    "                    for idx, (_, row) in enumerate(sorted_time.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"{row['训练时间(秒)']:.2f} 秒\\n\")\n",
    "                \n",
    "                self.log(\"\\n✓ 所有任务完成！\")\n",
    "                self.log(f\"结果保存至: {out_dir.absolute()}\")\n",
    "                self.log(f\"成功: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\")\n",
    "                self.status_var.set(\"完成\")\n",
    "                \n",
    "                messagebox.showinfo(\"完成\", \n",
    "                    f\"分类任务完成！\\n成功: {len(comparison_results)}/{len(selected_classifiers)}\\n结果保存至: {out_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\n错误: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"错误\", f\"发生错误:\\n{str(e)}\")\n",
    "            self.status_var.set(\"错误\")\n",
    "        \n",
    "        finally:\n",
    "            # 恢复按钮状态\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"打开结果目录\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":  # macOS\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:  # Linux\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"结果目录不存在！\")\n",
    "    \n",
    "    def view_report(self):\n",
    "        \"\"\"查看对比报告\"\"\"\n",
    "        report_file = Path(self.output_dir.get()) / \"comparison_summary.txt\"\n",
    "        if report_file.exists():\n",
    "            # 创建新窗口显示报告\n",
    "            report_window = tk.Toplevel(self.root)\n",
    "            report_window.title(\"分类器对比报告\")\n",
    "            report_window.geometry(\"800x600\")\n",
    "            \n",
    "            text_widget = scrolledtext.ScrolledText(report_window, wrap=tk.WORD)\n",
    "            text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "            \n",
    "            with open(report_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                text_widget.insert(1.0, content)\n",
    "            \n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"报告文件不存在！请先运行分类。\")\n",
    "\n",
    "# ==================== 主程序入口 ====================\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = ClassificationGUI(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8947d4",
   "metadata": {},
   "source": [
    "### 优化版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa1007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "遥感影像监督分类系统 - GUI版本 (性能优化版)\n",
    "支持多分类器对比和可视化\n",
    "优化：数据采样、特征缩放、参数调优、并行处理\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ==================== 后端处理类 ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"分类处理后端（性能优化版）\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.BACKGROUND_VALUE = 0\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # 预定义颜色\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"水体\": \"lightblue\", \"河流\": \"blue\", \"湖泊\": \"deepskyblue\",\n",
    "            \"植被\": \"forestgreen\", \"森林\": \"darkgreen\", \"草地\": \"limegreen\",\n",
    "            \"农田\": \"yellowgreen\", \"耕地\": \"olivedrab\",\n",
    "            \"建筑\": \"gray\", \"城市\": \"dimgray\", \"居民地\": \"slategray\",\n",
    "            \"裸地\": \"tan\", \"沙地\": \"wheat\", \"其他\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100, fast_mode=False):\n",
    "        \"\"\"\n",
    "        获取所有分类器（优化参数）\n",
    "        fast_mode: 快速模式，使用更少的估计器和更简单的参数\n",
    "        \"\"\"\n",
    "        # 根据模式调整参数\n",
    "        if fast_mode:\n",
    "            n_est = min(50, n_estimators)\n",
    "            max_depth = 10\n",
    "            max_iter = 200\n",
    "        else:\n",
    "            n_est = n_estimators\n",
    "            max_depth = 20\n",
    "            max_iter = 500\n",
    "        \n",
    "        classifiers = {\n",
    "            \"rf\": (\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=n_est, \n",
    "                    n_jobs=-1, \n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    max_features='sqrt'  # 减少特征数量\n",
    "                ),\n",
    "                \"随机森林\", \"Random Forest\", False, False\n",
    "            ),\n",
    "            \"svm\": (\n",
    "                SVC(\n",
    "                    kernel=\"rbf\", \n",
    "                    C=1.0,\n",
    "                    gamma='scale',\n",
    "                    cache_size=500,  # 增加缓存\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                ),\n",
    "                \"支持向量机\", \"SVM\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"dt\": (\n",
    "                DecisionTreeClassifier(\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2\n",
    "                ),\n",
    "                \"决策树\", \"Decision Tree\", False, False\n",
    "            ),\n",
    "            \"knn\": (\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=5,\n",
    "                    n_jobs=-1,\n",
    "                    algorithm='ball_tree',  # 更快的算法\n",
    "                    leaf_size=30\n",
    "                ),\n",
    "                \"K近邻\", \"KNN\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"nb\": (\n",
    "                GaussianNB(),\n",
    "                \"朴素贝叶斯\", \"Naive Bayes\", False, False\n",
    "            ),\n",
    "            \"gb\": (\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5,  # 减小深度提高速度\n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    subsample=0.8  # 使用子采样\n",
    "                ),\n",
    "                \"梯度提升\", \"Gradient Boosting\", False, False\n",
    "            ),\n",
    "            \"ada\": (\n",
    "                AdaBoostClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=1.0,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    algorithm='SAMME.R'  # 更快的算法\n",
    "                ),\n",
    "                \"AdaBoost\", \"AdaBoost\", False, False\n",
    "            ),\n",
    "            \"et\": (\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"极端随机树\", \"Extra Trees\", False, False\n",
    "            ),\n",
    "            \"lr\": (\n",
    "                LogisticRegression(\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    solver='lbfgs',  # 快速求解器\n",
    "                    multi_class='multinomial'\n",
    "                ),\n",
    "                \"逻辑回归\", \"Logistic Regression\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"mlp\": (\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=(100, 50),\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=False,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction=0.1,\n",
    "                    n_iter_no_change=10,  # 早停\n",
    "                    learning_rate='adaptive'\n",
    "                ),\n",
    "                \"神经网络\", \"MLP\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        # XGBoost\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            classifiers[\"xgb\"] = (\n",
    "                XGBClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,  # 减小深度\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbosity=0,\n",
    "                    tree_method='hist',  # 使用直方图算法，更快\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"XGBoost\", \"XGBoost\", True, False  # 需要标签编码\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        # LightGBM\n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "            classifiers[\"lgb\"] = (\n",
    "                LGBMClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=max_depth,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=-1,\n",
    "                    num_leaves=31,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"LightGBM\", \"LightGBM\", False, False\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image):\n",
    "        \"\"\"获取背景掩膜\"\"\"\n",
    "        data = image.values\n",
    "        background_mask = np.all(data == 0, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"从shp文件获取类别信息\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in class_name:\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"矢量栅格化\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=ref_img.shape[1:],\n",
    "            transform=ref_img.rio.transform(),\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint16\"\n",
    "        )\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True, max_samples=None):\n",
    "        \"\"\"\n",
    "        提取样本并清理NaN值\n",
    "        max_samples: 最大样本数，如果超过则进行分层采样\n",
    "        \"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # 清理NaN和Inf值\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        bad_mask = nan_mask | inf_mask\n",
    "        \n",
    "        n_nan = np.sum(nan_mask)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        X = X[~bad_mask]\n",
    "        y = y[~bad_mask]\n",
    "        \n",
    "        # ===== 性能优化：分层采样 =====\n",
    "        n_sampled = 0\n",
    "        if max_samples is not None and len(y) > max_samples:\n",
    "            n_original = len(y)\n",
    "            \n",
    "            # 使用分层采样保持类别比例\n",
    "            unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "            \n",
    "            if len(unique_classes) > 1:\n",
    "                # 使用sklearn的分层采样\n",
    "                splitter = StratifiedShuffleSplit(\n",
    "                    n_splits=1, \n",
    "                    train_size=max_samples, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                )\n",
    "                \n",
    "                sample_idx, _ = next(splitter.split(X, y))\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "            else:\n",
    "                # 只有一个类别，随机采样\n",
    "                np.random.seed(self.RANDOM_STATE)\n",
    "                sample_idx = np.random.choice(len(y), max_samples, replace=False)\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "        \n",
    "        return X, y, n_nan, n_inf, n_sampled\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"计算评价指标\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, progress_callback=None,\n",
    "                        label_encoder=None, scaler=None):\n",
    "        \"\"\"\n",
    "        分块预测（优化版）\n",
    "        添加了特征缩放支持\n",
    "        \"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], \n",
    "                                                   nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    # 如果使用了特征缩放\n",
    "                    if scaler is not None:\n",
    "                        data_to_predict = scaler.transform(data_to_predict)\n",
    "                    \n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    # 如果使用了标签编码，需要反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    data_flat = scaler.transform(data_flat)\n",
    "                \n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # 保存结果\n",
    "        prediction_da = xr.DataArray(\n",
    "            prediction,\n",
    "            dims=['y', 'x'],\n",
    "            coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "        )\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(self.BACKGROUND_VALUE, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUI主类 ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"遥感影像分类GUI主界面（性能优化版）\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"遥感影像监督分类系统 v2.2 (性能优化版)\")\n",
    "        self.root.geometry(\"1400x900\")\n",
    "        \n",
    "        # 后端处理对象\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # 数据变量\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        self.class_attr = tk.StringVar(value=\"class\")\n",
    "        self.name_attr = tk.StringVar(value=\"name\")\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # ===== 性能优化参数 =====\n",
    "        self.enable_sampling = tk.BooleanVar(value=True)  # 启用采样\n",
    "        self.max_samples = tk.IntVar(value=50000)  # 最大样本数\n",
    "        self.fast_mode = tk.BooleanVar(value=False)  # 快速模式\n",
    "        \n",
    "        # 分类器选择\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code, (_, name, _, _, _) in all_classifiers.items():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # 运行状态\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # 构建界面\n",
    "        self.build_ui()\n",
    "        \n",
    "        # 启动日志更新\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"构建用户界面\"\"\"\n",
    "        # 创建主框架\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.rowconfigure(0, weight=1)\n",
    "        main_frame.columnconfigure(1, weight=1)\n",
    "        main_frame.rowconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 1. 文件选择区 =====\n",
    "        file_frame = ttk.LabelFrame(main_frame, text=\"1. 数据输入\", padding=\"10\")\n",
    "        file_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)\n",
    "        \n",
    "        # 影像文件\n",
    "        ttk.Label(file_frame, text=\"影像文件:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=60).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_image).grid(\n",
    "            row=0, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 训练样本\n",
    "        ttk.Label(file_frame, text=\"训练样本:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=60).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_train_shp).grid(\n",
    "            row=1, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 验证样本\n",
    "        ttk.Label(file_frame, text=\"验证样本:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=60).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_val_shp).grid(\n",
    "            row=2, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 输出目录\n",
    "        ttk.Label(file_frame, text=\"输出目录:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=60).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_output).grid(\n",
    "            row=3, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # ===== 2. 参数设置区 =====\n",
    "        param_frame = ttk.LabelFrame(main_frame, text=\"2. 参数配置\", padding=\"10\")\n",
    "        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N), pady=5, padx=(0, 5))\n",
    "        \n",
    "        # 属性字段\n",
    "        ttk.Label(param_frame, text=\"类别编号字段:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.class_attr, width=15).grid(\n",
    "            row=0, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"类别名称字段:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.name_attr, width=15).grid(\n",
    "            row=1, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # 其他参数\n",
    "        ttk.Label(param_frame, text=\"树模型数量:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=13).grid(row=2, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"分块大小:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=13).grid(\n",
    "            row=3, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # ===== 性能优化选项 =====\n",
    "        ttk.Separator(param_frame, orient='horizontal').grid(\n",
    "            row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"性能优化:\", font=('', 9, 'bold')).grid(\n",
    "            row=5, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        sample_frame = ttk.Frame(param_frame)\n",
    "        sample_frame.grid(row=6, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        ttk.Checkbutton(sample_frame, text=\"启用采样\", \n",
    "                       variable=self.enable_sampling,\n",
    "                       command=self.toggle_sampling).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Label(sample_frame, text=\"  最大样本数:\").pack(side=tk.LEFT, padx=(10, 0))\n",
    "        self.max_samples_spinbox = ttk.Spinbox(\n",
    "            sample_frame, from_=10000, to=200000, increment=10000,\n",
    "            textvariable=self.max_samples, width=10\n",
    "        )\n",
    "        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"快速模式（减少模型复杂度）\", \n",
    "                       variable=self.fast_mode).grid(\n",
    "            row=7, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"忽略背景值（所有波段为0）\", \n",
    "                       variable=self.ignore_background).grid(\n",
    "            row=8, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        # ===== 3. 分类器选择区 =====\n",
    "        clf_frame = ttk.LabelFrame(main_frame, text=\"3. 分类器选择\", padding=\"10\")\n",
    "        clf_frame.grid(row=1, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        # 快捷按钮\n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 5))\n",
    "        ttk.Button(btn_frame, text=\"全选\", command=self.select_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"全不选\", command=self.deselect_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"推荐选择\", command=self.select_recommended).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"快速分类器\", command=self.select_fast).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        \n",
    "        # 分类器复选框\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        row = 1\n",
    "        col = 0\n",
    "        for code, (_, name, _, _, _) in all_classifiers.items():\n",
    "            cb = ttk.Checkbutton(clf_frame, text=f\"{name} ({code})\", \n",
    "                               variable=self.classifier_vars[code])\n",
    "            cb.grid(row=row, column=col, sticky=tk.W, pady=2, padx=5)\n",
    "            \n",
    "            col += 1\n",
    "            if col >= 3:\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        # ===== 4. 控制按钮区 =====\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"4. 运行控制\", padding=\"10\")\n",
    "        control_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5, padx=(0, 5))\n",
    "        \n",
    "        self.start_btn = ttk.Button(control_frame, text=\"开始分类\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"停止\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"打开结果目录\", \n",
    "                  command=self.open_result_dir, width=15).grid(\n",
    "            row=0, column=2, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"查看对比报告\", \n",
    "                  command=self.view_report, width=15).grid(\n",
    "            row=0, column=3, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        # 进度条\n",
    "        ttk.Label(control_frame, text=\"进度:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100, length=400)\n",
    "        self.progress_bar.grid(row=1, column=1, columnspan=3, sticky=(tk.W, tk.E), \n",
    "                              padx=5, pady=2)\n",
    "        \n",
    "        control_frame.columnconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 5. 日志输出区 =====\n",
    "        log_frame = ttk.LabelFrame(main_frame, text=\"5. 运行日志\", padding=\"10\")\n",
    "        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, \n",
    "                                                  height=20, width=100)\n",
    "        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        log_frame.columnconfigure(0, weight=1)\n",
    "        log_frame.rowconfigure(0, weight=1)\n",
    "        \n",
    "        # 状态栏\n",
    "        self.status_var = tk.StringVar(value=\"就绪\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))\n",
    "    \n",
    "    def toggle_sampling(self):\n",
    "        \"\"\"切换采样功能\"\"\"\n",
    "        if self.enable_sampling.get():\n",
    "            self.max_samples_spinbox.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.max_samples_spinbox.config(state=tk.DISABLED)\n",
    "    \n",
    "    # ===== 文件浏览函数 =====\n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择影像文件\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择训练样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择验证样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"选择输出目录\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "    \n",
    "    # ===== 分类器选择函数 =====\n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        \"\"\"选择推荐的分类器（精度优先）\"\"\"\n",
    "        recommended = [\"rf\", \"xgb\", \"svm\", \"et\", \"gb\", \"lgb\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "    \n",
    "    def select_fast(self):\n",
    "        \"\"\"选择快速分类器（速度优先）\"\"\"\n",
    "        fast = [\"rf\", \"dt\", \"nb\", \"et\", \"xgb\", \"lgb\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in fast)\n",
    "    \n",
    "    # ===== 日志相关函数 =====\n",
    "    def log(self, message):\n",
    "        \"\"\"添加日志消息\"\"\"\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        \"\"\"更新日志显示\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        \n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    # ===== 主要功能函数 =====\n",
    "    def start_classification(self):\n",
    "        \"\"\"开始分类\"\"\"\n",
    "        # 检查输入\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择影像文件！\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择训练样本！\")\n",
    "            return\n",
    "        \n",
    "        # 检查是否至少选择了一个分类器\n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() \n",
    "                               if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"错误\", \"请至少选择一个分类器！\")\n",
    "            return\n",
    "        \n",
    "        # 禁用开始按钮，启用停止按钮\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        # 清空日志\n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"开始分类任务... (性能优化版)\")\n",
    "        self.log(\"=\"*80)\n",
    "        \n",
    "        if self.enable_sampling.get():\n",
    "            self.log(f\"✓ 启用数据采样：最大 {self.max_samples.get()} 个样本\")\n",
    "        if self.fast_mode.get():\n",
    "            self.log(f\"✓ 启用快速模式：减少模型复杂度\")\n",
    "        \n",
    "        # 在新线程中运行分类\n",
    "        thread = threading.Thread(target=self.run_classification, \n",
    "                                 args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        \"\"\"停止分类\"\"\"\n",
    "        self.is_running = False\n",
    "        self.log(\"\\n用户请求停止...\")\n",
    "        self.status_var.set(\"已停止\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"执行分类（在后台线程中运行）\"\"\"\n",
    "        try:\n",
    "            # 创建输出目录\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # 1. 读取影像\n",
    "            self.log(f\"\\n正在读取影像: {self.image_path.get()}\")\n",
    "            self.status_var.set(\"读取影像...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            self.log(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 2. 读取类别信息\n",
    "            self.log(\"\\n正在读取类别信息...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), \n",
    "                self.class_attr.get(), \n",
    "                self.name_attr.get()\n",
    "            )\n",
    "            self.log(f\"检测到类别: {list(class_names.values())}\")\n",
    "            \n",
    "            # 3. 提取训练样本\n",
    "            self.log(\"\\n正在处理训练样本...\")\n",
    "            self.status_var.set(\"处理训练样本...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            \n",
    "            # 使用采样功能\n",
    "            max_samples = self.max_samples.get() if self.enable_sampling.get() else None\n",
    "            \n",
    "            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(\n",
    "                img, train_mask, \n",
    "                ignore_background=self.ignore_background.get(),\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            self.log(f\"训练样本数: {len(y_train)}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"  已移除 {n_nan} 个包含NaN的样本\")\n",
    "            if n_inf > 0:\n",
    "                self.log(f\"  已移除 {n_inf} 个包含Inf的样本\")\n",
    "            if n_sampled > 0:\n",
    "                self.log(f\"  已采样减少 {n_sampled} 个样本（提高速度）\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 4. 提取验证样本（如果有）\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(\"\\n正在处理验证样本...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(img)\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"验证样本数: {len(yv_true)}\")\n",
    "            \n",
    "            # 5. 对每个选择的分类器进行训练和评估\n",
    "            all_classifiers = self.backend.get_all_classifiers(\n",
    "                self.n_estimators.get(), \n",
    "                fast_mode=self.fast_mode.get()\n",
    "            )\n",
    "            comparison_results = []\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding, needs_scaling = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] 正在测试: {clf_name} ({clf_code})\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                self.status_var.set(f\"训练 {clf_name}...\")\n",
    "                \n",
    "                # 创建分类器目录\n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # ===== 数据预处理 =====\n",
    "                    label_encoder = None\n",
    "                    scaler = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    # 标签编码\n",
    "                    if needs_encoding:\n",
    "                        self.log(\"  应用标签编码...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    # 特征缩放\n",
    "                    if needs_scaling:\n",
    "                        self.log(\"  应用特征缩放...\")\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_use = scaler.fit_transform(X_train_use)\n",
    "                    \n",
    "                    # 训练\n",
    "                    self.log(\"开始训练...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"训练完成，耗时: {train_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 训练集精度\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    # 反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"训练集精度: {train_metrics['overall_accuracy']:.4f}, \"\n",
    "                           f\"Kappa: {train_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # 预测整幅影像\n",
    "                    self.log(\"开始预测整幅影像...\")\n",
    "                    self.status_var.set(f\"预测 {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"预测完成，耗时: {pred_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 验证集精度\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "                    if val_exists:\n",
    "                        self.log(\"评估验证集...\")\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"验证集精度: {val_metrics['overall_accuracy']:.4f}, \"\n",
    "                               f\"Kappa: {val_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    # 记录结果\n",
    "                    result = {\n",
    "                        '分类器代码': clf_code,\n",
    "                        '分类器名称': clf_name,\n",
    "                        '训练集精度': train_metrics['overall_accuracy'],\n",
    "                        '训练集Kappa': train_metrics['kappa'],\n",
    "                        '训练集F1': train_metrics['f1_macro'],\n",
    "                        '验证集精度': val_metrics['overall_accuracy'],\n",
    "                        '验证集Kappa': val_metrics['kappa'],\n",
    "                        '验证集F1': val_metrics['f1_macro'],\n",
    "                        '训练时间(秒)': train_time,\n",
    "                        '预测时间(秒)': pred_time,\n",
    "                        '总时间(秒)': train_time + pred_time\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    \n",
    "                    self.log(f\"✓ {clf_name} 完成\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"✗ {clf_name} 失败: {str(e)}\")\n",
    "                    import traceback\n",
    "                    self.log(traceback.format_exc())\n",
    "                    continue\n",
    "                \n",
    "                # 更新总进度\n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # 6. 生成对比报告\n",
    "            if comparison_results and self.is_running:\n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"生成对比报告...\")\n",
    "                self.status_var.set(\"生成报告...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # 生成详细报告\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"分类器性能对比摘要\\n\")\n",
    "                    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(f\"成功完成: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\\n\")\n",
    "                    f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "                    if val_exists:\n",
    "                        f.write(f\"验证样本数: {len(yv_true)}\\n\")\n",
    "                    f.write(f\"性能优化: 采样={self.enable_sampling.get()}, 快速模式={self.fast_mode.get()}\\n\\n\")\n",
    "                    \n",
    "                    # 精度排名\n",
    "                    sorted_df = comparison_df.sort_values('验证集精度', ascending=False)\n",
    "                    f.write(\"验证集精度排名:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"精度: {row['验证集精度']:.4f}, \"\n",
    "                               f\"Kappa: {row['验证集Kappa']:.4f}, \"\n",
    "                               f\"F1: {row['验证集F1']:.4f}\\n\")\n",
    "                    \n",
    "                    # 速度排名\n",
    "                    f.write(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "                    f.write(\"总时间排名（训练+预测）:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    sorted_time = comparison_df.sort_values('总时间(秒)')\n",
    "                    for idx, (_, row) in enumerate(sorted_time.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"{row['总时间(秒)']:.2f} 秒 \"\n",
    "                               f\"(训练: {row['训练时间(秒)']:.2f}s, 预测: {row['预测时间(秒)']:.2f}s)\\n\")\n",
    "                    \n",
    "                    # 推荐\n",
    "                    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "                    f.write(\"推荐:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    \n",
    "                    best_acc = sorted_df.iloc[0]\n",
    "                    f.write(f\"最高精度: {best_acc['分类器名称']} ({best_acc['验证集精度']:.4f})\\n\")\n",
    "                    \n",
    "                    best_speed = sorted_time.iloc[0]\n",
    "                    f.write(f\"最快速度: {best_speed['分类器名称']} ({best_speed['总时间(秒)']:.2f}秒)\\n\")\n",
    "                    \n",
    "                    # 综合评分\n",
    "                    comparison_df['综合得分'] = (\n",
    "                        comparison_df['验证集精度'] * 0.7 + \n",
    "                        (1 - comparison_df['总时间(秒)'] / comparison_df['总时间(秒)'].max()) * 0.3\n",
    "                    )\n",
    "                    best_overall = comparison_df.loc[comparison_df['综合得分'].idxmax()]\n",
    "                    f.write(f\"综合最佳: {best_overall['分类器名称']} \"\n",
    "                           f\"(精度: {best_overall['验证集精度']:.4f}, \"\n",
    "                           f\"时间: {best_overall['总时间(秒)']:.2f}秒)\\n\")\n",
    "                \n",
    "                self.log(\"\\n✓ 所有任务完成！\")\n",
    "                self.log(f\"结果保存至: {out_dir.absolute()}\")\n",
    "                self.log(f\"成功: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\")\n",
    "                self.status_var.set(\"完成\")\n",
    "                \n",
    "                # 显示最佳结果\n",
    "                best_clf = comparison_df.loc[comparison_df['验证集精度'].idxmax()]\n",
    "                self.log(f\"\\n【最佳精度】{best_clf['分类器名称']}: {best_clf['验证集精度']:.4f}\")\n",
    "                \n",
    "                messagebox.showinfo(\"完成\", \n",
    "                    f\"分类任务完成！\\n\"\n",
    "                    f\"成功: {len(comparison_results)}/{len(selected_classifiers)}\\n\"\n",
    "                    f\"最佳: {best_clf['分类器名称']} ({best_clf['验证集精度']:.4f})\\n\"\n",
    "                    f\"结果: {out_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\n错误: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"错误\", f\"发生错误:\\n{str(e)}\")\n",
    "            self.status_var.set(\"错误\")\n",
    "        \n",
    "        finally:\n",
    "            # 恢复按钮状态\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"打开结果目录\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":  # macOS\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:  # Linux\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"结果目录不存在！\")\n",
    "    \n",
    "    def view_report(self):\n",
    "        \"\"\"查看对比报告\"\"\"\n",
    "        report_file = Path(self.output_dir.get()) / \"comparison_summary.txt\"\n",
    "        if report_file.exists():\n",
    "            # 创建新窗口显示报告\n",
    "            report_window = tk.Toplevel(self.root)\n",
    "            report_window.title(\"分类器对比报告\")\n",
    "            report_window.geometry(\"800x600\")\n",
    "            \n",
    "            text_widget = scrolledtext.ScrolledText(report_window, wrap=tk.WORD)\n",
    "            text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "            \n",
    "            with open(report_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                text_widget.insert(1.0, content)\n",
    "            \n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"报告文件不存在！请先运行分类。\")\n",
    "\n",
    "# ==================== 主程序入口 ====================\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = ClassificationGUI(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba030f5",
   "metadata": {},
   "source": [
    "### SVM比较慢，优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84173253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "遥感影像监督分类系统 - GUI版本 (性能优化版)\n",
    "支持多分类器对比和可视化\n",
    "优化：数据采样、特征缩放、参数调优、并行处理\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ==================== 后端处理类 ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"分类处理后端（性能优化版）\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.BACKGROUND_VALUE = 0\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # 预定义颜色\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"水体\": \"lightblue\", \"河流\": \"blue\", \"湖泊\": \"deepskyblue\",\n",
    "            \"植被\": \"forestgreen\", \"森林\": \"darkgreen\", \"草地\": \"limegreen\",\n",
    "            \"农田\": \"yellowgreen\", \"耕地\": \"olivedrab\",\n",
    "            \"建筑\": \"gray\", \"城市\": \"dimgray\", \"居民地\": \"slategray\",\n",
    "            \"裸地\": \"tan\", \"沙地\": \"wheat\", \"其他\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100, fast_mode=False):\n",
    "        \"\"\"\n",
    "        获取所有分类器（优化参数）\n",
    "        fast_mode: 快速模式，使用更少的估计器和更简单的参数\n",
    "        \"\"\"\n",
    "        # 根据模式调整参数\n",
    "        if fast_mode:\n",
    "            n_est = min(50, n_estimators)\n",
    "            max_depth = 10\n",
    "            max_iter = 200\n",
    "        else:\n",
    "            n_est = n_estimators\n",
    "            max_depth = 20\n",
    "            max_iter = 500\n",
    "        \n",
    "        classifiers = {\n",
    "            \"rf\": (\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=n_est, \n",
    "                    n_jobs=-1, \n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    max_features='sqrt'  # 减少特征数量\n",
    "                ),\n",
    "                \"随机森林\", \"Random Forest\", False, False\n",
    "            ),\n",
    "            \"svm\": (\n",
    "                SVC(\n",
    "                    kernel=\"rbf\", \n",
    "                    C=1.0,\n",
    "                    gamma='scale',\n",
    "                    cache_size=500,  # 增加缓存\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                ),\n",
    "                \"支持向量机\", \"SVM\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"dt\": (\n",
    "                DecisionTreeClassifier(\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2\n",
    "                ),\n",
    "                \"决策树\", \"Decision Tree\", False, False\n",
    "            ),\n",
    "            \"knn\": (\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=5,\n",
    "                    n_jobs=-1,\n",
    "                    algorithm='ball_tree',  # 更快的算法\n",
    "                    leaf_size=30\n",
    "                ),\n",
    "                \"K近邻\", \"KNN\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"nb\": (\n",
    "                GaussianNB(),\n",
    "                \"朴素贝叶斯\", \"Naive Bayes\", False, False\n",
    "            ),\n",
    "            \"gb\": (\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5,  # 减小深度提高速度\n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    subsample=0.8  # 使用子采样\n",
    "                ),\n",
    "                \"梯度提升\", \"Gradient Boosting\", False, False\n",
    "            ),\n",
    "            \"ada\": (\n",
    "                AdaBoostClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=1.0,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    algorithm='SAMME.R'  # 更快的算法\n",
    "                ),\n",
    "                \"AdaBoost\", \"AdaBoost\", False, False\n",
    "            ),\n",
    "            \"et\": (\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"极端随机树\", \"Extra Trees\", False, False\n",
    "            ),\n",
    "            \"lr\": (\n",
    "                LogisticRegression(\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    solver='lbfgs',  # 快速求解器\n",
    "                    multi_class='multinomial'\n",
    "                ),\n",
    "                \"逻辑回归\", \"Logistic Regression\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "            \"mlp\": (\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=(100, 50),\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=False,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction=0.1,\n",
    "                    n_iter_no_change=10,  # 早停\n",
    "                    learning_rate='adaptive'\n",
    "                ),\n",
    "                \"神经网络\", \"MLP\", False, True  # 需要特征缩放\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        # XGBoost\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            classifiers[\"xgb\"] = (\n",
    "                XGBClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,  # 减小深度\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbosity=0,\n",
    "                    tree_method='hist',  # 使用直方图算法，更快\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"XGBoost\", \"XGBoost\", True, False  # 需要标签编码\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        # LightGBM\n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "            classifiers[\"lgb\"] = (\n",
    "                LGBMClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=max_depth,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=-1,\n",
    "                    num_leaves=31,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"LightGBM\", \"LightGBM\", False, False\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image):\n",
    "        \"\"\"获取背景掩膜\"\"\"\n",
    "        data = image.values\n",
    "        background_mask = np.all(data == 0, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"从shp文件获取类别信息\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in class_name:\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"矢量栅格化\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=ref_img.shape[1:],\n",
    "            transform=ref_img.rio.transform(),\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint16\"\n",
    "        )\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True, max_samples=None):\n",
    "        \"\"\"\n",
    "        提取样本并清理NaN值\n",
    "        max_samples: 最大样本数，如果超过则进行分层采样\n",
    "        \"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # 清理NaN和Inf值\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        bad_mask = nan_mask | inf_mask\n",
    "        \n",
    "        n_nan = np.sum(nan_mask)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        X = X[~bad_mask]\n",
    "        y = y[~bad_mask]\n",
    "        \n",
    "        # ===== 性能优化：分层采样 =====\n",
    "        n_sampled = 0\n",
    "        if max_samples is not None and len(y) > max_samples:\n",
    "            n_original = len(y)\n",
    "            \n",
    "            # 使用分层采样保持类别比例\n",
    "            unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "            \n",
    "            if len(unique_classes) > 1:\n",
    "                # 使用sklearn的分层采样\n",
    "                splitter = StratifiedShuffleSplit(\n",
    "                    n_splits=1, \n",
    "                    train_size=max_samples, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                )\n",
    "                \n",
    "                sample_idx, _ = next(splitter.split(X, y))\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "            else:\n",
    "                # 只有一个类别，随机采样\n",
    "                np.random.seed(self.RANDOM_STATE)\n",
    "                sample_idx = np.random.choice(len(y), max_samples, replace=False)\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "        \n",
    "        return X, y, n_nan, n_inf, n_sampled\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"计算评价指标\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, progress_callback=None,\n",
    "                        label_encoder=None, scaler=None):\n",
    "        \"\"\"\n",
    "        分块预测（优化版）\n",
    "        添加了特征缩放支持\n",
    "        \"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], \n",
    "                                                   nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    # 如果使用了特征缩放\n",
    "                    if scaler is not None:\n",
    "                        data_to_predict = scaler.transform(data_to_predict)\n",
    "                    \n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    # 如果使用了标签编码，需要反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    data_flat = scaler.transform(data_flat)\n",
    "                \n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # 保存结果\n",
    "        prediction_da = xr.DataArray(\n",
    "            prediction,\n",
    "            dims=['y', 'x'],\n",
    "            coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "        )\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(self.BACKGROUND_VALUE, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUI主类 ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"遥感影像分类GUI主界面（性能优化版）\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"遥感影像监督分类系统 v2.2 (性能优化版)\")\n",
    "        self.root.geometry(\"1400x900\")\n",
    "        \n",
    "        # 后端处理对象\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # 数据变量\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        self.class_attr = tk.StringVar(value=\"class\")\n",
    "        self.name_attr = tk.StringVar(value=\"name\")\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # ===== 性能优化参数 =====\n",
    "        self.enable_sampling = tk.BooleanVar(value=True)  # 启用采样\n",
    "        self.max_samples = tk.IntVar(value=50000)  # 最大样本数\n",
    "        self.fast_mode = tk.BooleanVar(value=False)  # 快速模式\n",
    "        \n",
    "        # 分类器选择\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code, (_, name, _, _, _) in all_classifiers.items():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # 运行状态\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # 构建界面\n",
    "        self.build_ui()\n",
    "        \n",
    "        # 启动日志更新\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"构建用户界面\"\"\"\n",
    "        # 创建主框架\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.rowconfigure(0, weight=1)\n",
    "        main_frame.columnconfigure(1, weight=1)\n",
    "        main_frame.rowconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 1. 文件选择区 =====\n",
    "        file_frame = ttk.LabelFrame(main_frame, text=\"1. 数据输入\", padding=\"10\")\n",
    "        file_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)\n",
    "        \n",
    "        # 影像文件\n",
    "        ttk.Label(file_frame, text=\"影像文件:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=60).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_image).grid(\n",
    "            row=0, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 训练样本\n",
    "        ttk.Label(file_frame, text=\"训练样本:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=60).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_train_shp).grid(\n",
    "            row=1, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 验证样本\n",
    "        ttk.Label(file_frame, text=\"验证样本:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=60).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_val_shp).grid(\n",
    "            row=2, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        # 输出目录\n",
    "        ttk.Label(file_frame, text=\"输出目录:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=60).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"浏览\", command=self.browse_output).grid(\n",
    "            row=3, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # ===== 2. 参数设置区 =====\n",
    "        param_frame = ttk.LabelFrame(main_frame, text=\"2. 参数配置\", padding=\"10\")\n",
    "        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N), pady=5, padx=(0, 5))\n",
    "        \n",
    "        # 属性字段\n",
    "        ttk.Label(param_frame, text=\"类别编号字段:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.class_attr, width=15).grid(\n",
    "            row=0, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"类别名称字段:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.name_attr, width=15).grid(\n",
    "            row=1, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # 其他参数\n",
    "        ttk.Label(param_frame, text=\"树模型数量:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=13).grid(row=2, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"分块大小:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=13).grid(\n",
    "            row=3, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # ===== 性能优化选项 =====\n",
    "        ttk.Separator(param_frame, orient='horizontal').grid(\n",
    "            row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"性能优化:\", font=('', 9, 'bold')).grid(\n",
    "            row=5, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        sample_frame = ttk.Frame(param_frame)\n",
    "        sample_frame.grid(row=6, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        ttk.Checkbutton(sample_frame, text=\"启用采样\", \n",
    "                       variable=self.enable_sampling,\n",
    "                       command=self.toggle_sampling).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Label(sample_frame, text=\"  最大样本数:\").pack(side=tk.LEFT, padx=(10, 0))\n",
    "        self.max_samples_spinbox = ttk.Spinbox(\n",
    "            sample_frame, from_=10000, to=200000, increment=10000,\n",
    "            textvariable=self.max_samples, width=10\n",
    "        )\n",
    "        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"快速模式（减少模型复杂度）\", \n",
    "                       variable=self.fast_mode).grid(\n",
    "            row=7, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"忽略背景值（所有波段为0）\", \n",
    "                       variable=self.ignore_background).grid(\n",
    "            row=8, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        # ===== 3. 分类器选择区 =====\n",
    "        clf_frame = ttk.LabelFrame(main_frame, text=\"3. 分类器选择\", padding=\"10\")\n",
    "        clf_frame.grid(row=1, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        # 快捷按钮\n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 5))\n",
    "        ttk.Button(btn_frame, text=\"全选\", command=self.select_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"全不选\", command=self.deselect_all_classifiers).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"推荐选择\", command=self.select_recommended).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        ttk.Button(btn_frame, text=\"快速分类器\", command=self.select_fast).pack(\n",
    "            side=tk.LEFT, padx=2\n",
    "        )\n",
    "        \n",
    "        # 分类器复选框\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        row = 1\n",
    "        col = 0\n",
    "        for code, (_, name, _, _, _) in all_classifiers.items():\n",
    "            cb = ttk.Checkbutton(clf_frame, text=f\"{name} ({code})\", \n",
    "                               variable=self.classifier_vars[code])\n",
    "            cb.grid(row=row, column=col, sticky=tk.W, pady=2, padx=5)\n",
    "            \n",
    "            col += 1\n",
    "            if col >= 3:\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        # ===== 4. 控制按钮区 =====\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"4. 运行控制\", padding=\"10\")\n",
    "        control_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5, padx=(0, 5))\n",
    "        \n",
    "        self.start_btn = ttk.Button(control_frame, text=\"开始分类\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"停止\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"打开结果目录\", \n",
    "                  command=self.open_result_dir, width=15).grid(\n",
    "            row=0, column=2, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"查看对比报告\", \n",
    "                  command=self.view_report, width=15).grid(\n",
    "            row=0, column=3, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        # 进度条\n",
    "        ttk.Label(control_frame, text=\"进度:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100, length=400)\n",
    "        self.progress_bar.grid(row=1, column=1, columnspan=3, sticky=(tk.W, tk.E), \n",
    "                              padx=5, pady=2)\n",
    "        \n",
    "        control_frame.columnconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 5. 日志输出区 =====\n",
    "        log_frame = ttk.LabelFrame(main_frame, text=\"5. 运行日志\", padding=\"10\")\n",
    "        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, \n",
    "                                                  height=20, width=100)\n",
    "        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        log_frame.columnconfigure(0, weight=1)\n",
    "        log_frame.rowconfigure(0, weight=1)\n",
    "        \n",
    "        # 状态栏\n",
    "        self.status_var = tk.StringVar(value=\"就绪\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))\n",
    "    \n",
    "    def toggle_sampling(self):\n",
    "        \"\"\"切换采样功能\"\"\"\n",
    "        if self.enable_sampling.get():\n",
    "            self.max_samples_spinbox.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.max_samples_spinbox.config(state=tk.DISABLED)\n",
    "    \n",
    "    # ===== 文件浏览函数 =====\n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择影像文件\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择训练样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"选择验证样本\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"所有文件\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"选择输出目录\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "    \n",
    "    # ===== 分类器选择函数 =====\n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        \"\"\"选择推荐的分类器（精度优先）\"\"\"\n",
    "        recommended = [\"rf\", \"xgb\", \"svm\", \"et\", \"gb\", \"lgb\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "    \n",
    "    def select_fast(self):\n",
    "        \"\"\"选择快速分类器（速度优先）\"\"\"\n",
    "        fast = [\"rf\", \"dt\", \"nb\", \"et\", \"xgb\", \"lgb\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in fast)\n",
    "    \n",
    "    # ===== 日志相关函数 =====\n",
    "    def log(self, message):\n",
    "        \"\"\"添加日志消息\"\"\"\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        \"\"\"更新日志显示\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        \n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    # ===== 主要功能函数 =====\n",
    "    def start_classification(self):\n",
    "        \"\"\"开始分类\"\"\"\n",
    "        # 检查输入\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择影像文件！\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"错误\", \"请选择训练样本！\")\n",
    "            return\n",
    "        \n",
    "        # 检查是否至少选择了一个分类器\n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() \n",
    "                               if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"错误\", \"请至少选择一个分类器！\")\n",
    "            return\n",
    "        \n",
    "        # 禁用开始按钮，启用停止按钮\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        # 清空日志\n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"开始分类任务... (性能优化版)\")\n",
    "        self.log(\"=\"*80)\n",
    "        \n",
    "        if self.enable_sampling.get():\n",
    "            self.log(f\"✓ 启用数据采样：最大 {self.max_samples.get()} 个样本\")\n",
    "        if self.fast_mode.get():\n",
    "            self.log(f\"✓ 启用快速模式：减少模型复杂度\")\n",
    "        \n",
    "        # 在新线程中运行分类\n",
    "        thread = threading.Thread(target=self.run_classification, \n",
    "                                 args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        \"\"\"停止分类\"\"\"\n",
    "        self.is_running = False\n",
    "        self.log(\"\\n用户请求停止...\")\n",
    "        self.status_var.set(\"已停止\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"执行分类（在后台线程中运行）\"\"\"\n",
    "        try:\n",
    "            # 创建输出目录\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # 1. 读取影像\n",
    "            self.log(f\"\\n正在读取影像: {self.image_path.get()}\")\n",
    "            self.status_var.set(\"读取影像...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            self.log(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 2. 读取类别信息\n",
    "            self.log(\"\\n正在读取类别信息...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), \n",
    "                self.class_attr.get(), \n",
    "                self.name_attr.get()\n",
    "            )\n",
    "            self.log(f\"检测到类别: {list(class_names.values())}\")\n",
    "            \n",
    "            # 3. 提取训练样本\n",
    "            self.log(\"\\n正在处理训练样本...\")\n",
    "            self.status_var.set(\"处理训练样本...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            \n",
    "            # 使用采样功能\n",
    "            max_samples = self.max_samples.get() if self.enable_sampling.get() else None\n",
    "            \n",
    "            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(\n",
    "                img, train_mask, \n",
    "                ignore_background=self.ignore_background.get(),\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            self.log(f\"训练样本数: {len(y_train)}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"  已移除 {n_nan} 个包含NaN的样本\")\n",
    "            if n_inf > 0:\n",
    "                self.log(f\"  已移除 {n_inf} 个包含Inf的样本\")\n",
    "            if n_sampled > 0:\n",
    "                self.log(f\"  已采样减少 {n_sampled} 个样本（提高速度）\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 4. 提取验证样本（如果有）\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(\"\\n正在处理验证样本...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(img)\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"验证样本数: {len(yv_true)}\")\n",
    "            \n",
    "            # 5. 对每个选择的分类器进行训练和评估\n",
    "            all_classifiers = self.backend.get_all_classifiers(\n",
    "                self.n_estimators.get(), \n",
    "                fast_mode=self.fast_mode.get()\n",
    "            )\n",
    "            comparison_results = []\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding, needs_scaling = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] 正在测试: {clf_name} ({clf_code})\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                self.status_var.set(f\"训练 {clf_name}...\")\n",
    "                \n",
    "                # 创建分类器目录\n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # ===== 数据预处理 =====\n",
    "                    label_encoder = None\n",
    "                    scaler = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    # 标签编码\n",
    "                    if needs_encoding:\n",
    "                        self.log(\"  应用标签编码...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    # 特征缩放\n",
    "                    if needs_scaling:\n",
    "                        self.log(\"  应用特征缩放...\")\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_use = scaler.fit_transform(X_train_use)\n",
    "                    \n",
    "                    # 训练\n",
    "                    self.log(\"开始训练...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"训练完成，耗时: {train_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 训练集精度\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    # 反向转换\n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"训练集精度: {train_metrics['overall_accuracy']:.4f}, \"\n",
    "                           f\"Kappa: {train_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # 预测整幅影像\n",
    "                    self.log(\"开始预测整幅影像...\")\n",
    "                    self.status_var.set(f\"预测 {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"预测完成，耗时: {pred_time:.2f} 秒\")\n",
    "                    \n",
    "                    # 验证集精度\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "                    if val_exists:\n",
    "                        self.log(\"评估验证集...\")\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"验证集精度: {val_metrics['overall_accuracy']:.4f}, \"\n",
    "                               f\"Kappa: {val_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    # 记录结果\n",
    "                    result = {\n",
    "                        '分类器代码': clf_code,\n",
    "                        '分类器名称': clf_name,\n",
    "                        '训练集精度': train_metrics['overall_accuracy'],\n",
    "                        '训练集Kappa': train_metrics['kappa'],\n",
    "                        '训练集F1': train_metrics['f1_macro'],\n",
    "                        '验证集精度': val_metrics['overall_accuracy'],\n",
    "                        '验证集Kappa': val_metrics['kappa'],\n",
    "                        '验证集F1': val_metrics['f1_macro'],\n",
    "                        '训练时间(秒)': train_time,\n",
    "                        '预测时间(秒)': pred_time,\n",
    "                        '总时间(秒)': train_time + pred_time\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    \n",
    "                    self.log(f\"✓ {clf_name} 完成\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"✗ {clf_name} 失败: {str(e)}\")\n",
    "                    import traceback\n",
    "                    self.log(traceback.format_exc())\n",
    "                    continue\n",
    "                \n",
    "                # 更新总进度\n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # 6. 生成对比报告\n",
    "            if comparison_results and self.is_running:\n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"生成对比报告...\")\n",
    "                self.status_var.set(\"生成报告...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # 生成详细报告\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"分类器性能对比摘要\\n\")\n",
    "                    f.write(\"=\"*60 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(f\"成功完成: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\\n\")\n",
    "                    f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "                    if val_exists:\n",
    "                        f.write(f\"验证样本数: {len(yv_true)}\\n\")\n",
    "                    f.write(f\"性能优化: 采样={self.enable_sampling.get()}, 快速模式={self.fast_mode.get()}\\n\\n\")\n",
    "                    \n",
    "                    # 精度排名\n",
    "                    sorted_df = comparison_df.sort_values('验证集精度', ascending=False)\n",
    "                    f.write(\"验证集精度排名:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"精度: {row['验证集精度']:.4f}, \"\n",
    "                               f\"Kappa: {row['验证集Kappa']:.4f}, \"\n",
    "                               f\"F1: {row['验证集F1']:.4f}\\n\")\n",
    "                    \n",
    "                    # 速度排名\n",
    "                    f.write(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "                    f.write(\"总时间排名（训练+预测）:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    sorted_time = comparison_df.sort_values('总时间(秒)')\n",
    "                    for idx, (_, row) in enumerate(sorted_time.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['分类器名称']:12s} - \"\n",
    "                               f\"{row['总时间(秒)']:.2f} 秒 \"\n",
    "                               f\"(训练: {row['训练时间(秒)']:.2f}s, 预测: {row['预测时间(秒)']:.2f}s)\\n\")\n",
    "                    \n",
    "                    # 推荐\n",
    "                    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "                    f.write(\"推荐:\\n\")\n",
    "                    f.write(\"-\"*60 + \"\\n\")\n",
    "                    \n",
    "                    best_acc = sorted_df.iloc[0]\n",
    "                    f.write(f\"最高精度: {best_acc['分类器名称']} ({best_acc['验证集精度']:.4f})\\n\")\n",
    "                    \n",
    "                    best_speed = sorted_time.iloc[0]\n",
    "                    f.write(f\"最快速度: {best_speed['分类器名称']} ({best_speed['总时间(秒)']:.2f}秒)\\n\")\n",
    "                    \n",
    "                    # 综合评分\n",
    "                    comparison_df['综合得分'] = (\n",
    "                        comparison_df['验证集精度'] * 0.7 + \n",
    "                        (1 - comparison_df['总时间(秒)'] / comparison_df['总时间(秒)'].max()) * 0.3\n",
    "                    )\n",
    "                    best_overall = comparison_df.loc[comparison_df['综合得分'].idxmax()]\n",
    "                    f.write(f\"综合最佳: {best_overall['分类器名称']} \"\n",
    "                           f\"(精度: {best_overall['验证集精度']:.4f}, \"\n",
    "                           f\"时间: {best_overall['总时间(秒)']:.2f}秒)\\n\")\n",
    "                \n",
    "                self.log(\"\\n✓ 所有任务完成！\")\n",
    "                self.log(f\"结果保存至: {out_dir.absolute()}\")\n",
    "                self.log(f\"成功: {len(comparison_results)}/{len(selected_classifiers)} 个分类器\")\n",
    "                self.status_var.set(\"完成\")\n",
    "                \n",
    "                # 显示最佳结果\n",
    "                best_clf = comparison_df.loc[comparison_df['验证集精度'].idxmax()]\n",
    "                self.log(f\"\\n【最佳精度】{best_clf['分类器名称']}: {best_clf['验证集精度']:.4f}\")\n",
    "                \n",
    "                messagebox.showinfo(\"完成\", \n",
    "                    f\"分类任务完成！\\n\"\n",
    "                    f\"成功: {len(comparison_results)}/{len(selected_classifiers)}\\n\"\n",
    "                    f\"最佳: {best_clf['分类器名称']} ({best_clf['验证集精度']:.4f})\\n\"\n",
    "                    f\"结果: {out_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\n错误: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"错误\", f\"发生错误:\\n{str(e)}\")\n",
    "            self.status_var.set(\"错误\")\n",
    "        \n",
    "        finally:\n",
    "            # 恢复按钮状态\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"打开结果目录\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":  # macOS\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:  # Linux\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"结果目录不存在！\")\n",
    "    \n",
    "    def view_report(self):\n",
    "        \"\"\"查看对比报告\"\"\"\n",
    "        report_file = Path(self.output_dir.get()) / \"comparison_summary.txt\"\n",
    "        if report_file.exists():\n",
    "            # 创建新窗口显示报告\n",
    "            report_window = tk.Toplevel(self.root)\n",
    "            report_window.title(\"分类器对比报告\")\n",
    "            report_window.geometry(\"800x600\")\n",
    "            \n",
    "            text_widget = scrolledtext.ScrolledText(report_window, wrap=tk.WORD)\n",
    "            text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "            \n",
    "            with open(report_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                text_widget.insert(1.0, content)\n",
    "            \n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            messagebox.showwarning(\"警告\", \"报告文件不存在！请先运行分类。\")\n",
    "\n",
    "# ==================== 主程序入口 ====================\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = ClassificationGUI(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb730b",
   "metadata": {},
   "source": [
    "## deepseek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ebef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 08:42:55,803 [INFO] 开始监督分类任务...\n",
      "2025-10-16 08:42:55,804 [INFO] 正在读取类别信息...\n",
      "2025-10-16 08:42:55,816 [INFO] 检测到类别: ['类1', '类2', '类3', '类4', '类5', '类6', '类7', '类8', '类9', '类10', '类11']\n",
      "2025-10-16 08:42:55,825 [INFO] 影像尺寸: (14, 1024, 2098), 波段数: 14\n",
      "2025-10-16 08:42:55,828 [INFO] 影像坐标系: EPSG:32633\n",
      "2025-10-16 08:42:55,829 [INFO] 影像变换参数: | 0.20, 0.00, 351916.64|\n",
      "| 0.00,-0.20, 5997247.36|\n",
      "| 0.00, 0.00, 1.00|\n",
      "2025-10-16 08:42:55,830 [INFO] 单个像元面积: 0.04 平方米 (0.000000 平方千米)\n",
      "2025-10-16 08:42:55,831 [INFO] 正在处理训练样本...\n",
      "2025-10-16 08:42:56,080 [INFO] 训练样本数: 15041\n",
      "2025-10-16 08:42:56,082 [INFO] 使用分类器: RandomForestClassifier\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.2s finished\n",
      "2025-10-16 08:42:58,063 [INFO] 模型训练完成。\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "2025-10-16 08:42:58,856 [INFO] 训练集总体精度: 1.0000, Kappa: 1.0000\n",
      "2025-10-16 08:43:01,377 [INFO] 开始分块预测...\n",
      "Block predicting:   0%|          | 0/2 [00:00<?, ?it/s][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "Block predicting:  50%|█████     | 1/2 [00:08<00:08,  8.88s/it][Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=48)]: Done 300 out of 300 | elapsed:    0.2s finished\n",
      "Block predicting: 100%|██████████| 2/2 [00:17<00:00,  8.96s/it]\n",
      "2025-10-16 08:43:19,355 [INFO] 分类结果保存至: results_rioxarray\\classified_result.tif\n",
      "2025-10-16 08:43:19,356 [INFO] 生成原始分类结果可视化...\n",
      "2025-10-16 08:43:21,972 [INFO] 计算原始分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3160367787.py:578: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3160367787.py:579: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 08:43:22,988 [INFO] 原始分类总面积: 0.0859 平方千米\n",
      "2025-10-16 08:43:22,990 [INFO] 开始后处理...\n",
      "2025-10-16 08:43:22,991 [INFO] 后处理参数: 最小图斑大小=10, 形态学操作=opening, 核大小=3\n",
      "2025-10-16 08:43:22,991 [INFO] 开始后处理分类结果...\n",
      "2025-10-16 08:43:24,108 [INFO] 后处理完成: 原始非零像元数 2148352, 处理后非零像元数 1624370\n",
      "2025-10-16 08:43:24,110 [INFO] 后处理去除了 523982 个像元 (24.39%)\n",
      "2025-10-16 08:43:24,161 [INFO] 后处理结果保存至: results_rioxarray\\classified_result_postprocessed.tif\n",
      "2025-10-16 08:43:24,162 [INFO] 生成后处理分类结果可视化...\n",
      "2025-10-16 08:43:26,835 [INFO] 计算后处理分类结果面积统计...\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3160367787.py:578: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_217852\\3160367787.py:579: UserWarning: Glyph 178 (\\N{SUPERSCRIPT TWO}) missing from font(s) SimHei.\n",
      "  plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
      "2025-10-16 08:43:27,993 [INFO] 后处理分类总面积: 0.0650 平方千米\n",
      "2025-10-16 08:43:28,006 [INFO] 正在进行验证...\n",
      "2025-10-16 08:43:28,624 [INFO] 验证集总体精度: 0.8829, Kappa: 0.8388\n",
      "2025-10-16 08:43:30,332 [INFO] 全部任务完成，用时 34.5 秒。\n",
      "2025-10-16 08:43:30,333 [INFO] 所有结果已保存至: d:\\code313\\Geo_programe\\rasterio\\RF\\results_rioxarray\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "通用遥感影像监督分类系统 (rioxarray版本)\n",
    "-------------------------------------------------\n",
    "功能：\n",
    "1. 自动读取多波段遥感影像；\n",
    "2. 从矢量样本中提取训练/验证数据；\n",
    "3. 支持随机森林 / SVM / XGBoost 分类；\n",
    "4. 采用分块预测模式；\n",
    "5. 输出分类结果 GeoTIFF；\n",
    "6. 自动生成分类报告与混淆矩阵；\n",
    "7. 显示分类影像和精度评价结果；\n",
    "8. 分类面积统计（平方千米）；\n",
    "9. 后处理功能（去除小图斑、形态学操作）。\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]  # 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 支持负号显示\n",
    "\n",
    "# ------------------ 参数配置 ------------------\n",
    "IMAGE_PATH = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\2017_09_05_stack.tif\"\n",
    "TRAIN_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\cal.shp\"\n",
    "VAL_SHP = r\"D:\\code313\\Geo_programe\\rasterio\\RF\\data\\val.shp\"\n",
    "CLASS_ATTRIBUTE = \"class\"  # 类别编号字段\n",
    "NAME_ATTRIBUTE = \"name\"    # 类别名称字段\n",
    "OUT_DIR = Path(\"./results_rioxarray\")\n",
    "\n",
    "CLASSIFIER = \"rf\"  # 可选: \"rf\", \"svm\", \"xgb\"\n",
    "N_ESTIMATORS = 300\n",
    "BLOCK_SIZE = 512\n",
    "USE_GPU = False\n",
    "\n",
    "# 后处理参数\n",
    "POSTPROCESSING = True  # 是否进行后处理\n",
    "MIN_PATCH_SIZE = 10    # 最小图斑大小（像元数），小于此值的图斑将被去除\n",
    "MORPHOLOGY_OPERATION = \"opening\"  # 形态学操作: \"opening\"（开运算）, \"closing\"（闭运算）, \"both\"（两者都）, \"none\"（无）\n",
    "MORPHOLOGY_SIZE = 3     # 形态学操作核大小\n",
    "\n",
    "# 预定义颜色映射（可根据需要扩展）\n",
    "LANDUSE_COLORS = {\n",
    "    # 水体相关\n",
    "    \"水体\": \"lightblue\",\n",
    "    \"河流\": \"blue\",\n",
    "    \"湖泊\": \"deepskyblue\",\n",
    "    \"水库\": \"dodgerblue\",\n",
    "    \"海洋\": \"navy\",\n",
    "    \n",
    "    # 植被相关\n",
    "    \"植被\": \"forestgreen\",\n",
    "    \"森林\": \"darkgreen\",\n",
    "    \"草地\": \"limegreen\",\n",
    "    \"农田\": \"yellowgreen\",\n",
    "    \"耕地\": \"olivedrab\",\n",
    "    \n",
    "    # 建筑相关\n",
    "    \"建筑\": \"gray\",\n",
    "    \"城市\": \"dimgray\",\n",
    "    \"居民地\": \"slategray\",\n",
    "    \"工业区\": \"darkgray\",\n",
    "    \n",
    "    # 其他地物\n",
    "    \"裸地\": \"tan\",\n",
    "    \"沙地\": \"wheat\",\n",
    "    \"岩石\": \"sienna\",\n",
    "    \"雪\": \"white\",\n",
    "    \"云\": \"ghostwhite\",\n",
    "    \n",
    "    # 默认颜色（如果上述未匹配）\n",
    "    \"其他\": \"darkred\"\n",
    "}\n",
    "\n",
    "# 自动生成颜色配置（用于未匹配的类别）\n",
    "COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                'darkred', 'purple', 'orange', 'pink', 'brown', \n",
    "                'cyan', 'magenta', 'lime', 'navy', 'teal']\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------ 日志系统 ------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(OUT_DIR / \"classification_log.txt\", encoding=\"utf-8\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ------------------ 辅助函数 ------------------\n",
    "def get_class_info_from_shp(shp_path, class_attr, name_attr):\n",
    "    \"\"\"从shp文件中获取类别信息和自动生成的颜色\"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    \n",
    "    # 检查是否存在名称字段\n",
    "    if name_attr not in gdf.columns:\n",
    "        logger.warning(f\"shp文件中没有找到 '{name_attr}' 字段，将使用类别编号作为名称\")\n",
    "        # 如果没有名称字段，使用类别编号作为名称\n",
    "        gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "    \n",
    "    # 获取唯一的类别编号和对应的名称\n",
    "    class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "    class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "    \n",
    "    # 生成颜色映射\n",
    "    class_colors = {}\n",
    "    for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "        # 尝试从预定义颜色中匹配\n",
    "        color_found = False\n",
    "        for key, color in LANDUSE_COLORS.items():\n",
    "            if key in class_name:\n",
    "                class_colors[class_id] = color\n",
    "                color_found = True\n",
    "                break\n",
    "        \n",
    "        # 如果没有匹配到预定义颜色，使用自动分配的颜色\n",
    "        if not color_found:\n",
    "            class_colors[class_id] = COLOR_PALETTE[i % len(COLOR_PALETTE)]\n",
    "    \n",
    "    unique_classes = sorted(class_names.keys())\n",
    "    \n",
    "    return class_names, class_colors, unique_classes\n",
    "\n",
    "def rasterize_samples(shp, ref_img, attr):\n",
    "    \"\"\"将矢量样本栅格化为与影像对齐的数组\"\"\"\n",
    "    import rasterio.features\n",
    "    \n",
    "    gdf = gpd.read_file(shp)\n",
    "    gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "    shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "    \n",
    "    arr = rasterio.features.rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=ref_img.shape[1:],\n",
    "        transform=ref_img.rio.transform(),\n",
    "        fill=0,\n",
    "        all_touched=True,\n",
    "        dtype=\"uint16\"\n",
    "    )\n",
    "    return arr\n",
    "\n",
    "def extract_samples(image, mask):\n",
    "    \"\"\"根据掩膜提取样本特征与标签\"\"\"\n",
    "    data = np.moveaxis(image.values, 0, -1)  # (bands, rows, cols) → (rows, cols, bands)\n",
    "    valid = mask > 0\n",
    "    X = data[valid]\n",
    "    y = mask[valid]\n",
    "    return X, y\n",
    "\n",
    "def get_classifier(name):\n",
    "    \"\"\"构造分类器\"\"\"\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=N_ESTIMATORS, n_jobs=-1, oob_score=True, verbose=1\n",
    "        )\n",
    "    elif name == \"svm\":\n",
    "        return SVC(kernel=\"rbf\", probability=True)\n",
    "    elif name == \"xgb\":\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            return XGBClassifier(\n",
    "                n_estimators=N_ESTIMATORS, learning_rate=0.1, max_depth=8, n_jobs=-1\n",
    "            )\n",
    "        except ImportError:\n",
    "            raise ImportError(\"未安装 xgboost，请先运行 pip install xgboost\")\n",
    "    else:\n",
    "        raise ValueError(f\"未知分类器类型: {name}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"绘制详细的混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 计算百分比\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # 创建热图\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '样本数量'})\n",
    "    \n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 同时保存百分比版本\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': '百分比 (%)'})\n",
    "    plt.xlabel('预测类别', fontsize=12)\n",
    "    plt.ylabel('真实类别', fontsize=12)\n",
    "    plt.title('混淆矩阵 (百分比)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.png', '_percent.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def comprehensive_evaluation(y_true, y_pred, class_names, save_path):\n",
    "    \"\"\"全方位精度评价\"\"\"\n",
    "    # 计算各项指标\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # 创建详细报告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "    \n",
    "    # 创建精度评价表格\n",
    "    eval_df = pd.DataFrame({\n",
    "        '类别': class_names,\n",
    "        '精确率 (Precision)': precision,\n",
    "        '召回率 (Recall)': recall,\n",
    "        'F1分数': f1,\n",
    "        '样本数量': np.bincount(y_true)[1:len(class_names)+1]  # 从1开始计数\n",
    "    })\n",
    "    \n",
    "    # 保存详细报告\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"           遥感影像分类精度评价报告\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"总体精度 (Overall Accuracy): {overall_accuracy:.4f}\\n\")\n",
    "        f.write(f\"Kappa系数: {kappa:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别精度评价:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(eval_df.to_string(index=False, float_format='%.4f'))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"详细分类报告:\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        f.write(report)\n",
    "    \n",
    "    # 绘制精度指标条形图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, precision, width, label='精确率', alpha=0.8)\n",
    "    plt.bar(x, recall, width, label='召回率', alpha=0.8)\n",
    "    plt.bar(x + width, f1, width, label='F1分数', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('分数')\n",
    "    plt.title('各类别分类精度指标')\n",
    "    plt.xticks(x, class_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(save_path).replace('.txt', '_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return overall_accuracy, kappa, eval_df\n",
    "\n",
    "def plot_classification_results(original_img, classified_img, class_names, class_colors, save_path, title_suffix=\"\"):\n",
    "    \"\"\"显示原始影像和分类结果\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # 显示原始影像 (使用前3个波段作为RGB)\n",
    "    if original_img.shape[0] >= 3:\n",
    "        rgb_data = np.moveaxis(original_img.values[:3], 0, -1)\n",
    "        # 数据标准化显示\n",
    "        p2, p98 = np.percentile(rgb_data, (2, 98))\n",
    "        rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "        ax1.imshow(rgb_display)\n",
    "    else:\n",
    "        # 单波段影像显示\n",
    "        ax1.imshow(original_img.values[0], cmap='gray')\n",
    "    \n",
    "    ax1.set_title('原始遥感影像', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # 显示分类结果\n",
    "    classified_data = classified_img.values.squeeze()\n",
    "    \n",
    "    # 创建分类图例\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]  # 排除背景值\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    colors = [class_colors.get(c, 'black') for c in classes]\n",
    "    labels = [class_names.get(c, f'未知类别_{c}') for c in classes]\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    im = ax2.imshow(classified_data, cmap=cmap, norm=norm)\n",
    "    title = '分类结果' + title_suffix\n",
    "    ax2.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 添加图例\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=label) \n",
    "                      for color, label in zip(colors, labels)]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.35, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(clf, feature_names, save_path):\n",
    "    \"\"\"绘制特征重要性图（适用于随机森林和XGBoost）\"\"\"\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('特征重要性排序', fontsize=14, fontweight='bold')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.xlabel('特征波段')\n",
    "        plt.ylabel('重要性')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "def calculate_pixel_area(transform):\n",
    "    \"\"\"计算单个像元的面积（单位：平方米）\"\"\"\n",
    "    # 获取像元尺寸（通常为米）\n",
    "    pixel_width = abs(transform[0])  # x方向分辨率\n",
    "    pixel_height = abs(transform[4])  # y方向分辨率\n",
    "    \n",
    "    # 计算单个像元面积（平方米）\n",
    "    pixel_area = pixel_width * pixel_height\n",
    "    \n",
    "    return pixel_area\n",
    "\n",
    "def predict_by_block_rioxarray(model, image, out_path, block_size=BLOCK_SIZE):\n",
    "    \"\"\"使用rioxarray进行分块预测整幅影像\"\"\"\n",
    "    height, width = image.shape[1], image.shape[2]\n",
    "    \n",
    "    # 创建空的结果数组\n",
    "    result_data = np.zeros((height, width), dtype=np.uint16)\n",
    "    \n",
    "    # 分块处理\n",
    "    for y in tqdm(range(0, height, block_size), desc=\"Block predicting\"):\n",
    "        y_end = min(y + block_size, height)\n",
    "        \n",
    "        for x in range(0, width, block_size):\n",
    "            x_end = min(x + block_size, width)\n",
    "            \n",
    "            # 读取当前块的数据\n",
    "            block_data = image.isel(y=slice(y, y_end), x=slice(x, x_end)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape[:2]\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            data_flat = np.nan_to_num(data_flat)\n",
    "            \n",
    "            # 预测\n",
    "            preds = model.predict(data_flat).reshape(original_shape).astype(\"uint16\")\n",
    "            \n",
    "            # 将结果写入到对应的位置\n",
    "            result_data[y:y_end, x:x_end] = preds\n",
    "    \n",
    "    # 使用xarray创建DataArray (rioxarray是基于xarray的)\n",
    "    result_da = xr.DataArray(\n",
    "        result_data.reshape(1, height, width),  # 添加波段维度\n",
    "        coords={\n",
    "            'band': [1],\n",
    "            'y': image.y,\n",
    "            'x': image.x\n",
    "        },\n",
    "        dims=['band', 'y', 'x'],\n",
    "        attrs=image.attrs\n",
    "    )\n",
    "    \n",
    "    # 设置空间参考信息\n",
    "    result_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "    result_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "    result_da.rio.write_nodata(0, inplace=True)\n",
    "    \n",
    "    # 保存为GeoTIFF\n",
    "    result_da.rio.to_raster(\n",
    "        out_path,\n",
    "        driver='GTiff',\n",
    "        dtype='uint16',\n",
    "        compress='lzw',\n",
    "        tiled=True,\n",
    "        blockxsize=min(block_size, width),\n",
    "        blockysize=min(block_size, block_size)\n",
    "    )\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "def postprocess_classification(classified_data, min_patch_size=10, morphology_op=\"opening\", morphology_size=3):\n",
    "    \"\"\"\n",
    "    后处理分类结果\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - min_patch_size: 最小图斑大小（像元数）\n",
    "    - morphology_op: 形态学操作类型 (\"opening\", \"closing\", \"both\", \"none\")\n",
    "    - morphology_size: 形态学操作核大小\n",
    "    \n",
    "    返回:\n",
    "    - 后处理后的分类结果\n",
    "    \"\"\"\n",
    "    logger.info(\"开始后处理分类结果...\")\n",
    "    processed_data = classified_data.copy()\n",
    "    \n",
    "    # 获取所有类别（排除背景0）\n",
    "    classes = np.unique(classified_data)\n",
    "    classes = classes[classes > 0]\n",
    "    \n",
    "    # 对每个类别进行后处理\n",
    "    for class_id in classes:\n",
    "        # 创建二值掩膜\n",
    "        binary_mask = (classified_data == class_id).astype(np.uint8)\n",
    "        \n",
    "        # 去除小图斑\n",
    "        if min_patch_size > 0:\n",
    "            # 使用连通组件分析标记图斑\n",
    "            labeled_array, num_features = ndimage.label(binary_mask)\n",
    "            \n",
    "            # 计算每个图斑的大小\n",
    "            component_sizes = np.bincount(labeled_array.ravel())\n",
    "            \n",
    "            # 创建掩膜，只保留大于最小图斑大小的区域\n",
    "            size_mask = component_sizes >= min_patch_size\n",
    "            size_mask[0] = 0  # 背景\n",
    "            \n",
    "            # 应用大小过滤\n",
    "            binary_mask = size_mask[labeled_array]\n",
    "        \n",
    "        # 形态学操作\n",
    "        if morphology_op != \"none\" and morphology_size > 0:\n",
    "            # 创建结构元素\n",
    "            structure = np.ones((morphology_size, morphology_size), dtype=np.uint8)\n",
    "            \n",
    "            if morphology_op == \"opening\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "            elif morphology_op == \"closing\":\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "            elif morphology_op == \"both\":\n",
    "                binary_mask = morphology.binary_opening(binary_mask, structure)\n",
    "                binary_mask = morphology.binary_closing(binary_mask, structure)\n",
    "        \n",
    "        # 更新分类结果\n",
    "        processed_data[binary_mask > 0] = class_id\n",
    "        # 将去除的小图斑区域设为背景（0）\n",
    "        processed_data[(classified_data == class_id) & (binary_mask == 0)] = 0\n",
    "    \n",
    "    # 统计后处理变化\n",
    "    original_nonzero = np.count_nonzero(classified_data)\n",
    "    processed_nonzero = np.count_nonzero(processed_data)\n",
    "    change_percent = (original_nonzero - processed_nonzero) / original_nonzero * 100\n",
    "    \n",
    "    logger.info(f\"后处理完成: 原始非零像元数 {original_nonzero}, 处理后非零像元数 {processed_nonzero}\")\n",
    "    logger.info(f\"后处理去除了 {original_nonzero - processed_nonzero} 个像元 ({change_percent:.2f}%)\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def save_classification_result_rioxarray(data, ref_image, out_path):\n",
    "    \"\"\"使用rioxarray保存分类结果到GeoTIFF文件\"\"\"\n",
    "    \n",
    "    # 使用xarray创建DataArray\n",
    "    result_da = xr.DataArray(\n",
    "        data.reshape(1, data.shape[0], data.shape[1]),  # 添加波段维度\n",
    "        coords={\n",
    "            'band': [1],\n",
    "            'y': ref_image.y,\n",
    "            'x': ref_image.x\n",
    "        },\n",
    "        dims=['band', 'y', 'x'],\n",
    "        attrs=ref_image.attrs\n",
    "    )\n",
    "    \n",
    "    # 设置空间参考信息\n",
    "    result_da.rio.write_crs(ref_image.rio.crs, inplace=True)\n",
    "    result_da.rio.write_transform(ref_image.rio.transform(), inplace=True)\n",
    "    result_da.rio.write_nodata(0, inplace=True)\n",
    "    \n",
    "    # 保存为GeoTIFF\n",
    "    result_da.rio.to_raster(\n",
    "        out_path,\n",
    "        driver='GTiff',\n",
    "        dtype='uint16',\n",
    "        compress='lzw',\n",
    "        tiled=True\n",
    "    )\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "def calculate_area_statistics(classified_data, class_names, class_colors, pixel_area_km2, suffix=\"\"):\n",
    "    \"\"\"\n",
    "    计算分类面积统计\n",
    "    \n",
    "    参数:\n",
    "    - classified_data: 分类结果数组\n",
    "    - class_names: 类别名称字典\n",
    "    - class_colors: 类别颜色字典\n",
    "    - pixel_area_km2: 单个像元面积（平方千米）\n",
    "    - suffix: 文件名后缀\n",
    "    \n",
    "    返回:\n",
    "    - stats_df: 统计DataFrame\n",
    "    - total_area_km2: 总面积\n",
    "    \"\"\"\n",
    "    # 获取类别和数量\n",
    "    unique, counts = np.unique(classified_data[classified_data > 0], return_counts=True)\n",
    "    total_pixels = np.sum(counts)\n",
    "    \n",
    "    # 计算各类别面积\n",
    "    areas_km2 = [count * pixel_area_km2 for count in counts]\n",
    "    total_area_km2 = np.sum(areas_km2)\n",
    "    \n",
    "    # 创建统计表格\n",
    "    stats_df = pd.DataFrame({\n",
    "        '类别编号': unique,\n",
    "        '类别名称': [class_names.get(c, f'未知类别_{c}') for c in unique],\n",
    "        '像元数量': counts,\n",
    "        '面积(km²)': [round(area, 4) for area in areas_km2],\n",
    "        '面积占比 (%)': (counts / total_pixels * 100).round(2)\n",
    "    })\n",
    "    \n",
    "    # 保存统计表格\n",
    "    stats_filename = f\"classification_statistics{suffix}.csv\"\n",
    "    stats_df.to_csv(OUT_DIR / stats_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 绘制面积占比饼图\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(stats_df['面积占比 (%)'], labels=stats_df['类别名称'], autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'分类结果面积占比分布{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_distribution{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制面积柱状图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(stats_df['类别名称'], stats_df['面积(km²)'], \n",
    "            color=[class_colors.get(c, 'gray') for c in unique])\n",
    "    plt.xlabel('地物类别')\n",
    "    plt.ylabel('面积 (km²)')\n",
    "    plt.title(f'各类别面积统计{suffix}', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 在柱状图上添加数值标签\n",
    "    for i, v in enumerate(stats_df['面积(km²)']):\n",
    "        plt.text(i, v + max(areas_km2)*0.01, f'{v:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"area_bar_chart{suffix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 生成面积统计摘要\n",
    "    with open(OUT_DIR / f\"area_summary{suffix}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"分类面积统计摘要{suffix}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"总分类面积: {total_area_km2:.4f} km²\\n\")\n",
    "        f.write(f\"像元大小: {pixel_area_km2 * 1e6:.2f} 平方米\\n\")\n",
    "        f.write(f\"总像元数: {total_pixels}\\n\\n\")\n",
    "        \n",
    "        f.write(\"各类别面积统计:\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        for _, row in stats_df.iterrows():\n",
    "            f.write(f\"{row['类别名称']}: {row['面积(km²)']:.4f} km² ({row['面积占比 (%)']}%)\\n\")\n",
    "    \n",
    "    return stats_df, total_area_km2\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    logger.info(\"开始监督分类任务...\")\n",
    "\n",
    "    # 0. 从训练样本shp文件中获取类别信息\n",
    "    logger.info(\"正在读取类别信息...\")\n",
    "    class_names, class_colors, train_classes = get_class_info_from_shp(TRAIN_SHP, CLASS_ATTRIBUTE, NAME_ATTRIBUTE)\n",
    "    logger.info(f\"检测到类别: {list(class_names.values())}\")\n",
    "\n",
    "    # 1. 读取影像\n",
    "    img = rxr.open_rasterio(IMAGE_PATH, masked=True)\n",
    "    logger.info(f\"影像尺寸: {img.shape}, 波段数: {img.rio.count}\")\n",
    "    \n",
    "    # 获取影像的空间参考信息\n",
    "    transform = img.rio.transform()\n",
    "    crs = img.rio.crs\n",
    "    logger.info(f\"影像坐标系: {crs}\")\n",
    "    logger.info(f\"影像变换参数: {transform}\")\n",
    "\n",
    "    # 计算像元面积\n",
    "    pixel_area_m2 = calculate_pixel_area(transform)\n",
    "    pixel_area_km2 = pixel_area_m2 / 1e6  # 转换为平方千米\n",
    "    logger.info(f\"单个像元面积: {pixel_area_m2:.2f} 平方米 ({pixel_area_km2:.6f} 平方千米)\")\n",
    "\n",
    "    # 2. 训练样本栅格化与提取\n",
    "    logger.info(\"正在处理训练样本...\")\n",
    "    train_mask = rasterize_samples(TRAIN_SHP, img, CLASS_ATTRIBUTE)\n",
    "    X_train, y_train = extract_samples(img, train_mask)\n",
    "    logger.info(f\"训练样本数: {len(y_train)}\")\n",
    "\n",
    "    # 3. 训练分类器\n",
    "    clf = get_classifier(CLASSIFIER)\n",
    "    logger.info(f\"使用分类器: {clf.__class__.__name__}\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    logger.info(\"模型训练完成。\")\n",
    "\n",
    "    # 4. 精度评估（训练集）\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    # 获取实际存在的类别\n",
    "    actual_train_classes = sorted(np.unique(y_train))\n",
    "    train_class_names = [class_names.get(c, f'未知类别_{c}') for c in actual_train_classes if c > 0]\n",
    "    \n",
    "    # 全方位精度评价\n",
    "    overall_acc, kappa, eval_df = comprehensive_evaluation(\n",
    "        y_train, y_pred_train, train_class_names, OUT_DIR / \"train_evaluation.txt\"\n",
    "    )\n",
    "    logger.info(f\"训练集总体精度: {overall_acc:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 绘制训练集混淆矩阵\n",
    "    plot_confusion_matrix(y_train, y_pred_train, train_class_names, OUT_DIR / \"train_cm.png\")\n",
    "\n",
    "    # 5. 特征重要性分析（如果适用）\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        feature_names = [f'波段{i+1}' for i in range(X_train.shape[1])]\n",
    "        plot_feature_importance(clf, feature_names, OUT_DIR / \"feature_importance.png\")\n",
    "\n",
    "    # 6. 分块预测整幅影像 (使用rioxarray)\n",
    "    logger.info(\"开始分块预测...\")\n",
    "    classified_path = OUT_DIR / \"classified_result.tif\"\n",
    "    predict_by_block_rioxarray(clf, img, classified_path)\n",
    "    logger.info(f\"分类结果保存至: {classified_path}\")\n",
    "\n",
    "    # 7. 显示原始分类结果\n",
    "    logger.info(\"生成原始分类结果可视化...\")\n",
    "    classified_img = rxr.open_rasterio(classified_path)\n",
    "    plot_classification_results(img, classified_img, class_names, class_colors, \n",
    "                               OUT_DIR / \"classification_visualization.png\", \" (原始)\")\n",
    "\n",
    "    # 8. 原始分类结果面积统计\n",
    "    logger.info(\"计算原始分类结果面积统计...\")\n",
    "    original_classified_data = classified_img.values.squeeze()\n",
    "    original_stats_df, original_total_area = calculate_area_statistics(\n",
    "        original_classified_data, class_names, class_colors, pixel_area_km2, \"_original\"\n",
    "    )\n",
    "    logger.info(f\"原始分类总面积: {original_total_area:.4f} 平方千米\")\n",
    "\n",
    "    # 9. 后处理\n",
    "    if POSTPROCESSING:\n",
    "        logger.info(\"开始后处理...\")\n",
    "        logger.info(f\"后处理参数: 最小图斑大小={MIN_PATCH_SIZE}, 形态学操作={MORPHOLOGY_OPERATION}, 核大小={MORPHOLOGY_SIZE}\")\n",
    "        \n",
    "        # 进行后处理\n",
    "        processed_data = postprocess_classification(\n",
    "            original_classified_data, \n",
    "            min_patch_size=MIN_PATCH_SIZE,\n",
    "            morphology_op=MORPHOLOGY_OPERATION,\n",
    "            morphology_size=MORPHOLOGY_SIZE\n",
    "        )\n",
    "        \n",
    "        # 保存后处理结果 (使用rioxarray)\n",
    "        processed_path = OUT_DIR / \"classified_result_postprocessed.tif\"\n",
    "        save_classification_result_rioxarray(processed_data, img, processed_path)\n",
    "        logger.info(f\"后处理结果保存至: {processed_path}\")\n",
    "        \n",
    "        # 显示后处理分类结果\n",
    "        logger.info(\"生成后处理分类结果可视化...\")\n",
    "        processed_img = rxr.open_rasterio(processed_path)\n",
    "        plot_classification_results(img, processed_img, class_names, class_colors,\n",
    "                                   OUT_DIR / \"classification_visualization_postprocessed.png\", \" (后处理)\")\n",
    "        \n",
    "        # 后处理分类结果面积统计\n",
    "        logger.info(\"计算后处理分类结果面积统计...\")\n",
    "        processed_stats_df, processed_total_area = calculate_area_statistics(\n",
    "            processed_data, class_names, class_colors, pixel_area_km2, \"_postprocessed\"\n",
    "        )\n",
    "        logger.info(f\"后处理分类总面积: {processed_total_area:.4f} 平方千米\")\n",
    "        \n",
    "        # 生成后处理变化报告\n",
    "        area_change = processed_total_area - original_total_area\n",
    "        area_change_percent = (area_change / original_total_area) * 100\n",
    "        \n",
    "        with open(OUT_DIR / \"postprocessing_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"后处理变化报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"后处理参数:\\n\")\n",
    "            f.write(f\"  最小图斑大小: {MIN_PATCH_SIZE} 像元\\n\")\n",
    "            f.write(f\"  形态学操作: {MORPHOLOGY_OPERATION}\\n\")\n",
    "            f.write(f\"  核大小: {MORPHOLOGY_SIZE}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"面积变化:\\n\")\n",
    "            f.write(f\"  原始总面积: {original_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  后处理总面积: {processed_total_area:.4f} km²\\n\")\n",
    "            f.write(f\"  面积变化: {area_change:+.4f} km² ({area_change_percent:+.2f}%)\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别面积变化:\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "            for class_id in class_names.keys():\n",
    "                if class_id in original_stats_df['类别编号'].values and class_id in processed_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    change = proc_area - orig_area\n",
    "                    change_percent = (change / orig_area) * 100 if orig_area > 0 else 0\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → {proc_area:.4f} km² ({change:+.4f}, {change_percent:+.2f}%)\\n\")\n",
    "                elif class_id in original_stats_df['类别编号'].values:\n",
    "                    orig_area = original_stats_df[original_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: {orig_area:.4f} → 0.0000 km² (完全去除)\\n\")\n",
    "                elif class_id in processed_stats_df['类别编号'].values:\n",
    "                    proc_area = processed_stats_df[processed_stats_df['类别编号'] == class_id]['面积(km²)'].values[0]\n",
    "                    f.write(f\"{class_names[class_id]}: 0.0000 → {proc_area:.4f} km² (新增)\\n\")\n",
    "\n",
    "    # 10. 验证阶段\n",
    "    if os.path.exists(VAL_SHP):\n",
    "        logger.info(\"正在进行验证...\")\n",
    "        val_mask = rasterize_samples(VAL_SHP, img, CLASS_ATTRIBUTE)\n",
    "        \n",
    "        # 使用原始分类结果进行验证\n",
    "        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "            pred_arr = pred_img.values.squeeze()\n",
    "        \n",
    "        Xv = pred_arr[val_mask > 0]\n",
    "        yv = val_mask[val_mask > 0]\n",
    "        \n",
    "        # 验证集全方位精度评价\n",
    "        val_classes = sorted(np.unique(yv))\n",
    "        val_class_names = [class_names.get(c, f'未知类别_{c}') for c in val_classes if c > 0]\n",
    "        \n",
    "        val_overall_acc, val_kappa, val_eval_df = comprehensive_evaluation(\n",
    "            yv, Xv, val_class_names, OUT_DIR / \"validation_evaluation.txt\"\n",
    "        )\n",
    "        logger.info(f\"验证集总体精度: {val_overall_acc:.4f}, Kappa: {val_kappa:.4f}\")\n",
    "        \n",
    "        # 绘制验证集混淆矩阵\n",
    "        plot_confusion_matrix(yv, Xv, val_class_names, OUT_DIR / \"val_cm.png\")\n",
    "\n",
    "        # 生成综合报告\n",
    "        with open(OUT_DIR / \"comprehensive_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"遥感影像分类综合报告\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"分类器: {clf.__class__.__name__}\\n\")\n",
    "            f.write(f\"训练样本数: {len(y_train)}\\n\")\n",
    "            f.write(f\"验证样本数: {len(yv)}\\n\")\n",
    "            f.write(f\"类别编号字段: {CLASS_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"类别名称字段: {NAME_ATTRIBUTE}\\n\")\n",
    "            f.write(f\"检测到的类别: {list(class_names.values())}\\n\")\n",
    "            f.write(f\"像元面积: {pixel_area_m2:.2f} 平方米\\n\")\n",
    "            f.write(f\"后处理: {'是' if POSTPROCESSING else '否'}\\n\\n\")\n",
    "            \n",
    "            f.write(\"精度评价汇总:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"训练集总体精度: {overall_acc:.4f}\\n\")\n",
    "            f.write(f\"训练集Kappa系数: {kappa:.4f}\\n\")\n",
    "            f.write(f\"验证集总体精度: {val_overall_acc:.4f}\\n\")\n",
    "            f.write(f\"验证集Kappa系数: {val_kappa:.4f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"各类别验证精度:\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(val_eval_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "    # 11. 保存类别信息\n",
    "    class_info_df = pd.DataFrame({\n",
    "        '类别编号': list(class_names.keys()),\n",
    "        '类别名称': list(class_names.values()),\n",
    "        '显示颜色': [class_colors.get(c, 'black') for c in class_names.keys()]\n",
    "    })\n",
    "    class_info_df.to_csv(OUT_DIR / \"class_information.csv\", index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    logger.info(f\"全部任务完成，用时 {time.time()-t0:.1f} 秒。\")\n",
    "    logger.info(f\"所有结果已保存至: {OUT_DIR.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
