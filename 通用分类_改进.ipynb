{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfb0d5a",
   "metadata": {},
   "source": [
    "# ç‰ˆæœ¬1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7188491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - GUIç‰ˆæœ¬ (å®Œå…¨ä¼˜åŒ–ç‰ˆ)\n",
    "==============================================\n",
    "ç‰ˆæœ¬: v3.0\n",
    "ä½œè€…: AI Assistant\n",
    "æ—¥æœŸ: 2024\n",
    "\n",
    "ä¸»è¦ç‰¹æ€§:\n",
    "- 12ç§åˆ†ç±»å™¨ + 5ç§SVMå˜ä½“\n",
    "- æ™ºèƒ½æ€§èƒ½ä¼˜åŒ–ï¼ˆé‡‡æ ·ã€ç‰¹å¾ç¼©æ”¾ã€å¿«é€Ÿæ¨¡å¼ï¼‰\n",
    "- SVMé€Ÿåº¦ä¼˜åŒ–ï¼ˆçº¿æ€§æ ¸ã€SGDã€æ ¸è¿‘ä¼¼ï¼‰\n",
    "- é¢„æµ‹æ—¶é—´ä¼°ç®—å’Œæ€§èƒ½è­¦å‘Š\n",
    "- å®æ—¶è¿›åº¦æ˜¾ç¤ºå’Œè¯¦ç»†æ—¥å¿—\n",
    "- è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.kernel_approximation import Nystroem, RBFSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ==================== åç«¯å¤„ç†ç±» ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"åˆ†ç±»å¤„ç†åç«¯ï¼ˆå®Œå…¨ä¼˜åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.BACKGROUND_VALUE = 0\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # é¢„å®šä¹‰é¢œè‰²\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"æ°´ä½“\": \"lightblue\", \"æ²³æµ\": \"blue\", \"æ¹–æ³Š\": \"deepskyblue\",\n",
    "            \"æ¤è¢«\": \"forestgreen\", \"æ£®æ—\": \"darkgreen\", \"è‰åœ°\": \"limegreen\",\n",
    "            \"å†œç”°\": \"yellowgreen\", \"è€•åœ°\": \"olivedrab\",\n",
    "            \"å»ºç­‘\": \"gray\", \"åŸå¸‚\": \"dimgray\", \"å±…æ°‘åœ°\": \"slategray\",\n",
    "            \"è£¸åœ°\": \"tan\", \"æ²™åœ°\": \"wheat\", \"å…¶ä»–\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰åˆ†ç±»å™¨ï¼ˆåŒ…å«SVMä¼˜åŒ–ç‰ˆæœ¬ï¼‰\n",
    "        \n",
    "        è¿”å›æ ¼å¼: {code: (classifier, name, desc, needs_encoding, needs_scaling, speed_tag)}\n",
    "        speed_tag: \"very_fast\", \"fast\", \"medium\", \"slow\", \"very_slow\"\n",
    "        \"\"\"\n",
    "        # æ ¹æ®æ¨¡å¼è°ƒæ•´å‚æ•°\n",
    "        if fast_mode:\n",
    "            n_est = min(50, n_estimators)\n",
    "            max_depth = 10\n",
    "            max_iter = 200\n",
    "        else:\n",
    "            n_est = n_estimators\n",
    "            max_depth = 20\n",
    "            max_iter = 500\n",
    "        \n",
    "        # æ ¸è¿‘ä¼¼çš„ç»„ä»¶æ•°\n",
    "        if n_train_samples:\n",
    "            n_components = min(1000, n_train_samples // 2)\n",
    "        else:\n",
    "            n_components = 1000\n",
    "        \n",
    "        classifiers = {\n",
    "            # ===== æ ‘æ¨¡å‹ç³»åˆ—ï¼ˆé€Ÿåº¦å¿«ï¼‰ =====\n",
    "            \"rf\": (\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=n_est, \n",
    "                    n_jobs=-1, \n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"éšæœºæ£®æ—\", \"Random Forest - ç¨³å®šå¯é çš„é›†æˆå­¦ä¹ \", \n",
    "                False, False, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"et\": (\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"æç«¯éšæœºæ ‘\", \"Extra Trees - æ›´å¿«çš„éšæœºæ£®æ—\", \n",
    "                False, False, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"dt\": (\n",
    "                DecisionTreeClassifier(\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2\n",
    "                ),\n",
    "                \"å†³ç­–æ ‘\", \"Decision Tree - ç®€å•å¿«é€Ÿ\", \n",
    "                False, False, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            # ===== SVMç³»åˆ—ï¼ˆå¤šç§ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ =====\n",
    "            \"svm_linear\": (\n",
    "                SVC(\n",
    "                    kernel=\"linear\",\n",
    "                    C=1.0,\n",
    "                    cache_size=500,\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_iter=max_iter\n",
    "                ),\n",
    "                \"SVM-çº¿æ€§æ ¸\", \"SVM Linear - çº¿æ€§å¯åˆ†é—®é¢˜\", \n",
    "                False, True, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"linear_svc\": (\n",
    "                CalibratedClassifierCV(\n",
    "                    LinearSVC(\n",
    "                        C=1.0,\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE,\n",
    "                        dual=False,\n",
    "                        loss='squared_hinge'\n",
    "                    ),\n",
    "                    cv=3\n",
    "                ),\n",
    "                \"çº¿æ€§SVM(å¿«)\", \"Linear SVM - å¿«é€Ÿçº¿æ€§åˆ†ç±»å™¨\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"sgd_svm\": (\n",
    "                SGDClassifier(\n",
    "                    loss='hinge',\n",
    "                    penalty='l2',\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    learning_rate='optimal'\n",
    "                ),\n",
    "                \"SGD-SVM\", \"SGD SVM - æå¿«çš„çº¿æ€§SVM\", \n",
    "                False, True, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"nystroem_svm\": (\n",
    "                Pipeline([\n",
    "                    (\"feature_map\", Nystroem(\n",
    "                        kernel='rbf',\n",
    "                        gamma=0.1,\n",
    "                        n_components=n_components,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    )),\n",
    "                    (\"sgd\", SGDClassifier(\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    ))\n",
    "                ]),\n",
    "                \"æ ¸è¿‘ä¼¼SVM\", \"Nystroem SVM - RBFæ ¸çš„å¿«é€Ÿè¿‘ä¼¼\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"rbf_sampler_svm\": (\n",
    "                Pipeline([\n",
    "                    (\"feature_map\", RBFSampler(\n",
    "                        gamma=0.1,\n",
    "                        n_components=n_components,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    )),\n",
    "                    (\"sgd\", SGDClassifier(\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    ))\n",
    "                ]),\n",
    "                \"RBFé‡‡æ ·SVM\", \"RBF Sampler SVM - å¦ä¸€ç§RBFè¿‘ä¼¼\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"svm_rbf\": (\n",
    "                SVC(\n",
    "                    kernel=\"rbf\", \n",
    "                    C=1.0,\n",
    "                    gamma='scale',\n",
    "                    cache_size=500,\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                ),\n",
    "                \"SVM-RBFæ ¸âš ï¸\", \"SVM RBF - é«˜ç²¾åº¦ä½†é¢„æµ‹ææ…¢\", \n",
    "                False, True, \"very_slow\"\n",
    "            ),\n",
    "            \n",
    "            # ===== å…¶ä»–åˆ†ç±»å™¨ =====\n",
    "            \"knn\": (\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=5,\n",
    "                    n_jobs=-1,\n",
    "                    algorithm='ball_tree',\n",
    "                    leaf_size=30\n",
    "                ),\n",
    "                \"Kè¿‘é‚»\", \"KNN - åŸºäºè·ç¦»çš„åˆ†ç±»å™¨\", \n",
    "                False, True, \"slow\"\n",
    "            ),\n",
    "            \n",
    "            \"nb\": (\n",
    "                GaussianNB(),\n",
    "                \"æœ´ç´ è´å¶æ–¯\", \"Naive Bayes - æœ€å¿«çš„æ¦‚ç‡åˆ†ç±»å™¨\", \n",
    "                False, False, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"gb\": (\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5,\n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    subsample=0.8\n",
    "                ),\n",
    "                \"æ¢¯åº¦æå‡\", \"Gradient Boosting - å¼ºå¤§çš„é›†æˆæ–¹æ³•\", \n",
    "                False, False, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"ada\": (\n",
    "                AdaBoostClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=1.0,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    algorithm='SAMME.R'\n",
    "                ),\n",
    "                \"AdaBoost\", \"AdaBoost - è‡ªé€‚åº”æå‡\", \n",
    "                False, False, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"lr\": (\n",
    "                LogisticRegression(\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    solver='lbfgs',\n",
    "                    multi_class='multinomial'\n",
    "                ),\n",
    "                \"é€»è¾‘å›å½’\", \"Logistic Regression - ç»å…¸çº¿æ€§åˆ†ç±»å™¨\", \n",
    "                False, True, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"mlp\": (\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=(100, 50),\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=False,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction=0.1,\n",
    "                    n_iter_no_change=10,\n",
    "                    learning_rate='adaptive'\n",
    "                ),\n",
    "                \"ç¥ç»ç½‘ç»œ\", \"MLP - å‰é¦ˆç¥ç»ç½‘ç»œ\", \n",
    "                False, True, \"medium\"\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        # XGBoost\n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "            classifiers[\"xgb\"] = (\n",
    "                XGBClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=6,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbosity=0,\n",
    "                    tree_method='hist',\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"XGBoost\", \"XGBoost - é«˜æ€§èƒ½æ¢¯åº¦æå‡\", \n",
    "                True, False, \"fast\"\n",
    "            )\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        # å°†ç¬¬328-347è¡Œçš„ LightGBM å¯¼å…¥éƒ¨åˆ†æ›¿æ¢ä¸ºï¼š\n",
    "\n",
    "        # LightGBM\n",
    "        try:\n",
    "            # å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™è·³è¿‡\n",
    "            import lightgbm\n",
    "            from lightgbm import LGBMClassifier\n",
    "            classifiers[\"lgb\"] = (\n",
    "                LGBMClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=max_depth,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=-1,\n",
    "                    num_leaves=31,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8\n",
    "                ),\n",
    "                \"LightGBM\", \"LightGBM - æé€Ÿæ¢¯åº¦æå‡\", \n",
    "                False, False, \"very_fast\"\n",
    "            )\n",
    "        except (ImportError, AttributeError) as e:\n",
    "            # æ•è·å¯¼å…¥é”™è¯¯å’Œå±æ€§é”™è¯¯\n",
    "            pass\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image):\n",
    "        \"\"\"è·å–èƒŒæ™¯æ©è†œ\"\"\"\n",
    "        data = image.values\n",
    "        background_mask = np.all(data == 0, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in class_name:\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"çŸ¢é‡æ …æ ¼åŒ–\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=ref_img.shape[1:],\n",
    "            transform=ref_img.rio.transform(),\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint16\"\n",
    "        )\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True, max_samples=None):\n",
    "        \"\"\"\n",
    "        æå–æ ·æœ¬å¹¶æ¸…ç†NaNå€¼\n",
    "        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼Œå¦‚æœè¶…è¿‡åˆ™è¿›è¡Œåˆ†å±‚é‡‡æ ·\n",
    "        \"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # æ¸…ç†NaNå’ŒInfå€¼\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        bad_mask = nan_mask | inf_mask\n",
    "        \n",
    "        n_nan = np.sum(nan_mask)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        X = X[~bad_mask]\n",
    "        y = y[~bad_mask]\n",
    "        \n",
    "        # åˆ†å±‚é‡‡æ ·\n",
    "        n_sampled = 0\n",
    "        if max_samples is not None and len(y) > max_samples:\n",
    "            n_original = len(y)\n",
    "            \n",
    "            unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "            \n",
    "            if len(unique_classes) > 1:\n",
    "                splitter = StratifiedShuffleSplit(\n",
    "                    n_splits=1, \n",
    "                    train_size=max_samples, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                )\n",
    "                \n",
    "                sample_idx, _ = next(splitter.split(X, y))\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "            else:\n",
    "                np.random.seed(self.RANDOM_STATE)\n",
    "                sample_idx = np.random.choice(len(y), max_samples, replace=False)\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "        \n",
    "        return X, y, n_nan, n_inf, n_sampled\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"è®¡ç®—è¯„ä»·æŒ‡æ ‡\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):\n",
    "        \"\"\"\n",
    "        ä¼°ç®—é¢„æµ‹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        åŸºäºé€Ÿåº¦æ ‡ç­¾å’Œåƒå…ƒæ•°é‡\n",
    "        \"\"\"\n",
    "        time_per_million_pixels = {\n",
    "            \"very_fast\": 1,      # 1ç§’/ç™¾ä¸‡åƒå…ƒ\n",
    "            \"fast\": 3,           # 3ç§’/ç™¾ä¸‡åƒå…ƒ\n",
    "            \"medium\": 10,        # 10ç§’/ç™¾ä¸‡åƒå…ƒ\n",
    "            \"slow\": 30,          # 30ç§’/ç™¾ä¸‡åƒå…ƒ\n",
    "            \"very_slow\": 300     # 300ç§’/ç™¾ä¸‡åƒå…ƒ (5åˆ†é’Ÿ)\n",
    "        }\n",
    "        \n",
    "        base_time = time_per_million_pixels.get(speed_tag, 10)\n",
    "        return (n_pixels / 1_000_000) * base_time\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, progress_callback=None,\n",
    "                        label_encoder=None, scaler=None):\n",
    "        \"\"\"\n",
    "        åˆ†å—é¢„æµ‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰\n",
    "        \"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], \n",
    "                                                   nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    if scaler is not None:\n",
    "                        data_to_predict = scaler.transform(data_to_predict)\n",
    "                    \n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    data_flat = scaler.transform(data_flat)\n",
    "                \n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        prediction_da = xr.DataArray(\n",
    "            prediction,\n",
    "            dims=['y', 'x'],\n",
    "            coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "        )\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(self.BACKGROUND_VALUE, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUIä¸»ç±» ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢ï¼ˆå®Œå…¨ä¼˜åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0 (å®Œå…¨ä¼˜åŒ–ç‰ˆ)\")\n",
    "        self.root.geometry(\"1450x950\")\n",
    "        \n",
    "        # åç«¯å¤„ç†å¯¹è±¡\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # æ•°æ®å˜é‡\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        self.class_attr = tk.StringVar(value=\"class\")\n",
    "        self.name_attr = tk.StringVar(value=\"name\")\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "        self.enable_sampling = tk.BooleanVar(value=True)\n",
    "        self.max_samples = tk.IntVar(value=50000)\n",
    "        self.fast_mode = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # åˆ†ç±»å™¨é€‰æ‹©\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code in all_classifiers.keys():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # è¿è¡ŒçŠ¶æ€\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # æ„å»ºç•Œé¢\n",
    "        self.build_ui()\n",
    "        \n",
    "        # å¯åŠ¨æ—¥å¿—æ›´æ–°\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"æ„å»ºç”¨æˆ·ç•Œé¢\"\"\"\n",
    "        # åˆ›å»ºä¸»æ¡†æ¶\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.rowconfigure(0, weight=1)\n",
    "        main_frame.columnconfigure(1, weight=1)\n",
    "        main_frame.rowconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 1. æ–‡ä»¶é€‰æ‹©åŒº =====\n",
    "        file_frame = ttk.LabelFrame(main_frame, text=\"1. æ•°æ®è¾“å…¥\", padding=\"10\")\n",
    "        file_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"å½±åƒæ–‡ä»¶:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=65).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_image).grid(\n",
    "            row=0, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è®­ç»ƒæ ·æœ¬:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=65).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_train_shp).grid(\n",
    "            row=1, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"éªŒè¯æ ·æœ¬:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=65).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_val_shp).grid(\n",
    "            row=2, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è¾“å‡ºç›®å½•:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=65).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_output).grid(\n",
    "            row=3, column=2, padx=5\n",
    "        )\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # ===== 2. å‚æ•°è®¾ç½®åŒº =====\n",
    "        param_frame = ttk.LabelFrame(main_frame, text=\"2. å‚æ•°é…ç½®\", padding=\"10\")\n",
    "        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N), pady=5, padx=(0, 5))\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"ç±»åˆ«ç¼–å·å­—æ®µ:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.class_attr, width=15).grid(\n",
    "            row=0, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"ç±»åˆ«åç§°å­—æ®µ:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.name_attr, width=15).grid(\n",
    "            row=1, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"æ ‘æ¨¡å‹æ•°é‡:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=13).grid(row=2, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"åˆ†å—å¤§å°:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=13).grid(\n",
    "            row=3, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # æ€§èƒ½ä¼˜åŒ–é€‰é¡¹\n",
    "        ttk.Separator(param_frame, orient='horizontal').grid(\n",
    "            row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=8\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"âš¡ æ€§èƒ½ä¼˜åŒ–:\", font=('', 9, 'bold')).grid(\n",
    "            row=5, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        sample_frame = ttk.Frame(param_frame)\n",
    "        sample_frame.grid(row=6, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        ttk.Checkbutton(sample_frame, text=\"å¯ç”¨é‡‡æ ·\", \n",
    "                       variable=self.enable_sampling,\n",
    "                       command=self.toggle_sampling).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Label(sample_frame, text=\"  æœ€å¤§æ ·æœ¬æ•°:\").pack(side=tk.LEFT, padx=(10, 0))\n",
    "        self.max_samples_spinbox = ttk.Spinbox(\n",
    "            sample_frame, from_=10000, to=200000, increment=10000,\n",
    "            textvariable=self.max_samples, width=10\n",
    "        )\n",
    "        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘æ¨¡å‹å¤æ‚åº¦ï¼‰\", \n",
    "                       variable=self.fast_mode).grid(\n",
    "            row=7, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"å¿½ç•¥èƒŒæ™¯å€¼ï¼ˆæ‰€æœ‰æ³¢æ®µä¸º0ï¼‰\", \n",
    "                       variable=self.ignore_background).grid(\n",
    "            row=8, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        # ===== 3. åˆ†ç±»å™¨é€‰æ‹©åŒº =====\n",
    "        clf_frame = ttk.LabelFrame(main_frame, text=\"3. åˆ†ç±»å™¨é€‰æ‹© (âœ“æ¨è âš ï¸æ…¢é€Ÿ)\", padding=\"10\")\n",
    "        clf_frame.grid(row=1, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        # å¿«æ·æŒ‰é’®\n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 5))\n",
    "        \n",
    "        ttk.Button(btn_frame, text=\"å…¨é€‰\", command=self.select_all_classifiers, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"å…¨ä¸é€‰\", command=self.deselect_all_classifiers, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âœ“æ¨èç»„åˆ\", command=self.select_recommended, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âš¡å¿«é€Ÿåˆ†ç±»å™¨\", command=self.select_fast, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"SVMå…¨é€‰\", command=self.select_all_svm, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        \n",
    "        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ\n",
    "        canvas = tk.Canvas(clf_frame, height=200)\n",
    "        scrollbar = ttk.Scrollbar(clf_frame, orient=\"vertical\", command=canvas.yview)\n",
    "        scrollable_frame = ttk.Frame(canvas)\n",
    "        \n",
    "        scrollable_frame.bind(\n",
    "            \"<Configure>\",\n",
    "            lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "        )\n",
    "        \n",
    "        canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        # åˆ†ç±»å™¨å¤é€‰æ¡†ï¼ˆåˆ†ç»„æ˜¾ç¤ºï¼‰\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        \n",
    "        # SVMç»„\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸ“Š SVMç³»åˆ—:\", font=('', 9, 'bold')).grid(\n",
    "            row=0, column=0, columnspan=3, sticky=tk.W, pady=(5, 2)\n",
    "        )\n",
    "        row = 1\n",
    "        col = 0\n",
    "        svm_codes = [\"svm_linear\", \"linear_svc\", \"sgd_svm\", \"nystroem_svm\", \n",
    "                     \"rbf_sampler_svm\", \"svm_rbf\"]\n",
    "        for code in svm_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name, \n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        if col > 0:\n",
    "            row += 1\n",
    "        \n",
    "        # æ ‘æ¨¡å‹ç»„\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸŒ² æ ‘æ¨¡å‹ç³»åˆ—:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, columnspan=3, sticky=tk.W, pady=(10, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        col = 0\n",
    "        tree_codes = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"gb\", \"ada\"]\n",
    "        for code in tree_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name,\n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        if col > 0:\n",
    "            row += 1\n",
    "        \n",
    "        # å…¶ä»–åˆ†ç±»å™¨ç»„\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸ“ˆ å…¶ä»–åˆ†ç±»å™¨:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, columnspan=3, sticky=tk.W, pady=(10, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        col = 0\n",
    "        other_codes = [\"knn\", \"nb\", \"lr\", \"mlp\"]\n",
    "        for code in other_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name,\n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        canvas.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        scrollbar.grid(row=1, column=3, sticky=(tk.N, tk.S))\n",
    "        \n",
    "        clf_frame.rowconfigure(1, weight=1)\n",
    "        \n",
    "        # ===== 4. æ§åˆ¶æŒ‰é’®åŒº =====\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"4. è¿è¡Œæ§åˆ¶\", padding=\"10\")\n",
    "        control_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5, padx=(0, 5))\n",
    "        \n",
    "        self.start_btn = ttk.Button(control_frame, text=\"â–¶ å¼€å§‹åˆ†ç±»\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"â¸ åœæ­¢\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"ğŸ“ æ‰“å¼€ç»“æœ\", \n",
    "                  command=self.open_result_dir, width=15).grid(\n",
    "            row=0, column=2, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"ğŸ“Š æŸ¥çœ‹æŠ¥å‘Š\", \n",
    "                  command=self.view_report, width=15).grid(\n",
    "            row=0, column=3, padx=5, pady=5\n",
    "        )\n",
    "        \n",
    "        # è¿›åº¦æ¡\n",
    "        ttk.Label(control_frame, text=\"è¿›åº¦:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100, length=400)\n",
    "        self.progress_bar.grid(row=1, column=1, columnspan=3, sticky=(tk.W, tk.E), \n",
    "                              padx=5, pady=2)\n",
    "        \n",
    "        control_frame.columnconfigure(3, weight=1)\n",
    "        \n",
    "        # ===== 5. æ—¥å¿—è¾“å‡ºåŒº =====\n",
    "        log_frame = ttk.LabelFrame(main_frame, text=\"5. è¿è¡Œæ—¥å¿—\", padding=\"10\")\n",
    "        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, \n",
    "                                                  height=18, width=120,\n",
    "                                                  font=('Consolas', 9))\n",
    "        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        log_frame.columnconfigure(0, weight=1)\n",
    "        log_frame.rowconfigure(0, weight=1)\n",
    "        \n",
    "        # çŠ¶æ€æ \n",
    "        self.status_var = tk.StringVar(value=\"å°±ç»ª | è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶å¼€å§‹\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))\n",
    "    \n",
    "    def toggle_sampling(self):\n",
    "        \"\"\"åˆ‡æ¢é‡‡æ ·åŠŸèƒ½\"\"\"\n",
    "        if self.enable_sampling.get():\n",
    "            self.max_samples_spinbox.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.max_samples_spinbox.config(state=tk.DISABLED)\n",
    "    \n",
    "    # ===== æ–‡ä»¶æµè§ˆå‡½æ•° =====\n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©å½±åƒæ–‡ä»¶\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "            self.status_var.set(f\"å·²é€‰æ‹©å½±åƒ: {Path(filename).name}\")\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©è®­ç»ƒæ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "            self.status_var.set(f\"å·²é€‰æ‹©è®­ç»ƒæ ·æœ¬: {Path(filename).name}\")\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©éªŒè¯æ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "            self.status_var.set(f\"å·²é€‰æ‹©éªŒè¯æ ·æœ¬: {Path(filename).name}\")\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"é€‰æ‹©è¾“å‡ºç›®å½•\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "            self.status_var.set(f\"è¾“å‡ºç›®å½•: {dirname}\")\n",
    "    \n",
    "    # ===== åˆ†ç±»å™¨é€‰æ‹©å‡½æ•° =====\n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        \"\"\"é€‰æ‹©æ¨èçš„åˆ†ç±»å™¨ï¼ˆç²¾åº¦å’Œé€Ÿåº¦å¹³è¡¡ï¼‰\"\"\"\n",
    "        recommended = [\"rf\", \"xgb\", \"et\", \"lgb\", \"linear_svc\", \"nystroem_svm\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "        self.status_var.set(\"å·²é€‰æ‹©æ¨èç»„åˆ: RF, XGBoost, ET, LightGBM, Linear SVM, Nystroem SVM\")\n",
    "    \n",
    "    def select_fast(self):\n",
    "        \"\"\"é€‰æ‹©å¿«é€Ÿåˆ†ç±»å™¨ï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰\"\"\"\n",
    "        fast = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"nb\", \"lr\", \"sgd_svm\", \"linear_svc\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in fast)\n",
    "        self.status_var.set(\"å·²é€‰æ‹©å¿«é€Ÿåˆ†ç±»å™¨: é€‚åˆå¤§æ•°æ®é‡å¿«é€Ÿæµ‹è¯•\")\n",
    "    \n",
    "    def select_all_svm(self):\n",
    "        \"\"\"é€‰æ‹©æ‰€æœ‰SVMå˜ä½“\"\"\"\n",
    "        svm_codes = [\"svm_linear\", \"linear_svc\", \"sgd_svm\", \"nystroem_svm\", \n",
    "                     \"rbf_sampler_svm\", \"svm_rbf\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in svm_codes)\n",
    "        self.status_var.set(\"å·²é€‰æ‹©æ‰€æœ‰SVMå˜ä½“: ç”¨äºå¯¹æ¯”ä¸åŒSVMå®ç°\")\n",
    "    \n",
    "    # ===== æ—¥å¿—ç›¸å…³å‡½æ•° =====\n",
    "    def log(self, message):\n",
    "        \"\"\"æ·»åŠ æ—¥å¿—æ¶ˆæ¯\"\"\"\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        \"\"\"æ›´æ–°æ—¥å¿—æ˜¾ç¤º\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        \n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    # ===== ä¸»è¦åŠŸèƒ½å‡½æ•° =====\n",
    "    def start_classification(self):\n",
    "        \"\"\"å¼€å§‹åˆ†ç±»\"\"\"\n",
    "        # æ£€æŸ¥è¾“å…¥\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼\")\n",
    "            return\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦è‡³å°‘é€‰æ‹©äº†ä¸€ä¸ªåˆ†ç±»å™¨\n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() \n",
    "                               if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼\")\n",
    "            return\n",
    "        \n",
    "        # æ€§èƒ½è­¦å‘Š\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        slow_clfs = []\n",
    "        very_slow_clfs = []\n",
    "        \n",
    "        for code in selected_classifiers:\n",
    "            if code in all_classifiers:\n",
    "                speed_tag = all_classifiers[code][5]\n",
    "                name = all_classifiers[code][1]\n",
    "                if speed_tag == \"very_slow\":\n",
    "                    very_slow_clfs.append(name)\n",
    "                elif speed_tag == \"slow\":\n",
    "                    slow_clfs.append(name)\n",
    "        \n",
    "        # æ˜¾ç¤ºè­¦å‘Š\n",
    "        if very_slow_clfs:\n",
    "            warning_msg = \"âš ï¸ æ€§èƒ½è­¦å‘Š\\n\\n\"\n",
    "            warning_msg += \"ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹**éå¸¸æ…¢**:\\n\"\n",
    "            for clf in very_slow_clfs:\n",
    "                warning_msg += f\"  â€¢ {clf}\\n\"\n",
    "            warning_msg += f\"\\né¢„è®¡é¢„æµ‹æ—¶é—´: >5åˆ†é’Ÿ/åˆ†ç±»å™¨\\n\\n\"\n",
    "            warning_msg += \"å»ºè®®:\\n\"\n",
    "            warning_msg += \"  â€¢ ä½¿ç”¨ 'SVM-çº¿æ€§æ ¸' æˆ– 'SGD-SVM' æ›¿ä»£\\n\"\n",
    "            warning_msg += \"  â€¢ æˆ–ä½¿ç”¨ 'æ ¸è¿‘ä¼¼SVM' è·å¾—ç±»ä¼¼æ•ˆæœ\\n\"\n",
    "            warning_msg += \"  â€¢ æˆ–å¯ç”¨æ•°æ®é‡‡æ ·å‡å°‘è®¡ç®—é‡\\n\\n\"\n",
    "            warning_msg += \"æ˜¯å¦ç»§ç»­?\"\n",
    "            \n",
    "            if not messagebox.askyesno(\"æ€§èƒ½è­¦å‘Š\", warning_msg, icon='warning'):\n",
    "                return\n",
    "        \n",
    "        # ç¦ç”¨å¼€å§‹æŒ‰é’®ï¼Œå¯ç”¨åœæ­¢æŒ‰é’®\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        # æ¸…ç©ºæ—¥å¿—\n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0 - å¼€å§‹åˆ†ç±»ä»»åŠ¡\")\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(f\"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª\")\n",
    "        \n",
    "        if self.enable_sampling.get():\n",
    "            self.log(f\"âœ“ æ•°æ®é‡‡æ ·: æœ€å¤§ {self.max_samples.get():,} ä¸ªæ ·æœ¬\")\n",
    "        if self.fast_mode.get():\n",
    "            self.log(f\"âœ“ å¿«é€Ÿæ¨¡å¼: å¯ç”¨\")\n",
    "        self.log(\"\")\n",
    "        \n",
    "        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œåˆ†ç±»\n",
    "        thread = threading.Thread(target=self.run_classification, \n",
    "                                 args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        \"\"\"åœæ­¢åˆ†ç±»\"\"\"\n",
    "        self.is_running = False\n",
    "        self.log(\"\\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...\")\n",
    "        self.status_var.set(\"å·²åœæ­¢\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"æ‰§è¡Œåˆ†ç±»ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰\"\"\"\n",
    "        try:\n",
    "            # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # 1. è¯»å–å½±åƒ\n",
    "            self.log(f\"ğŸ“ æ­£åœ¨è¯»å–å½±åƒ...\")\n",
    "            self.log(f\"   è·¯å¾„: {self.image_path.get()}\")\n",
    "            self.status_var.set(\"è¯»å–å½±åƒ...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            n_pixels = img.shape[1] * img.shape[2]\n",
    "            self.log(f\"   å°ºå¯¸: {img.shape[1]} Ã— {img.shape[2]} = {n_pixels:,} åƒå…ƒ\")\n",
    "            self.log(f\"   æ³¢æ®µæ•°: {img.rio.count}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 2. è¯»å–ç±»åˆ«ä¿¡æ¯\n",
    "            self.log(f\"\\nğŸ“Š æ­£åœ¨è¯»å–ç±»åˆ«ä¿¡æ¯...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), \n",
    "                self.class_attr.get(), \n",
    "                self.name_attr.get()\n",
    "            )\n",
    "            self.log(f\"   æ£€æµ‹åˆ° {len(class_names)} ä¸ªç±»åˆ«: {list(class_names.values())}\")\n",
    "            \n",
    "            # 3. æå–è®­ç»ƒæ ·æœ¬\n",
    "            self.log(f\"\\nğŸ¯ æ­£åœ¨å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            self.status_var.set(\"å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            \n",
    "            max_samples = self.max_samples.get() if self.enable_sampling.get() else None\n",
    "            \n",
    "            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(\n",
    "                img, train_mask, \n",
    "                ignore_background=self.ignore_background.get(),\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            self.log(f\"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"   â””â”€ ç§»é™¤NaNæ ·æœ¬: {n_nan:,}\")\n",
    "            if n_inf > 0:\n",
    "                self.log(f\"   â””â”€ ç§»é™¤Infæ ·æœ¬: {n_inf:,}\")\n",
    "            if n_sampled > 0:\n",
    "                self.log(f\"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,} (æé€Ÿä¼˜åŒ–)\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # 4. æå–éªŒè¯æ ·æœ¬\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(f\"\\nâœ… æ­£åœ¨å¤„ç†éªŒè¯æ ·æœ¬...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(img)\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}\")\n",
    "            \n",
    "            # 5. åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°\n",
    "            all_classifiers = self.backend.get_all_classifiers(\n",
    "                self.n_estimators.get(), \n",
    "                fast_mode=self.fast_mode.get(),\n",
    "                n_train_samples=len(y_train)\n",
    "            )\n",
    "            \n",
    "            comparison_results = []\n",
    "            total_start_time = time.time()\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] {clf_name}\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                self.log(f\"æè¿°: {clf_desc}\")\n",
    "                \n",
    "                # é¢„ä¼°æ—¶é—´\n",
    "                est_pred_time = self.backend.estimate_prediction_time(clf_code, n_pixels, speed_tag)\n",
    "                if est_pred_time > 60:\n",
    "                    self.log(f\"â±ï¸  é¢„è®¡é¢„æµ‹æ—¶é—´: ~{est_pred_time/60:.1f} åˆ†é’Ÿ\")\n",
    "                elif est_pred_time > 10:\n",
    "                    self.log(f\"â±ï¸  é¢„è®¡é¢„æµ‹æ—¶é—´: ~{est_pred_time:.0f} ç§’\")\n",
    "                \n",
    "                self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] è®­ç»ƒ {clf_name}...\")\n",
    "                \n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # æ•°æ®é¢„å¤„ç†\n",
    "                    label_encoder = None\n",
    "                    scaler = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    if needs_encoding:\n",
    "                        self.log(\"   ğŸ”„ åº”ç”¨æ ‡ç­¾ç¼–ç ...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    if needs_scaling:\n",
    "                        self.log(\"   ğŸ“ åº”ç”¨ç‰¹å¾ç¼©æ”¾...\")\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_use = scaler.fit_transform(X_train_use)\n",
    "                    \n",
    "                    # è®­ç»ƒ\n",
    "                    self.log(\"   ğŸ”¨ è®­ç»ƒä¸­...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f} ç§’\")\n",
    "                    \n",
    "                    # è®­ç»ƒé›†ç²¾åº¦\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}, \"\n",
    "                           f\"Kappa: {train_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # é¢„æµ‹æ•´å¹…å½±åƒ\n",
    "                    self.log(\"   ğŸ—ºï¸  é¢„æµ‹æ•´å¹…å½±åƒ...\")\n",
    "                    self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] é¢„æµ‹ {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f} ç§’\")\n",
    "                    \n",
    "                    # éªŒè¯é›†ç²¾åº¦\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "                    if val_exists:\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}, \"\n",
    "                               f\"Kappa: {val_metrics['kappa']:.4f}\")\n",
    "                    \n",
    "                    # è®°å½•ç»“æœ\n",
    "                    result = {\n",
    "                        'åˆ†ç±»å™¨ä»£ç ': clf_code,\n",
    "                        'åˆ†ç±»å™¨åç§°': clf_name,\n",
    "                        'é€Ÿåº¦ç­‰çº§': speed_tag,\n",
    "                        'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],\n",
    "                        'è®­ç»ƒé›†Kappa': train_metrics['kappa'],\n",
    "                        'è®­ç»ƒé›†F1': train_metrics['f1_macro'],\n",
    "                        'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],\n",
    "                        'éªŒè¯é›†Kappa': val_metrics['kappa'],\n",
    "                        'éªŒè¯é›†F1': val_metrics['f1_macro'],\n",
    "                        'è®­ç»ƒæ—¶é—´(ç§’)': train_time,\n",
    "                        'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,\n",
    "                        'æ€»æ—¶é—´(ç§’)': train_time + pred_time\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    \n",
    "                    self.log(f\"   âœ… {clf_name} å®Œæˆ!\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"   âŒ {clf_name} å¤±è´¥: {str(e)}\")\n",
    "                    import traceback\n",
    "                    self.log(f\"   {traceback.format_exc()}\")\n",
    "                    continue\n",
    "                \n",
    "                # æ›´æ–°æ€»è¿›åº¦\n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # 6. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š\n",
    "            if comparison_results and self.is_running:\n",
    "                total_time = time.time() - total_start_time\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"ğŸ“ ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...\")\n",
    "                self.status_var.set(\"ç”ŸæˆæŠ¥å‘Š...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"=\"*70 + \"\\n\")\n",
    "                    f.write(\"        é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\\n\")\n",
    "                    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(f\"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                    f.write(f\"å½±åƒå°ºå¯¸: {img.shape[1]} Ã— {img.shape[2]} = {n_pixels:,} åƒå…ƒ\\n\")\n",
    "                    f.write(f\"è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}\\n\")\n",
    "                    if val_exists:\n",
    "                        f.write(f\"éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}\\n\")\n",
    "                    f.write(f\"ç±»åˆ«æ•°é‡: {len(class_names)}\\n\")\n",
    "                    f.write(f\"æ€§èƒ½ä¼˜åŒ–: é‡‡æ ·={self.enable_sampling.get()}, \"\n",
    "                           f\"å¿«é€Ÿæ¨¡å¼={self.fast_mode.get()}\\n\")\n",
    "                    f.write(f\"æˆåŠŸå®Œæˆ: {len(comparison_results)}/{len(selected_classifiers)} ä¸ªåˆ†ç±»å™¨\\n\")\n",
    "                    f.write(f\"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\\n\\n\")\n",
    "                    \n",
    "                    # ç²¾åº¦æ’å\n",
    "                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    f.write(\"ğŸ“Š éªŒè¯é›†ç²¾åº¦æ’å:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx:2d}. {row['åˆ†ç±»å™¨åç§°']:18s} - \"\n",
    "                               f\"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}, \"\n",
    "                               f\"Kappa: {row['éªŒè¯é›†Kappa']:.4f}, \"\n",
    "                               f\"F1: {row['éªŒè¯é›†F1']:.4f}\\n\")\n",
    "                    \n",
    "                    # é€Ÿåº¦æ’å\n",
    "                    f.write(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "                    f.write(\"âš¡ æ€»æ—¶é—´æ’åï¼ˆè®­ç»ƒ+é¢„æµ‹ï¼‰:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    sorted_time = comparison_df.sort_values('æ€»æ—¶é—´(ç§’)')\n",
    "                    for idx, (_, row) in enumerate(sorted_time.iterrows(), 1):\n",
    "                        f.write(f\"{idx:2d}. {row['åˆ†ç±»å™¨åç§°']:18s} - \"\n",
    "                               f\"{row['æ€»æ—¶é—´(ç§’)']:7.2f}ç§’ \"\n",
    "                               f\"(è®­ç»ƒ: {row['è®­ç»ƒæ—¶é—´(ç§’)']:6.2f}s, \"\n",
    "                               f\"é¢„æµ‹: {row['é¢„æµ‹æ—¶é—´(ç§’)']:6.2f}s)\\n\")\n",
    "                    \n",
    "                    # é€Ÿåº¦åˆ†ç±»ç»Ÿè®¡\n",
    "                    f.write(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "                    f.write(\"ğŸ“ˆ é€Ÿåº¦åˆ†ç±»ç»Ÿè®¡:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    speed_stats = comparison_df.groupby('é€Ÿåº¦ç­‰çº§').agg({\n",
    "                        'åˆ†ç±»å™¨åç§°': 'count',\n",
    "                        'éªŒè¯é›†ç²¾åº¦': 'mean',\n",
    "                        'æ€»æ—¶é—´(ç§’)': 'mean'\n",
    "                    }).round(4)\n",
    "                    f.write(speed_stats.to_string())\n",
    "                    \n",
    "                    # æ¨è\n",
    "                    f.write(\"\\n\\n\" + \"=\"*70 + \"\\n\")\n",
    "                    f.write(\"ğŸ’¡ æ¨è:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    \n",
    "                    best_acc = sorted_df.iloc[0]\n",
    "                    f.write(f\"ğŸ† æœ€é«˜ç²¾åº¦: {best_acc['åˆ†ç±»å™¨åç§°']} \"\n",
    "                           f\"(ç²¾åº¦: {best_acc['éªŒè¯é›†ç²¾åº¦']:.4f}, \"\n",
    "                           f\"æ—¶é—´: {best_acc['æ€»æ—¶é—´(ç§’)']:.2f}ç§’)\\n\")\n",
    "                    \n",
    "                    best_speed = sorted_time.iloc[0]\n",
    "                    f.write(f\"âš¡ æœ€å¿«é€Ÿåº¦: {best_speed['åˆ†ç±»å™¨åç§°']} \"\n",
    "                           f\"(æ—¶é—´: {best_speed['æ€»æ—¶é—´(ç§’)']:.2f}ç§’, \"\n",
    "                           f\"ç²¾åº¦: {best_speed['éªŒè¯é›†ç²¾åº¦']:.4f})\\n\")\n",
    "                    \n",
    "                    # ç»¼åˆè¯„åˆ†\n",
    "                    comparison_df['ç»¼åˆå¾—åˆ†'] = (\n",
    "                        comparison_df['éªŒè¯é›†ç²¾åº¦'] * 0.7 + \n",
    "                        (1 - comparison_df['æ€»æ—¶é—´(ç§’)'] / comparison_df['æ€»æ—¶é—´(ç§’)'].max()) * 0.3\n",
    "                    )\n",
    "                    best_overall = comparison_df.loc[comparison_df['ç»¼åˆå¾—åˆ†'].idxmax()]\n",
    "                    f.write(f\"â­ ç»¼åˆæœ€ä½³: {best_overall['åˆ†ç±»å™¨åç§°']} \"\n",
    "                           f\"(ç²¾åº¦: {best_overall['éªŒè¯é›†ç²¾åº¦']:.4f}, \"\n",
    "                           f\"æ—¶é—´: {best_overall['æ€»æ—¶é—´(ç§’)']:.2f}ç§’, \"\n",
    "                           f\"å¾—åˆ†: {best_overall['ç»¼åˆå¾—åˆ†']:.4f})\\n\")\n",
    "                \n",
    "                self.log(\"âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!\")\n",
    "                self.log(f\"ğŸ“ ç»“æœä¿å­˜è‡³: {out_dir.absolute()}\")\n",
    "                self.log(f\"ğŸ“Š æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)} ä¸ªåˆ†ç±»å™¨\")\n",
    "                self.log(f\"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\")\n",
    "                \n",
    "                # æ˜¾ç¤ºæœ€ä½³ç»“æœ\n",
    "                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]\n",
    "                self.log(f\"\\nğŸ† æœ€ä½³ç²¾åº¦: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\")\n",
    "                \n",
    "                self.status_var.set(f\"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\")\n",
    "                \n",
    "                messagebox.showinfo(\"ä»»åŠ¡å®Œæˆ\", \n",
    "                    f\"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\\n\\n\"\n",
    "                    f\"âœ… æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\\n\"\n",
    "                    f\"ğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\\n\"\n",
    "                    f\"â±ï¸  è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\\n\\n\"\n",
    "                    f\"ğŸ“ ç»“æœ: {out_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\nâŒ é”™è¯¯: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"é”™è¯¯\", f\"å‘ç”Ÿé”™è¯¯:\\n{str(e)}\")\n",
    "            self.status_var.set(\"âŒ é”™è¯¯\")\n",
    "        \n",
    "        finally:\n",
    "            # æ¢å¤æŒ‰é’®çŠ¶æ€\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"æ‰“å¼€ç»“æœç›®å½•\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"ç»“æœç›®å½•ä¸å­˜åœ¨ï¼\")\n",
    "    \n",
    "    def view_report(self):\n",
    "        \"\"\"æŸ¥çœ‹å¯¹æ¯”æŠ¥å‘Š\"\"\"\n",
    "        report_file = Path(self.output_dir.get()) / \"comparison_summary.txt\"\n",
    "        if report_file.exists():\n",
    "            # åˆ›å»ºæ–°çª—å£æ˜¾ç¤ºæŠ¥å‘Š\n",
    "            report_window = tk.Toplevel(self.root)\n",
    "            report_window.title(\"ğŸ“Š åˆ†ç±»å™¨å¯¹æ¯”æŠ¥å‘Š\")\n",
    "            report_window.geometry(\"900x700\")\n",
    "            \n",
    "            # æ·»åŠ å·¥å…·æ \n",
    "            toolbar = ttk.Frame(report_window)\n",
    "            toolbar.pack(side=tk.TOP, fill=tk.X, padx=5, pady=5)\n",
    "            \n",
    "            ttk.Button(toolbar, text=\"ğŸ“ æ‰“å¼€CSV\", \n",
    "                      command=lambda: os.startfile(\n",
    "                          Path(self.output_dir.get()) / \"classifier_comparison.csv\"\n",
    "                      )).pack(side=tk.LEFT, padx=2)\n",
    "            \n",
    "            ttk.Button(toolbar, text=\"ğŸ”„ åˆ·æ–°\", \n",
    "                      command=lambda: self.refresh_report(text_widget, report_file)).pack(\n",
    "                side=tk.LEFT, padx=2)\n",
    "            \n",
    "            # æ–‡æœ¬æ˜¾ç¤ºåŒºåŸŸ\n",
    "            text_widget = scrolledtext.ScrolledText(report_window, wrap=tk.WORD,\n",
    "                                                   font=('Consolas', 10))\n",
    "            text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "            \n",
    "            with open(report_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                text_widget.insert(1.0, content)\n",
    "            \n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨ï¼\\nè¯·å…ˆè¿è¡Œåˆ†ç±»ä»»åŠ¡ã€‚\")\n",
    "    \n",
    "    def refresh_report(self, text_widget, report_file):\n",
    "        \"\"\"åˆ·æ–°æŠ¥å‘Šæ˜¾ç¤º\"\"\"\n",
    "        text_widget.config(state=tk.NORMAL)\n",
    "        text_widget.delete(1.0, tk.END)\n",
    "        \n",
    "        with open(report_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            text_widget.insert(1.0, content)\n",
    "        \n",
    "        text_widget.config(state=tk.DISABLED)\n",
    "\n",
    "# ==================== ä¸»ç¨‹åºå…¥å£ ====================\n",
    "def main():\n",
    "    \"\"\"ç¨‹åºå…¥å£\"\"\"\n",
    "    root = tk.Tk()\n",
    "    \n",
    "    # è®¾ç½®å›¾æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰\n",
    "    # root.iconbitmap('icon.ico')\n",
    "    \n",
    "    app = ClassificationGUI(root)\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"æ”¯æŒçš„åˆ†ç±»å™¨:\")\n",
    "    app.log(\"  ğŸ“Š SVMç³»åˆ—: çº¿æ€§æ ¸ã€RBFæ ¸ã€SGD-SVMã€æ ¸è¿‘ä¼¼ç­‰\")\n",
    "    app.log(\"  ğŸŒ² æ ‘æ¨¡å‹: RFã€XGBoostã€LightGBMã€ETã€GBã€DTç­‰\")\n",
    "    app.log(\"  ğŸ“ˆ å…¶ä»–: KNNã€æœ´ç´ è´å¶æ–¯ã€é€»è¾‘å›å½’ã€ç¥ç»ç½‘ç»œç­‰\")\n",
    "    app.log(\"\")\n",
    "    app.log(\"ä¼˜åŒ–ç‰¹æ€§:\")\n",
    "    app.log(\"  âš¡ æ•°æ®é‡‡æ · - åŠ å¿«è®­ç»ƒé€Ÿåº¦\")\n",
    "    app.log(\"  ğŸ“ ç‰¹å¾ç¼©æ”¾ - æå‡SVM/KNNæ€§èƒ½\")\n",
    "    app.log(\"  ğŸš€ å¿«é€Ÿæ¨¡å¼ - å‡å°‘æ¨¡å‹å¤æ‚åº¦\")\n",
    "    app.log(\"  âš ï¸  æ€§èƒ½è­¦å‘Š - é¿å…é€‰æ‹©æ…¢é€Ÿåˆ†ç±»å™¨\")\n",
    "    app.log(\"\")\n",
    "    app.log(\"ğŸ’¡ æç¤º: ç‚¹å‡»ä¸Šæ–¹'âœ“æ¨èç»„åˆ'æˆ–'âš¡å¿«é€Ÿåˆ†ç±»å™¨'å¿«é€Ÿé€‰æ‹©\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"\")\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28af57",
   "metadata": {},
   "source": [
    "# ç‰ˆæœ¬2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0.1\n",
      "================================================================================\n",
      "\n",
      "æ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...\n",
      "âœ“ XGBoost å¯ç”¨\n",
      "âœ“ LightGBM å¯ç”¨\n",
      "\n",
      "âœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!\n",
      "è¯·åœ¨GUIç•Œé¢ä¸­æ“ä½œ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (run_classification):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_109364\\1781054574.py\", line 1080, in run_classification\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 402, in set\n",
      "    return self._tk.globalsetvar(self._name, value)\n",
      "RuntimeError: main thread is not in main loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_109364\\1781054574.py\", line 1253, in run_classification\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 402, in set\n",
      "    return self._tk.globalsetvar(self._name, value)\n",
      "RuntimeError: main thread is not in main loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\geog_2025\\envi\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"D:\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\xyt556\\AppData\\Local\\Temp\\7\\ipykernel_109364\\1781054574.py\", line 1256, in run_classification\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 1675, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 1665, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Variable.__del__ at 0x000002872C888550>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python310\\lib\\tkinter\\__init__.py\", line 388, in __del__\n",
      "    if self._tk.getboolean(self._tk.call(\"info\", \"exists\", self._name)):\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - å®Œæ•´ç‰ˆ\n",
    "=====================================\n",
    "ç‰ˆæœ¬: v3.0.1 (é”™è¯¯ä¿®å¤ç‰ˆ)\n",
    "ä½œè€…: AI Assistant\n",
    "æ—¥æœŸ: 2024\n",
    "\n",
    "ä¸»è¦ç‰¹æ€§:\n",
    "- 15+ç§åˆ†ç±»å™¨ï¼ˆåŒ…å«6ç§SVMå˜ä½“ï¼‰\n",
    "- æ™ºèƒ½æ€§èƒ½ä¼˜åŒ–ï¼ˆé‡‡æ ·ã€ç‰¹å¾ç¼©æ”¾ã€å¿«é€Ÿæ¨¡å¼ï¼‰\n",
    "- å®Œå–„çš„é”™è¯¯å¤„ç†\n",
    "- å›¾å½¢åŒ–ç•Œé¢\n",
    "- è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š\n",
    "\n",
    "ä½¿ç”¨è¯´æ˜:\n",
    "1. å®‰è£…ä¾èµ–: pip install numpy pandas matplotlib seaborn geopandas rioxarray scikit-learn xgboost\n",
    "2. è¿è¡Œç¨‹åº: python classification_system_v3.py\n",
    "3. æŒ‰ç•Œé¢æç¤ºæ“ä½œ\n",
    "\n",
    "æ³¨æ„äº‹é¡¹:\n",
    "- XGBoost å’Œ LightGBM ä¸ºå¯é€‰ä¾èµ–ï¼Œæœªå®‰è£…ä¸å½±å“å…¶ä»–åˆ†ç±»å™¨ä½¿ç”¨\n",
    "- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒè¿è¡Œ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.kernel_approximation import Nystroem, RBFSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ==================== åç«¯å¤„ç†ç±» ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"åˆ†ç±»å¤„ç†åç«¯ï¼ˆå®Œå…¨ä¼˜åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.BACKGROUND_VALUE = 0\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # é¢„å®šä¹‰é¢œè‰²\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"æ°´ä½“\": \"lightblue\", \"æ²³æµ\": \"blue\", \"æ¹–æ³Š\": \"deepskyblue\",\n",
    "            \"æ¤è¢«\": \"forestgreen\", \"æ£®æ—\": \"darkgreen\", \"è‰åœ°\": \"limegreen\",\n",
    "            \"å†œç”°\": \"yellowgreen\", \"è€•åœ°\": \"olivedrab\",\n",
    "            \"å»ºç­‘\": \"gray\", \"åŸå¸‚\": \"dimgray\", \"å±…æ°‘åœ°\": \"slategray\",\n",
    "            \"è£¸åœ°\": \"tan\", \"æ²™åœ°\": \"wheat\", \"å…¶ä»–\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "        \n",
    "        # æ£€æŸ¥å¯é€‰åº“çš„å¯ç”¨æ€§\n",
    "        self.check_optional_libraries()\n",
    "    \n",
    "    def check_optional_libraries(self):\n",
    "        \"\"\"æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨\"\"\"\n",
    "        self.has_xgboost = False\n",
    "        self.has_lightgbm = False\n",
    "        \n",
    "        # æ£€æŸ¥ XGBoost\n",
    "        try:\n",
    "            import xgboost\n",
    "            from xgboost import XGBClassifier\n",
    "            # æµ‹è¯•èƒ½å¦æ­£å¸¸å®ä¾‹åŒ–\n",
    "            _ = XGBClassifier(n_estimators=10, verbosity=0)\n",
    "            self.has_xgboost = True\n",
    "            print(\"âœ“ XGBoost å¯ç”¨\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— XGBoost ä¸å¯ç”¨: {type(e).__name__}\")\n",
    "            self.has_xgboost = False\n",
    "        \n",
    "        # æ£€æŸ¥ LightGBMï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰\n",
    "        try:\n",
    "            import lightgbm\n",
    "            from lightgbm import LGBMClassifier\n",
    "            # æµ‹è¯•èƒ½å¦æ­£å¸¸å®ä¾‹åŒ–\n",
    "            _ = LGBMClassifier(n_estimators=10, verbose=-1)\n",
    "            self.has_lightgbm = True\n",
    "            print(\"âœ“ LightGBM å¯ç”¨\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— LightGBM ä¸å¯ç”¨: {type(e).__name__}\")\n",
    "            self.has_lightgbm = False\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨\n",
    "        \n",
    "        è¿”å›æ ¼å¼: {code: (classifier, name, desc, needs_encoding, needs_scaling, speed_tag)}\n",
    "        \"\"\"\n",
    "        # æ ¹æ®æ¨¡å¼è°ƒæ•´å‚æ•°\n",
    "        if fast_mode:\n",
    "            n_est = min(50, n_estimators)\n",
    "            max_depth = 10\n",
    "            max_iter = 200\n",
    "        else:\n",
    "            n_est = n_estimators\n",
    "            max_depth = 20\n",
    "            max_iter = 500\n",
    "        \n",
    "        # æ ¸è¿‘ä¼¼çš„ç»„ä»¶æ•°\n",
    "        if n_train_samples:\n",
    "            n_components = min(1000, n_train_samples // 2)\n",
    "        else:\n",
    "            n_components = 1000\n",
    "        \n",
    "        classifiers = {\n",
    "            # ===== æ ‘æ¨¡å‹ç³»åˆ— =====\n",
    "            \"rf\": (\n",
    "                RandomForestClassifier(\n",
    "                    n_estimators=n_est, \n",
    "                    n_jobs=-1, \n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"éšæœºæ£®æ—\", \"Random Forest - ç¨³å®šå¯é \", \n",
    "                False, False, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"et\": (\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                \"æç«¯éšæœºæ ‘\", \"Extra Trees - æ›´å¿«çš„RF\", \n",
    "                False, False, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"dt\": (\n",
    "                DecisionTreeClassifier(\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=5,\n",
    "                    min_samples_leaf=2\n",
    "                ),\n",
    "                \"å†³ç­–æ ‘\", \"Decision Tree - ç®€å•å¿«é€Ÿ\", \n",
    "                False, False, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            # ===== SVMç³»åˆ— =====\n",
    "            \"svm_linear\": (\n",
    "                SVC(\n",
    "                    kernel=\"linear\",\n",
    "                    C=1.0,\n",
    "                    cache_size=500,\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    max_iter=max_iter\n",
    "                ),\n",
    "                \"SVM-çº¿æ€§æ ¸\", \"SVM Linear\", \n",
    "                False, True, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"linear_svc\": (\n",
    "                CalibratedClassifierCV(\n",
    "                    LinearSVC(\n",
    "                        C=1.0,\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE,\n",
    "                        dual=False,\n",
    "                        loss='squared_hinge'\n",
    "                    ),\n",
    "                    cv=3\n",
    "                ),\n",
    "                \"çº¿æ€§SVM(å¿«)\", \"Linear SVM - å¿«é€Ÿç‰ˆ\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"sgd_svm\": (\n",
    "                SGDClassifier(\n",
    "                    loss='hinge',\n",
    "                    penalty='l2',\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    learning_rate='optimal'\n",
    "                ),\n",
    "                \"SGD-SVM\", \"SGD SVM - æå¿«\", \n",
    "                False, True, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"nystroem_svm\": (\n",
    "                Pipeline([\n",
    "                    (\"feature_map\", Nystroem(\n",
    "                        kernel='rbf',\n",
    "                        gamma=0.1,\n",
    "                        n_components=n_components,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    )),\n",
    "                    (\"sgd\", SGDClassifier(\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    ))\n",
    "                ]),\n",
    "                \"æ ¸è¿‘ä¼¼SVM\", \"Nystroem - RBFè¿‘ä¼¼\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"rbf_sampler_svm\": (\n",
    "                Pipeline([\n",
    "                    (\"feature_map\", RBFSampler(\n",
    "                        gamma=0.1,\n",
    "                        n_components=n_components,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    )),\n",
    "                    (\"sgd\", SGDClassifier(\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=self.RANDOM_STATE\n",
    "                    ))\n",
    "                ]),\n",
    "                \"RBFé‡‡æ ·SVM\", \"RBF Sampler\", \n",
    "                False, True, \"fast\"\n",
    "            ),\n",
    "            \n",
    "            \"svm_rbf\": (\n",
    "                SVC(\n",
    "                    kernel=\"rbf\", \n",
    "                    C=1.0,\n",
    "                    gamma='scale',\n",
    "                    cache_size=500,\n",
    "                    probability=True, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                ),\n",
    "                \"SVM-RBFæ ¸âš ï¸\", \"SVM RBF - æ…¢ä½†ç²¾ç¡®\", \n",
    "                False, True, \"very_slow\"\n",
    "            ),\n",
    "            \n",
    "            # ===== å…¶ä»–åˆ†ç±»å™¨ =====\n",
    "            \"knn\": (\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=5,\n",
    "                    n_jobs=-1,\n",
    "                    algorithm='ball_tree',\n",
    "                    leaf_size=30\n",
    "                ),\n",
    "                \"Kè¿‘é‚»\", \"KNN\", \n",
    "                False, True, \"slow\"\n",
    "            ),\n",
    "            \n",
    "            \"nb\": (\n",
    "                GaussianNB(),\n",
    "                \"æœ´ç´ è´å¶æ–¯\", \"Naive Bayes - æœ€å¿«\", \n",
    "                False, False, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"gb\": (\n",
    "                GradientBoostingClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=5,\n",
    "                    random_state=self.RANDOM_STATE, \n",
    "                    verbose=0,\n",
    "                    subsample=0.8\n",
    "                ),\n",
    "                \"æ¢¯åº¦æå‡\", \"Gradient Boosting\", \n",
    "                False, False, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"ada\": (\n",
    "                AdaBoostClassifier(\n",
    "                    n_estimators=n_est,\n",
    "                    learning_rate=1.0,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    algorithm='SAMME.R'\n",
    "                ),\n",
    "                \"AdaBoost\", \"AdaBoost\", \n",
    "                False, False, \"medium\"\n",
    "            ),\n",
    "            \n",
    "            \"lr\": (\n",
    "                LogisticRegression(\n",
    "                    max_iter=max_iter,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=0,\n",
    "                    solver='lbfgs',\n",
    "                    multi_class='multinomial'\n",
    "                ),\n",
    "                \"é€»è¾‘å›å½’\", \"Logistic Regression\", \n",
    "                False, True, \"very_fast\"\n",
    "            ),\n",
    "            \n",
    "            \"mlp\": (\n",
    "                MLPClassifier(\n",
    "                    hidden_layer_sizes=(100, 50),\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=self.RANDOM_STATE,\n",
    "                    verbose=False,\n",
    "                    early_stopping=True,\n",
    "                    validation_fraction=0.1,\n",
    "                    n_iter_no_change=10,\n",
    "                    learning_rate='adaptive'\n",
    "                ),\n",
    "                \"ç¥ç»ç½‘ç»œ\", \"MLP\", \n",
    "                False, True, \"medium\"\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        # æ·»åŠ  XGBoostï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "        if self.has_xgboost:\n",
    "            try:\n",
    "                from xgboost import XGBClassifier\n",
    "                classifiers[\"xgb\"] = (\n",
    "                    XGBClassifier(\n",
    "                        n_estimators=n_est,\n",
    "                        learning_rate=0.1,\n",
    "                        max_depth=6,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=self.RANDOM_STATE,\n",
    "                        verbosity=0,\n",
    "                        tree_method='hist',\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8\n",
    "                    ),\n",
    "                    \"XGBoost\", \"XGBoost - é«˜æ€§èƒ½\", \n",
    "                    True, False, \"fast\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  XGBoost å®ä¾‹åŒ–å¤±è´¥: {e}\")\n",
    "        \n",
    "        # æ·»åŠ  LightGBMï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "        if self.has_lightgbm:\n",
    "            try:\n",
    "                from lightgbm import LGBMClassifier\n",
    "                classifiers[\"lgb\"] = (\n",
    "                    LGBMClassifier(\n",
    "                        n_estimators=n_est,\n",
    "                        learning_rate=0.1,\n",
    "                        max_depth=max_depth,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=self.RANDOM_STATE,\n",
    "                        verbose=-1,\n",
    "                        num_leaves=31,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.8,\n",
    "                        force_col_wise=True  # é¿å…è­¦å‘Š\n",
    "                    ),\n",
    "                    \"LightGBM\", \"LightGBM - æé€Ÿ\", \n",
    "                    False, False, \"very_fast\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  LightGBM å®ä¾‹åŒ–å¤±è´¥: {e}\")\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image):\n",
    "        \"\"\"è·å–èƒŒæ™¯æ©è†œ\"\"\"\n",
    "        data = image.values\n",
    "        background_mask = np.all(data == 0, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"Class_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in class_name:\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"çŸ¢é‡æ …æ ¼åŒ–\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=ref_img.shape[1:],\n",
    "            transform=ref_img.rio.transform(),\n",
    "            fill=0,\n",
    "            all_touched=True,\n",
    "            dtype=\"uint16\"\n",
    "        )\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True, max_samples=None):\n",
    "        \"\"\"æå–æ ·æœ¬å¹¶æ¸…ç†NaNå€¼ï¼Œå¯é€‰åˆ†å±‚é‡‡æ ·\"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # æ¸…ç†NaNå’ŒInfå€¼\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        bad_mask = nan_mask | inf_mask\n",
    "        \n",
    "        n_nan = np.sum(nan_mask)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        X = X[~bad_mask]\n",
    "        y = y[~bad_mask]\n",
    "        \n",
    "        # åˆ†å±‚é‡‡æ ·\n",
    "        n_sampled = 0\n",
    "        if max_samples is not None and len(y) > max_samples:\n",
    "            n_original = len(y)\n",
    "            unique_classes = np.unique(y)\n",
    "            \n",
    "            if len(unique_classes) > 1:\n",
    "                splitter = StratifiedShuffleSplit(\n",
    "                    n_splits=1, \n",
    "                    train_size=max_samples, \n",
    "                    random_state=self.RANDOM_STATE\n",
    "                )\n",
    "                sample_idx, _ = next(splitter.split(X, y))\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "            else:\n",
    "                np.random.seed(self.RANDOM_STATE)\n",
    "                sample_idx = np.random.choice(len(y), max_samples, replace=False)\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "        \n",
    "        return X, y, n_nan, n_inf, n_sampled\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"è®¡ç®—è¯„ä»·æŒ‡æ ‡\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):\n",
    "        \"\"\"ä¼°ç®—é¢„æµ‹æ—¶é—´ï¼ˆç§’ï¼‰\"\"\"\n",
    "        time_per_million_pixels = {\n",
    "            \"very_fast\": 1,\n",
    "            \"fast\": 3,\n",
    "            \"medium\": 10,\n",
    "            \"slow\": 30,\n",
    "            \"very_slow\": 300\n",
    "        }\n",
    "        base_time = time_per_million_pixels.get(speed_tag, 10)\n",
    "        return (n_pixels / 1_000_000) * base_time\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, progress_callback=None,\n",
    "                        label_encoder=None, scaler=None):\n",
    "        \"\"\"åˆ†å—é¢„æµ‹\"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], \n",
    "                                                   nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    if scaler is not None:\n",
    "                        data_to_predict = scaler.transform(data_to_predict)\n",
    "                    \n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    data_flat = scaler.transform(data_flat)\n",
    "                \n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        prediction_da = xr.DataArray(\n",
    "            prediction,\n",
    "            dims=['y', 'x'],\n",
    "            coords={'y': image.coords['y'], 'x': image.coords['x']}\n",
    "        )\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(self.BACKGROUND_VALUE, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUIä¸»ç±» ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0.1\")\n",
    "        self.root.geometry(\"1450x950\")\n",
    "        \n",
    "        # åç«¯å¤„ç†å¯¹è±¡\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # æ•°æ®å˜é‡\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        self.class_attr = tk.StringVar(value=\"class\")\n",
    "        self.name_attr = tk.StringVar(value=\"name\")\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "        self.enable_sampling = tk.BooleanVar(value=True)\n",
    "        self.max_samples = tk.IntVar(value=50000)\n",
    "        self.fast_mode = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # åˆ†ç±»å™¨é€‰æ‹©\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code in all_classifiers.keys():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # è¿è¡ŒçŠ¶æ€\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # æ„å»ºç•Œé¢\n",
    "        self.build_ui()\n",
    "        \n",
    "        # å¯åŠ¨æ—¥å¿—æ›´æ–°\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"æ„å»ºç”¨æˆ·ç•Œé¢\"\"\"\n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.rowconfigure(0, weight=1)\n",
    "        main_frame.columnconfigure(1, weight=1)\n",
    "        main_frame.rowconfigure(3, weight=1)\n",
    "        \n",
    "        # 1. æ–‡ä»¶é€‰æ‹©åŒº\n",
    "        file_frame = ttk.LabelFrame(main_frame, text=\"1. æ•°æ®è¾“å…¥\", padding=\"10\")\n",
    "        file_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"å½±åƒæ–‡ä»¶:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=65).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_image).grid(row=0, column=2, padx=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è®­ç»ƒæ ·æœ¬:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=65).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_train_shp).grid(row=1, column=2, padx=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"éªŒè¯æ ·æœ¬:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=65).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_val_shp).grid(row=2, column=2, padx=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è¾“å‡ºç›®å½•:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=65).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_output).grid(row=3, column=2, padx=5)\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # 2. å‚æ•°è®¾ç½®åŒº\n",
    "        param_frame = ttk.LabelFrame(main_frame, text=\"2. å‚æ•°é…ç½®\", padding=\"10\")\n",
    "        param_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N), pady=5, padx=(0, 5))\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"ç±»åˆ«ç¼–å·å­—æ®µ:\").grid(row=0, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.class_attr, width=15).grid(\n",
    "            row=0, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"ç±»åˆ«åç§°å­—æ®µ:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Entry(param_frame, textvariable=self.name_attr, width=15).grid(\n",
    "            row=1, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"æ ‘æ¨¡å‹æ•°é‡:\").grid(row=2, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=13).grid(row=2, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"åˆ†å—å¤§å°:\").grid(row=3, column=0, sticky=tk.W, pady=2)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=13).grid(\n",
    "            row=3, column=1, sticky=tk.W, padx=5\n",
    "        )\n",
    "        \n",
    "        # æ€§èƒ½ä¼˜åŒ–é€‰é¡¹\n",
    "        ttk.Separator(param_frame, orient='horizontal').grid(\n",
    "            row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=8\n",
    "        )\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"âš¡ æ€§èƒ½ä¼˜åŒ–:\", font=('', 9, 'bold')).grid(\n",
    "            row=5, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        sample_frame = ttk.Frame(param_frame)\n",
    "        sample_frame.grid(row=6, column=0, columnspan=2, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        ttk.Checkbutton(sample_frame, text=\"å¯ç”¨é‡‡æ ·\", \n",
    "                       variable=self.enable_sampling,\n",
    "                       command=self.toggle_sampling).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Label(sample_frame, text=\"  æœ€å¤§æ ·æœ¬æ•°:\").pack(side=tk.LEFT, padx=(10, 0))\n",
    "        self.max_samples_spinbox = ttk.Spinbox(\n",
    "            sample_frame, from_=10000, to=200000, increment=10000,\n",
    "            textvariable=self.max_samples, width=10\n",
    "        )\n",
    "        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"å¿«é€Ÿæ¨¡å¼\", variable=self.fast_mode).grid(\n",
    "            row=7, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        ttk.Checkbutton(param_frame, text=\"å¿½ç•¥èƒŒæ™¯å€¼\", variable=self.ignore_background).grid(\n",
    "            row=8, column=0, columnspan=2, sticky=tk.W, pady=2\n",
    "        )\n",
    "        \n",
    "        # 3. åˆ†ç±»å™¨é€‰æ‹©åŒº\n",
    "        clf_frame = ttk.LabelFrame(main_frame, text=\"3. åˆ†ç±»å™¨é€‰æ‹©\", padding=\"10\")\n",
    "        clf_frame.grid(row=1, column=1, rowspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.grid(row=0, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 5))\n",
    "        \n",
    "        ttk.Button(btn_frame, text=\"å…¨é€‰\", command=self.select_all_classifiers, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"å…¨ä¸é€‰\", command=self.deselect_all_classifiers, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âœ“æ¨è\", command=self.select_recommended, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âš¡å¿«é€Ÿ\", command=self.select_fast, \n",
    "                  width=12).pack(side=tk.LEFT, padx=2)\n",
    "        \n",
    "        # æ»šåŠ¨åŒºåŸŸ\n",
    "        canvas = tk.Canvas(clf_frame, height=200)\n",
    "        scrollbar = ttk.Scrollbar(clf_frame, orient=\"vertical\", command=canvas.yview)\n",
    "        scrollable_frame = ttk.Frame(canvas)\n",
    "        \n",
    "        scrollable_frame.bind(\n",
    "            \"<Configure>\",\n",
    "            lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "        )\n",
    "        \n",
    "        canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        \n",
    "        # SVMç»„\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸ“Š SVMç³»åˆ—:\", font=('', 9, 'bold')).grid(\n",
    "            row=0, column=0, columnspan=3, sticky=tk.W, pady=(5, 2)\n",
    "        )\n",
    "        row = 1\n",
    "        col = 0\n",
    "        svm_codes = [\"svm_linear\", \"linear_svc\", \"sgd_svm\", \"nystroem_svm\", \n",
    "                     \"rbf_sampler_svm\", \"svm_rbf\"]\n",
    "        for code in svm_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name, \n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        if col > 0:\n",
    "            row += 1\n",
    "        \n",
    "        # æ ‘æ¨¡å‹ç»„\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸŒ² æ ‘æ¨¡å‹:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, columnspan=3, sticky=tk.W, pady=(10, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        col = 0\n",
    "        tree_codes = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"gb\", \"ada\"]\n",
    "        for code in tree_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name,\n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        if col > 0:\n",
    "            row += 1\n",
    "        \n",
    "        # å…¶ä»–åˆ†ç±»å™¨\n",
    "        ttk.Label(scrollable_frame, text=\"ğŸ“ˆ å…¶ä»–:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, columnspan=3, sticky=tk.W, pady=(10, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        col = 0\n",
    "        other_codes = [\"knn\", \"nb\", \"lr\", \"mlp\"]\n",
    "        for code in other_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                cb = ttk.Checkbutton(scrollable_frame, text=name,\n",
    "                                   variable=self.classifier_vars[code])\n",
    "                cb.grid(row=row, column=col, sticky=tk.W, pady=1, padx=5)\n",
    "                col += 1\n",
    "                if col >= 3:\n",
    "                    col = 0\n",
    "                    row += 1\n",
    "        \n",
    "        canvas.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        scrollbar.grid(row=1, column=3, sticky=(tk.N, tk.S))\n",
    "        clf_frame.rowconfigure(1, weight=1)\n",
    "        \n",
    "        # 4. æ§åˆ¶æŒ‰é’®åŒº\n",
    "        control_frame = ttk.LabelFrame(main_frame, text=\"4. è¿è¡Œæ§åˆ¶\", padding=\"10\")\n",
    "        control_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=5, padx=(0, 5))\n",
    "        \n",
    "        self.start_btn = ttk.Button(control_frame, text=\"â–¶ å¼€å§‹åˆ†ç±»\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"â¸ åœæ­¢\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"ğŸ“ æ‰“å¼€ç»“æœ\", \n",
    "                  command=self.open_result_dir, width=15).grid(row=0, column=2, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Button(control_frame, text=\"ğŸ“Š æŸ¥çœ‹æŠ¥å‘Š\", \n",
    "                  command=self.view_report, width=15).grid(row=0, column=3, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(control_frame, text=\"è¿›åº¦:\").grid(row=1, column=0, sticky=tk.W, pady=2)\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100, length=400)\n",
    "        self.progress_bar.grid(row=1, column=1, columnspan=3, sticky=(tk.W, tk.E), \n",
    "                              padx=5, pady=2)\n",
    "        \n",
    "        control_frame.columnconfigure(3, weight=1)\n",
    "        \n",
    "        # 5. æ—¥å¿—è¾“å‡ºåŒº\n",
    "        log_frame = ttk.LabelFrame(main_frame, text=\"5. è¿è¡Œæ—¥å¿—\", padding=\"10\")\n",
    "        log_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, \n",
    "                                                  height=18, width=120,\n",
    "                                                  font=('Consolas', 9))\n",
    "        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "        \n",
    "        log_frame.columnconfigure(0, weight=1)\n",
    "        log_frame.rowconfigure(0, weight=1)\n",
    "        \n",
    "        # çŠ¶æ€æ \n",
    "        self.status_var = tk.StringVar(value=\"å°±ç»ª\")\n",
    "        status_bar = ttk.Label(main_frame, textvariable=self.status_var, \n",
    "                              relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(5, 0))\n",
    "    \n",
    "    def toggle_sampling(self):\n",
    "        \"\"\"åˆ‡æ¢é‡‡æ ·åŠŸèƒ½\"\"\"\n",
    "        if self.enable_sampling.get():\n",
    "            self.max_samples_spinbox.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.max_samples_spinbox.config(state=tk.DISABLED)\n",
    "    \n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©å½±åƒæ–‡ä»¶\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "            self.status_var.set(f\"å·²é€‰æ‹©å½±åƒ: {Path(filename).name}\")\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©è®­ç»ƒæ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©éªŒè¯æ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"é€‰æ‹©è¾“å‡ºç›®å½•\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "    \n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        \"\"\"æ¨èç»„åˆ\"\"\"\n",
    "        recommended = [\"rf\", \"xgb\", \"et\", \"lgb\", \"linear_svc\", \"nystroem_svm\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "    \n",
    "    def select_fast(self):\n",
    "        \"\"\"å¿«é€Ÿåˆ†ç±»å™¨\"\"\"\n",
    "        fast = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"nb\", \"lr\", \"sgd_svm\", \"linear_svc\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in fast)\n",
    "    \n",
    "    def log(self, message):\n",
    "        \"\"\"æ·»åŠ æ—¥å¿—\"\"\"\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        \"\"\"æ›´æ–°æ—¥å¿—æ˜¾ç¤º\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    def start_classification(self):\n",
    "        \"\"\"å¼€å§‹åˆ†ç±»\"\"\"\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼\")\n",
    "            return\n",
    "        \n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼\")\n",
    "            return\n",
    "        \n",
    "        # æ€§èƒ½è­¦å‘Š\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        very_slow_clfs = []\n",
    "        \n",
    "        for code in selected_classifiers:\n",
    "            if code in all_classifiers:\n",
    "                speed_tag = all_classifiers[code][5]\n",
    "                name = all_classifiers[code][1]\n",
    "                if speed_tag == \"very_slow\":\n",
    "                    very_slow_clfs.append(name)\n",
    "        \n",
    "        if very_slow_clfs:\n",
    "            warning_msg = \"âš ï¸ ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹éå¸¸æ…¢:\\n\"\n",
    "            for clf in very_slow_clfs:\n",
    "                warning_msg += f\"  â€¢ {clf}\\n\"\n",
    "            warning_msg += \"\\nå»ºè®®ä½¿ç”¨å…¶ä»–SVMå˜ä½“\\n\\næ˜¯å¦ç»§ç»­?\"\n",
    "            \n",
    "            if not messagebox.askyesno(\"æ€§èƒ½è­¦å‘Š\", warning_msg, icon='warning'):\n",
    "                return\n",
    "        \n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0.1\")\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(f\"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª\")\n",
    "        self.log(\"\")\n",
    "        \n",
    "        thread = threading.Thread(target=self.run_classification, args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        \"\"\"åœæ­¢åˆ†ç±»\"\"\"\n",
    "        self.is_running = False\n",
    "        self.log(\"\\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...\")\n",
    "        self.status_var.set(\"å·²åœæ­¢\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"æ‰§è¡Œåˆ†ç±»\"\"\"\n",
    "        try:\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # è¯»å–å½±åƒ\n",
    "            self.log(f\"ğŸ“ è¯»å–å½±åƒ...\")\n",
    "            self.status_var.set(\"è¯»å–å½±åƒ...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            n_pixels = img.shape[1] * img.shape[2]\n",
    "            self.log(f\"   å°ºå¯¸: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # è¯»å–ç±»åˆ«ä¿¡æ¯\n",
    "            self.log(f\"\\nğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), self.class_attr.get(), self.name_attr.get()\n",
    "            )\n",
    "            self.log(f\"   ç±»åˆ«: {list(class_names.values())}\")\n",
    "            \n",
    "            # æå–è®­ç»ƒæ ·æœ¬\n",
    "            self.log(f\"\\nğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            self.status_var.set(\"å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            \n",
    "            max_samples = self.max_samples.get() if self.enable_sampling.get() else None\n",
    "            \n",
    "            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(\n",
    "                img, train_mask, \n",
    "                ignore_background=self.ignore_background.get(),\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            self.log(f\"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"   â””â”€ ç§»é™¤NaN: {n_nan:,}\")\n",
    "            if n_inf > 0:\n",
    "                self.log(f\"   â””â”€ ç§»é™¤Inf: {n_inf:,}\")\n",
    "            if n_sampled > 0:\n",
    "                self.log(f\"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # æå–éªŒè¯æ ·æœ¬\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(f\"\\nâœ… å¤„ç†éªŒè¯æ ·æœ¬...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(img)\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}\")\n",
    "            \n",
    "            # åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°\n",
    "            all_classifiers = self.backend.get_all_classifiers(\n",
    "                self.n_estimators.get(), \n",
    "                fast_mode=self.fast_mode.get(),\n",
    "                n_train_samples=len(y_train)\n",
    "            )\n",
    "            \n",
    "            comparison_results = []\n",
    "            total_start_time = time.time()\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] {clf_name}\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                \n",
    "                # é¢„ä¼°æ—¶é—´\n",
    "                est_pred_time = self.backend.estimate_prediction_time(clf_code, n_pixels, speed_tag)\n",
    "                if est_pred_time > 60:\n",
    "                    self.log(f\"â±ï¸  é¢„è®¡é¢„æµ‹: ~{est_pred_time/60:.1f} åˆ†é’Ÿ\")\n",
    "                \n",
    "                self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] è®­ç»ƒ {clf_name}...\")\n",
    "                \n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # æ•°æ®é¢„å¤„ç†\n",
    "                    label_encoder = None\n",
    "                    scaler = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    if needs_encoding:\n",
    "                        self.log(\"   ğŸ”„ æ ‡ç­¾ç¼–ç ...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    if needs_scaling:\n",
    "                        self.log(\"   ğŸ“ ç‰¹å¾ç¼©æ”¾...\")\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_use = scaler.fit_transform(X_train_use)\n",
    "                    \n",
    "                    # è®­ç»ƒ\n",
    "                    self.log(\"   ğŸ”¨ è®­ç»ƒä¸­...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’\")\n",
    "                    \n",
    "                    # è®­ç»ƒé›†ç²¾åº¦\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # é¢„æµ‹æ•´å¹…å½±åƒ\n",
    "                    self.log(\"   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...\")\n",
    "                    self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] é¢„æµ‹ {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’\")\n",
    "                    \n",
    "                    # éªŒè¯é›†ç²¾åº¦\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan, 'f1_macro': np.nan}\n",
    "                    if val_exists:\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}\")\n",
    "                    \n",
    "                    # è®°å½•ç»“æœ\n",
    "                    result = {\n",
    "                        'åˆ†ç±»å™¨ä»£ç ': clf_code,\n",
    "                        'åˆ†ç±»å™¨åç§°': clf_name,\n",
    "                        'é€Ÿåº¦ç­‰çº§': speed_tag,\n",
    "                        'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],\n",
    "                        'è®­ç»ƒé›†Kappa': train_metrics['kappa'],\n",
    "                        'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],\n",
    "                        'éªŒè¯é›†Kappa': val_metrics['kappa'],\n",
    "                        'è®­ç»ƒæ—¶é—´(ç§’)': train_time,\n",
    "                        'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,\n",
    "                        'æ€»æ—¶é—´(ç§’)': train_time + pred_time\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    \n",
    "                    self.log(f\"   âœ… {clf_name} å®Œæˆ!\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"   âŒ {clf_name} å¤±è´¥: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š\n",
    "            if comparison_results and self.is_running:\n",
    "                total_time = time.time() - total_start_time\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"ğŸ“ ç”ŸæˆæŠ¥å‘Š...\")\n",
    "                self.status_var.set(\"ç”ŸæˆæŠ¥å‘Š...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"=\"*70 + \"\\n\")\n",
    "                    f.write(\"        é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\\n\")\n",
    "                    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "                    \n",
    "                    f.write(f\"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                    f.write(f\"å½±åƒ: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ\\n\")\n",
    "                    f.write(f\"è®­ç»ƒæ ·æœ¬: {len(y_train):,}\\n\")\n",
    "                    if val_exists:\n",
    "                        f.write(f\"éªŒè¯æ ·æœ¬: {len(yv_true):,}\\n\")\n",
    "                    f.write(f\"ç±»åˆ«æ•°: {len(class_names)}\\n\")\n",
    "                    f.write(f\"æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\\n\")\n",
    "                    f.write(f\"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\\n\\n\")\n",
    "                    \n",
    "                    # ç²¾åº¦æ’å\n",
    "                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    f.write(\"ğŸ“Š éªŒè¯é›†ç²¾åº¦æ’å:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx:2d}. {row['åˆ†ç±»å™¨åç§°']:18s} - \"\n",
    "                               f\"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}, \"\n",
    "                               f\"Kappa: {row['éªŒè¯é›†Kappa']:.4f}\\n\")\n",
    "                    \n",
    "                    # é€Ÿåº¦æ’å\n",
    "                    f.write(\"\\n\" + \"-\"*70 + \"\\n\")\n",
    "                    f.write(\"âš¡ æ€»æ—¶é—´æ’å:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    sorted_time = comparison_df.sort_values('æ€»æ—¶é—´(ç§’)')\n",
    "                    for idx, (_, row) in enumerate(sorted_time.iterrows(), 1):\n",
    "                        f.write(f\"{idx:2d}. {row['åˆ†ç±»å™¨åç§°']:18s} - \"\n",
    "                               f\"{row['æ€»æ—¶é—´(ç§’)']:7.2f}ç§’\\n\")\n",
    "                    \n",
    "                    # æ¨è\n",
    "                    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "                    f.write(\"ğŸ’¡ æ¨è:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    \n",
    "                    best_acc = sorted_df.iloc[0]\n",
    "                    f.write(f\"ğŸ† æœ€é«˜ç²¾åº¦: {best_acc['åˆ†ç±»å™¨åç§°']} ({best_acc['éªŒè¯é›†ç²¾åº¦']:.4f})\\n\")\n",
    "                    \n",
    "                    best_speed = sorted_time.iloc[0]\n",
    "                    f.write(f\"âš¡ æœ€å¿«é€Ÿåº¦: {best_speed['åˆ†ç±»å™¨åç§°']} ({best_speed['æ€»æ—¶é—´(ç§’)']:.2f}ç§’)\\n\")\n",
    "                \n",
    "                self.log(\"âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!\")\n",
    "                self.log(f\"ğŸ“ ç»“æœ: {out_dir.absolute()}\")\n",
    "                self.log(f\"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\")\n",
    "                \n",
    "                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]\n",
    "                self.log(f\"\\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\")\n",
    "                \n",
    "                self.status_var.set(f\"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']}\")\n",
    "                \n",
    "                messagebox.showinfo(\"ä»»åŠ¡å®Œæˆ\", \n",
    "                    f\"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\\n\\n\"\n",
    "                    f\"âœ… æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\\n\"\n",
    "                    f\"ğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\\n\"\n",
    "                    f\"â±ï¸  è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\nâŒ é”™è¯¯: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"é”™è¯¯\", f\"å‘ç”Ÿé”™è¯¯:\\n{str(e)}\")\n",
    "            self.status_var.set(\"âŒ é”™è¯¯\")\n",
    "        \n",
    "        finally:\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"æ‰“å¼€ç»“æœç›®å½•\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"ç»“æœç›®å½•ä¸å­˜åœ¨ï¼\")\n",
    "    \n",
    "    def view_report(self):\n",
    "        \"\"\"æŸ¥çœ‹å¯¹æ¯”æŠ¥å‘Š\"\"\"\n",
    "        report_file = Path(self.output_dir.get()) / \"comparison_summary.txt\"\n",
    "        if report_file.exists():\n",
    "            report_window = tk.Toplevel(self.root)\n",
    "            report_window.title(\"ğŸ“Š åˆ†ç±»å™¨å¯¹æ¯”æŠ¥å‘Š\")\n",
    "            report_window.geometry(\"900x700\")\n",
    "            \n",
    "            toolbar = ttk.Frame(report_window)\n",
    "            toolbar.pack(side=tk.TOP, fill=tk.X, padx=5, pady=5)\n",
    "            \n",
    "            ttk.Button(toolbar, text=\"ğŸ“ æ‰“å¼€CSV\", \n",
    "                      command=lambda: os.startfile(\n",
    "                          Path(self.output_dir.get()) / \"classifier_comparison.csv\"\n",
    "                      )).pack(side=tk.LEFT, padx=2)\n",
    "            \n",
    "            text_widget = scrolledtext.ScrolledText(report_window, wrap=tk.WORD,\n",
    "                                                   font=('Consolas', 10))\n",
    "            text_widget.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "            \n",
    "            with open(report_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                text_widget.insert(1.0, content)\n",
    "            \n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·å…ˆè¿è¡Œåˆ†ç±»ã€‚\")\n",
    "\n",
    "# ==================== ä¸»ç¨‹åºå…¥å£ ====================\n",
    "def main():\n",
    "    \"\"\"ç¨‹åºå…¥å£\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0.1\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\næ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...\")\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    app = ClassificationGUI(root)\n",
    "    \n",
    "    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v3.0.1\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"æ”¯æŒçš„åˆ†ç±»å™¨:\")\n",
    "    app.log(\"  ğŸ“Š SVMç³»åˆ—: çº¿æ€§æ ¸ã€RBFæ ¸ã€SGD-SVMã€æ ¸è¿‘ä¼¼ç­‰\")\n",
    "    app.log(\"  ğŸŒ² æ ‘æ¨¡å‹: RFã€XGBoostã€LightGBMã€ETã€GBã€DTç­‰\")\n",
    "    app.log(\"  ğŸ“ˆ å…¶ä»–: KNNã€æœ´ç´ è´å¶æ–¯ã€é€»è¾‘å›å½’ã€ç¥ç»ç½‘ç»œç­‰\")\n",
    "    app.log(\"\")\n",
    "    app.log(\"ä¼˜åŒ–ç‰¹æ€§:\")\n",
    "    app.log(\"  âš¡ æ•°æ®é‡‡æ · - åŠ å¿«è®­ç»ƒ\")\n",
    "    app.log(\"  ğŸ“ ç‰¹å¾ç¼©æ”¾ - æå‡æ€§èƒ½\")\n",
    "    app.log(\"  ğŸš€ å¿«é€Ÿæ¨¡å¼ - å‡å°‘å¤æ‚åº¦\")\n",
    "    app.log(\"\")\n",
    "    app.log(\"ğŸ’¡ æç¤º: ç‚¹å‡»'âœ“æ¨è'æˆ–'âš¡å¿«é€Ÿ'å¿«é€Ÿé€‰æ‹©åˆ†ç±»å™¨\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"\")\n",
    "    \n",
    "    print(\"\\nâœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!\")\n",
    "    print(\"è¯·åœ¨GUIç•Œé¢ä¸­æ“ä½œ...\")\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09505602",
   "metadata": {},
   "source": [
    "# ç‰ˆæœ¬3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1a3762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ\n",
      "================================================================================\n",
      "\n",
      "æ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...\n",
      "âœ“ XGBoost å¯ç”¨\n",
      "âœ“ LightGBM å¯ç”¨\n",
      "\n",
      "âœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - ä¸“ä¸šç‰ˆ v4.1\n",
    "=====================================\n",
    "æ–°å¢:\n",
    "- å®Œå–„ç»“æœé¢„è§ˆæ˜¾ç¤º\n",
    "- Excelæ ¼å¼æŠ¥å‘Šè¾“å‡º\n",
    "- æ··æ·†çŸ©é˜µå¯è§†åŒ–\n",
    "- å›¾è¡¨å®æ—¶åˆ·æ–°ä¼˜åŒ–\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio import features\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.kernel_approximation import Nystroem, RBFSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, \n",
    "                           cohen_kappa_score, precision_score, recall_score, f1_score)\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\", \"Arial Unicode MS\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# æ£€æŸ¥openpyxl\n",
    "try:\n",
    "    import openpyxl\n",
    "    HAS_OPENPYXL = True\n",
    "except ImportError:\n",
    "    HAS_OPENPYXL = False\n",
    "    print(\"âš ï¸  æœªå®‰è£…openpyxlï¼Œå°†æ— æ³•å¯¼å‡ºExcelæ–‡ä»¶\")\n",
    "    print(\"   å®‰è£…: pip install openpyxl\")\n",
    "\n",
    "# ==================== åç«¯å¤„ç†ç±» ====================\n",
    "class ClassificationBackend:\n",
    "    \"\"\"åˆ†ç±»å¤„ç†åç«¯\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.RANDOM_STATE = 42\n",
    "        \n",
    "        # é¢„å®šä¹‰é¢œè‰²\n",
    "        self.LANDUSE_COLORS = {\n",
    "            \"æ°´ä½“\": \"lightblue\", \"æ²³æµ\": \"blue\", \"æ¹–æ³Š\": \"deepskyblue\",\n",
    "            \"æ¤è¢«\": \"forestgreen\", \"æ£®æ—\": \"darkgreen\", \"è‰åœ°\": \"limegreen\",\n",
    "            \"å†œç”°\": \"yellowgreen\", \"è€•åœ°\": \"olivedrab\",\n",
    "            \"å»ºç­‘\": \"gray\", \"åŸå¸‚\": \"dimgray\", \"å±…æ°‘åœ°\": \"slategray\",\n",
    "            \"è£¸åœ°\": \"tan\", \"æ²™åœ°\": \"wheat\", \"å…¶ä»–\": \"darkred\"\n",
    "        }\n",
    "        \n",
    "        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', \n",
    "                             'darkred', 'purple', 'orange', 'pink', 'brown']\n",
    "        \n",
    "        # æ£€æŸ¥å¯é€‰åº“\n",
    "        self.check_optional_libraries()\n",
    "    \n",
    "    def check_optional_libraries(self):\n",
    "        \"\"\"æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨\"\"\"\n",
    "        self.has_xgboost = False\n",
    "        self.has_lightgbm = False\n",
    "        \n",
    "        try:\n",
    "            import xgboost\n",
    "            from xgboost import XGBClassifier\n",
    "            _ = XGBClassifier(n_estimators=10, verbosity=0)\n",
    "            self.has_xgboost = True\n",
    "            print(\"âœ“ XGBoost å¯ç”¨\")\n",
    "        except Exception:\n",
    "            print(\"âœ— XGBoost ä¸å¯ç”¨\")\n",
    "        \n",
    "        try:\n",
    "            import lightgbm\n",
    "            from lightgbm import LGBMClassifier\n",
    "            _ = LGBMClassifier(n_estimators=10, verbose=-1)\n",
    "            self.has_lightgbm = True\n",
    "            print(\"âœ“ LightGBM å¯ç”¨\")\n",
    "        except Exception:\n",
    "            print(\"âœ— LightGBM ä¸å¯ç”¨\")\n",
    "    \n",
    "    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):\n",
    "        \"\"\"è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨\"\"\"\n",
    "        if fast_mode:\n",
    "            n_est = min(50, n_estimators)\n",
    "            max_depth = 10\n",
    "            max_iter = 200\n",
    "        else:\n",
    "            n_est = n_estimators\n",
    "            max_depth = 20\n",
    "            max_iter = 500\n",
    "        \n",
    "        if n_train_samples:\n",
    "            n_components = min(1000, n_train_samples // 2)\n",
    "        else:\n",
    "            n_components = 1000\n",
    "        \n",
    "        classifiers = {\n",
    "            \"rf\": (RandomForestClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE, \n",
    "                                         verbose=0, max_depth=max_depth, min_samples_split=5, \n",
    "                                         max_features='sqrt'),\n",
    "                  \"éšæœºæ£®æ—\", \"Random Forest\", False, False, \"fast\"),\n",
    "            \n",
    "            \"et\": (ExtraTreesClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE,\n",
    "                                       verbose=0, max_depth=max_depth, min_samples_split=5, max_features='sqrt'),\n",
    "                  \"æç«¯éšæœºæ ‘\", \"Extra Trees\", False, False, \"fast\"),\n",
    "            \n",
    "            \"dt\": (DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=max_depth,\n",
    "                                         min_samples_split=5, min_samples_leaf=2),\n",
    "                  \"å†³ç­–æ ‘\", \"Decision Tree\", False, False, \"very_fast\"),\n",
    "            \n",
    "            \"svm_linear\": (SVC(kernel=\"linear\", C=1.0, cache_size=500, probability=True, \n",
    "                             random_state=self.RANDOM_STATE, max_iter=max_iter),\n",
    "                          \"SVM-çº¿æ€§æ ¸\", \"SVM Linear\", False, True, \"medium\"),\n",
    "            \n",
    "            \"linear_svc\": (CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=max_iter, random_state=self.RANDOM_STATE,\n",
    "                                                           dual=False, loss='squared_hinge'), cv=3),\n",
    "                          \"çº¿æ€§SVM(å¿«)\", \"Linear SVM\", False, True, \"fast\"),\n",
    "            \n",
    "            \"sgd_svm\": (SGDClassifier(loss='hinge', penalty='l2', max_iter=max_iter, n_jobs=-1,\n",
    "                                     random_state=self.RANDOM_STATE, learning_rate='optimal'),\n",
    "                       \"SGD-SVM\", \"SGD SVM\", False, True, \"very_fast\"),\n",
    "            \n",
    "            \"nystroem_svm\": (Pipeline([\n",
    "                (\"feature_map\", Nystroem(kernel='rbf', gamma=0.1, n_components=n_components, \n",
    "                                        random_state=self.RANDOM_STATE)),\n",
    "                (\"sgd\", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))\n",
    "            ]), \"æ ¸è¿‘ä¼¼SVM\", \"Nystroem SVM\", False, True, \"fast\"),\n",
    "            \n",
    "            \"rbf_sampler_svm\": (Pipeline([\n",
    "                (\"feature_map\", RBFSampler(gamma=0.1, n_components=n_components, random_state=self.RANDOM_STATE)),\n",
    "                (\"sgd\", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))\n",
    "            ]), \"RBFé‡‡æ ·SVM\", \"RBF Sampler\", False, True, \"fast\"),\n",
    "            \n",
    "            \"svm_rbf\": (SVC(kernel=\"rbf\", C=1.0, gamma='scale', cache_size=500, probability=True, \n",
    "                          random_state=self.RANDOM_STATE),\n",
    "                       \"SVM-RBFæ ¸âš ï¸\", \"SVM RBF\", False, True, \"very_slow\"),\n",
    "            \n",
    "            \"knn\": (KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm='ball_tree', leaf_size=30),\n",
    "                   \"Kè¿‘é‚»\", \"KNN\", False, True, \"slow\"),\n",
    "            \n",
    "            \"nb\": (GaussianNB(), \"æœ´ç´ è´å¶æ–¯\", \"Naive Bayes\", False, False, \"very_fast\"),\n",
    "            \n",
    "            \"gb\": (GradientBoostingClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=5,\n",
    "                                             random_state=self.RANDOM_STATE, verbose=0, subsample=0.8),\n",
    "                  \"æ¢¯åº¦æå‡\", \"Gradient Boosting\", False, False, \"medium\"),\n",
    "            \n",
    "            \"ada\": (AdaBoostClassifier(n_estimators=n_est, learning_rate=1.0, \n",
    "                                      random_state=self.RANDOM_STATE, algorithm='SAMME.R'),\n",
    "                   \"AdaBoost\", \"AdaBoost\", False, False, \"medium\"),\n",
    "            \n",
    "            \"lr\": (LogisticRegression(max_iter=max_iter, n_jobs=-1, random_state=self.RANDOM_STATE,\n",
    "                                     verbose=0, solver='lbfgs', multi_class='multinomial'),\n",
    "                  \"é€»è¾‘å›å½’\", \"Logistic Regression\", False, True, \"very_fast\"),\n",
    "            \n",
    "            \"mlp\": (MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=max_iter, random_state=self.RANDOM_STATE,\n",
    "                                 verbose=False, early_stopping=True, validation_fraction=0.1, \n",
    "                                 n_iter_no_change=10, learning_rate='adaptive'),\n",
    "                   \"ç¥ç»ç½‘ç»œ\", \"MLP\", False, True, \"medium\"),\n",
    "        }\n",
    "        \n",
    "        if self.has_xgboost:\n",
    "            try:\n",
    "                from xgboost import XGBClassifier\n",
    "                classifiers[\"xgb\"] = (\n",
    "                    XGBClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=6, n_jobs=-1,\n",
    "                                 random_state=self.RANDOM_STATE, verbosity=0, tree_method='hist',\n",
    "                                 subsample=0.8, colsample_bytree=0.8),\n",
    "                    \"XGBoost\", \"XGBoost\", True, False, \"fast\"\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        if self.has_lightgbm:\n",
    "            try:\n",
    "                from lightgbm import LGBMClassifier\n",
    "                classifiers[\"lgb\"] = (\n",
    "                    LGBMClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=max_depth, n_jobs=-1,\n",
    "                                  random_state=self.RANDOM_STATE, verbose=-1, num_leaves=31,\n",
    "                                  subsample=0.8, colsample_bytree=0.8, force_col_wise=True),\n",
    "                    \"LightGBM\", \"LightGBM\", False, False, \"very_fast\"\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        return classifiers\n",
    "    \n",
    "    def get_background_mask(self, image, background_value=0):\n",
    "        \"\"\"è·å–èƒŒæ™¯æ©è†œ\"\"\"\n",
    "        data = image.values\n",
    "        if background_value == 0:\n",
    "            background_mask = np.all(data == 0, axis=0)\n",
    "        else:\n",
    "            background_mask = np.all(data == background_value, axis=0)\n",
    "        return background_mask\n",
    "    \n",
    "    def get_shapefile_fields(self, shp_path):\n",
    "        \"\"\"è·å–shapefileçš„æ‰€æœ‰å­—æ®µå\"\"\"\n",
    "        try:\n",
    "            gdf = gpd.read_file(shp_path)\n",
    "            return list(gdf.columns)\n",
    "        except Exception as e:\n",
    "            print(f\"è¯»å–shapefileå­—æ®µå¤±è´¥: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):\n",
    "        \"\"\"ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯\"\"\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if name_attr not in gdf.columns or name_attr == class_attr:\n",
    "            gdf[name_attr] = gdf[class_attr].apply(lambda x: f\"ç±»åˆ«_{x}\")\n",
    "        \n",
    "        class_info = gdf[[class_attr, name_attr]].drop_duplicates()\n",
    "        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))\n",
    "        \n",
    "        class_colors = {}\n",
    "        for i, (class_id, class_name) in enumerate(class_names.items()):\n",
    "            color_found = False\n",
    "            for key, color in self.LANDUSE_COLORS.items():\n",
    "                if key in str(class_name):\n",
    "                    class_colors[class_id] = color\n",
    "                    color_found = True\n",
    "                    break\n",
    "            if not color_found:\n",
    "                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]\n",
    "        \n",
    "        return class_names, class_colors, sorted(class_names.keys())\n",
    "    \n",
    "    def rasterize_samples(self, shp, ref_img, attr):\n",
    "        \"\"\"çŸ¢é‡æ …æ ¼åŒ–\"\"\"\n",
    "        gdf = gpd.read_file(shp)\n",
    "        gdf = gdf.to_crs(ref_img.rio.crs)\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))\n",
    "        \n",
    "        arr = features.rasterize(shapes=shapes, out_shape=ref_img.shape[1:],\n",
    "                                transform=ref_img.rio.transform(), fill=0,\n",
    "                                all_touched=True, dtype=\"uint16\")\n",
    "        return arr\n",
    "    \n",
    "    def extract_samples(self, image, mask, ignore_background=True, background_value=0, max_samples=None):\n",
    "        \"\"\"æå–æ ·æœ¬\"\"\"\n",
    "        data = np.moveaxis(image.values, 0, -1)\n",
    "        valid = mask > 0\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image, background_value)\n",
    "            valid = valid & (~background_mask)\n",
    "        \n",
    "        X = data[valid]\n",
    "        y = mask[valid]\n",
    "        \n",
    "        # æ¸…ç†NaNå’ŒInf\n",
    "        nan_mask = np.isnan(X).any(axis=1)\n",
    "        inf_mask = np.isinf(X).any(axis=1)\n",
    "        bad_mask = nan_mask | inf_mask\n",
    "        \n",
    "        n_nan = np.sum(nan_mask)\n",
    "        n_inf = np.sum(inf_mask)\n",
    "        \n",
    "        X = X[~bad_mask]\n",
    "        y = y[~bad_mask]\n",
    "        \n",
    "        # åˆ†å±‚é‡‡æ ·\n",
    "        n_sampled = 0\n",
    "        if max_samples is not None and len(y) > max_samples:\n",
    "            n_original = len(y)\n",
    "            unique_classes = np.unique(y)\n",
    "            \n",
    "            if len(unique_classes) > 1:\n",
    "                splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_samples, \n",
    "                                                 random_state=self.RANDOM_STATE)\n",
    "                sample_idx, _ = next(splitter.split(X, y))\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "            else:\n",
    "                np.random.seed(self.RANDOM_STATE)\n",
    "                sample_idx = np.random.choice(len(y), max_samples, replace=False)\n",
    "                X = X[sample_idx]\n",
    "                y = y[sample_idx]\n",
    "                n_sampled = n_original - len(y)\n",
    "        \n",
    "        return X, y, n_nan, n_inf, n_sampled\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"è®¡ç®—è¯„ä»·æŒ‡æ ‡\"\"\"\n",
    "        return {\n",
    "            'overall_accuracy': accuracy_score(y_true, y_pred),\n",
    "            'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        }\n",
    "    \n",
    "    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):\n",
    "        \"\"\"ä¼°ç®—é¢„æµ‹æ—¶é—´\"\"\"\n",
    "        time_per_million = {\"very_fast\": 1, \"fast\": 3, \"medium\": 10, \"slow\": 30, \"very_slow\": 300}\n",
    "        base_time = time_per_million.get(speed_tag, 10)\n",
    "        return (n_pixels / 1_000_000) * base_time\n",
    "    \n",
    "    def predict_by_block(self, model, image, out_path, block_size=512, \n",
    "                        ignore_background=True, background_value=0, progress_callback=None,\n",
    "                        label_encoder=None, scaler=None):\n",
    "        \"\"\"åˆ†å—é¢„æµ‹\"\"\"\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        prediction = np.zeros((height, width), dtype='uint16')\n",
    "        \n",
    "        if ignore_background:\n",
    "            background_mask = self.get_background_mask(image, background_value)\n",
    "        \n",
    "        total_blocks = int(np.ceil(height / block_size))\n",
    "        \n",
    "        for i, y in enumerate(range(0, height, block_size)):\n",
    "            h = min(block_size, height - y)\n",
    "            block_data = image.isel(y=slice(y, y+h)).values\n",
    "            data = np.moveaxis(block_data, 0, -1)\n",
    "            original_shape = data.shape\n",
    "            data_flat = data.reshape(-1, data.shape[-1])\n",
    "            \n",
    "            if ignore_background:\n",
    "                block_bg_mask = background_mask[y:y+h, :].flatten()\n",
    "                non_bg_indices = ~block_bg_mask\n",
    "                \n",
    "                if np.any(non_bg_indices):\n",
    "                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], \n",
    "                                                   nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                    \n",
    "                    if scaler is not None:\n",
    "                        data_to_predict = scaler.transform(data_to_predict)\n",
    "                    \n",
    "                    preds_non_bg = model.predict(data_to_predict)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)\n",
    "                    \n",
    "                    preds_flat = np.zeros(len(data_flat), dtype='uint16')\n",
    "                    preds_flat[non_bg_indices] = preds_non_bg\n",
    "                    preds = preds_flat.reshape(original_shape[0], original_shape[1])\n",
    "                else:\n",
    "                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')\n",
    "            else:\n",
    "                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                \n",
    "                if scaler is not None:\n",
    "                    data_flat = scaler.transform(data_flat)\n",
    "                \n",
    "                preds = model.predict(data_flat)\n",
    "                \n",
    "                if label_encoder is not None:\n",
    "                    preds = label_encoder.inverse_transform(preds)\n",
    "                \n",
    "                preds = preds.reshape(original_shape[0], original_shape[1]).astype(\"uint16\")\n",
    "            \n",
    "            prediction[y:y+h, :] = preds\n",
    "            \n",
    "            if progress_callback:\n",
    "                progress_callback((i + 1) / total_blocks * 100)\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        prediction_da = xr.DataArray(prediction, dims=['y', 'x'],\n",
    "                                     coords={'y': image.coords['y'], 'x': image.coords['x']})\n",
    "        \n",
    "        prediction_da.rio.write_crs(image.rio.crs, inplace=True)\n",
    "        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)\n",
    "        prediction_da.rio.write_nodata(background_value, inplace=True)\n",
    "        \n",
    "        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', \n",
    "                                    compress='lzw', tiled=True)\n",
    "        return out_path\n",
    "\n",
    "# ==================== GUIä¸»ç±» ====================\n",
    "class ClassificationGUI:\n",
    "    \"\"\"é¥æ„Ÿå½±åƒåˆ†ç±»GUIä¸»ç•Œé¢ï¼ˆä¸“ä¸šç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ\")\n",
    "        self.root.geometry(\"1600x900\")\n",
    "        \n",
    "        # åç«¯å¤„ç†å¯¹è±¡\n",
    "        self.backend = ClassificationBackend()\n",
    "        \n",
    "        # æ•°æ®å˜é‡\n",
    "        self.image_path = tk.StringVar()\n",
    "        self.train_shp_path = tk.StringVar()\n",
    "        self.val_shp_path = tk.StringVar()\n",
    "        self.output_dir = tk.StringVar(value=str(Path(\"./results_gui\")))\n",
    "        \n",
    "        # å­—æ®µé€‰æ‹©\n",
    "        self.train_fields = []\n",
    "        self.class_attr = tk.StringVar()\n",
    "        self.name_attr = tk.StringVar()\n",
    "        \n",
    "        # èƒŒæ™¯å€¼\n",
    "        self.background_value = tk.IntVar(value=0)\n",
    "        self.ignore_background = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # å…¶ä»–å‚æ•°\n",
    "        self.n_estimators = tk.IntVar(value=100)\n",
    "        self.block_size = tk.IntVar(value=512)\n",
    "        \n",
    "        # æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "        self.enable_sampling = tk.BooleanVar(value=True)\n",
    "        self.max_samples = tk.IntVar(value=50000)\n",
    "        self.fast_mode = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # åˆ†ç±»å™¨é€‰æ‹©\n",
    "        self.classifier_vars = {}\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        for code in all_classifiers.keys():\n",
    "            self.classifier_vars[code] = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # è¿è¡ŒçŠ¶æ€\n",
    "        self.is_running = False\n",
    "        self.log_queue = queue.Queue()\n",
    "        \n",
    "        # å­˜å‚¨ç»“æœæ•°æ®\n",
    "        self.comparison_results = []\n",
    "        self.current_confusion_matrix = None\n",
    "        self.current_y_true = None\n",
    "        self.current_y_pred = None\n",
    "        self.class_names_dict = {}\n",
    "        self.class_colors_dict = {}\n",
    "        self.best_result_path = None\n",
    "        \n",
    "        # æ„å»ºç•Œé¢\n",
    "        self.build_ui()\n",
    "        \n",
    "        # å¯åŠ¨æ—¥å¿—æ›´æ–°\n",
    "        self.update_log()\n",
    "    \n",
    "    def build_ui(self):\n",
    "        \"\"\"æ„å»ºç”¨æˆ·ç•Œé¢ï¼ˆå·¦å³åˆ†æ ï¼‰\"\"\"\n",
    "        # åˆ›å»ºä¸»PanedWindow\n",
    "        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)\n",
    "        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # ===== å·¦ä¾§é¢æ¿ï¼šå‚æ•°è®¾ç½® =====\n",
    "        left_frame = ttk.Frame(main_paned, width=600)\n",
    "        main_paned.add(left_frame, weight=1)\n",
    "        \n",
    "        # åˆ›å»ºæ»šåŠ¨åŒºåŸŸ\n",
    "        canvas = tk.Canvas(left_frame)\n",
    "        scrollbar = ttk.Scrollbar(left_frame, orient=\"vertical\", command=canvas.yview)\n",
    "        scrollable_left = ttk.Frame(canvas)\n",
    "        \n",
    "        scrollable_left.bind(\"<Configure>\", \n",
    "                            lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "        \n",
    "        canvas.create_window((0, 0), window=scrollable_left, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "        \n",
    "        # 1. æ–‡ä»¶é€‰æ‹©\n",
    "        file_frame = ttk.LabelFrame(scrollable_left, text=\"ğŸ“ æ•°æ®æ–‡ä»¶\", padding=\"10\")\n",
    "        file_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"å½±åƒæ–‡ä»¶:\").grid(row=0, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Entry(file_frame, textvariable=self.image_path, width=40).grid(\n",
    "            row=0, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_image).grid(row=0, column=2)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è®­ç»ƒæ ·æœ¬:\").grid(row=1, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Entry(file_frame, textvariable=self.train_shp_path, width=40).grid(\n",
    "            row=1, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_train_shp).grid(row=1, column=2)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"éªŒè¯æ ·æœ¬:\").grid(row=2, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Entry(file_frame, textvariable=self.val_shp_path, width=40).grid(\n",
    "            row=2, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_val_shp).grid(row=2, column=2)\n",
    "        \n",
    "        ttk.Label(file_frame, text=\"è¾“å‡ºç›®å½•:\").grid(row=3, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Entry(file_frame, textvariable=self.output_dir, width=40).grid(\n",
    "            row=3, column=1, sticky=(tk.W, tk.E), padx=5\n",
    "        )\n",
    "        ttk.Button(file_frame, text=\"æµè§ˆ\", command=self.browse_output).grid(row=3, column=2)\n",
    "        \n",
    "        file_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # 2. å­—æ®µé€‰æ‹©\n",
    "        field_frame = ttk.LabelFrame(scrollable_left, text=\"ğŸ·ï¸ å­—æ®µé…ç½®\", padding=\"10\")\n",
    "        field_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(field_frame, text=\"ç±»åˆ«ç¼–å·å­—æ®µ:\").grid(row=0, column=0, sticky=tk.W, pady=3)\n",
    "        self.class_attr_combo = ttk.Combobox(field_frame, textvariable=self.class_attr, \n",
    "                                            width=20, state=\"readonly\")\n",
    "        self.class_attr_combo.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=5)\n",
    "        \n",
    "        ttk.Label(field_frame, text=\"ç±»åˆ«åç§°å­—æ®µ:\").grid(row=1, column=0, sticky=tk.W, pady=3)\n",
    "        self.name_attr_combo = ttk.Combobox(field_frame, textvariable=self.name_attr, \n",
    "                                           width=20, state=\"readonly\")\n",
    "        self.name_attr_combo.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5)\n",
    "        \n",
    "        ttk.Button(field_frame, text=\"ğŸ”„ åˆ·æ–°å­—æ®µåˆ—è¡¨\", \n",
    "                  command=self.refresh_fields).grid(row=0, column=2, rowspan=2, padx=5)\n",
    "        \n",
    "        field_frame.columnconfigure(1, weight=1)\n",
    "        \n",
    "        # 3. èƒŒæ™¯å€¼è®¾ç½®\n",
    "        bg_frame = ttk.LabelFrame(scrollable_left, text=\"ğŸ¨ èƒŒæ™¯å€¼è®¾ç½®\", padding=\"10\")\n",
    "        bg_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Checkbutton(bg_frame, text=\"å¿½ç•¥èƒŒæ™¯å€¼\", \n",
    "                       variable=self.ignore_background).grid(row=0, column=0, sticky=tk.W, pady=3)\n",
    "        \n",
    "        ttk.Label(bg_frame, text=\"èƒŒæ™¯å€¼:\").grid(row=1, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Spinbox(bg_frame, from_=-9999, to=9999, textvariable=self.background_value, \n",
    "                   width=15).grid(row=1, column=1, sticky=tk.W, padx=5)\n",
    "        ttk.Label(bg_frame, text=\"(é»˜è®¤0, å¸¸è§: -9999, 255)\", \n",
    "                 font=('', 8), foreground='gray').grid(row=1, column=2, sticky=tk.W)\n",
    "        \n",
    "        # 4. åˆ†ç±»å‚æ•°\n",
    "        param_frame = ttk.LabelFrame(scrollable_left, text=\"âš™ï¸ åˆ†ç±»å‚æ•°\", padding=\"10\")\n",
    "        param_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"æ ‘æ¨¡å‹æ•°é‡:\").grid(row=0, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Spinbox(param_frame, from_=10, to=500, textvariable=self.n_estimators, \n",
    "                   width=15).grid(row=0, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"åˆ†å—å¤§å°:\").grid(row=1, column=0, sticky=tk.W, pady=3)\n",
    "        ttk.Spinbox(param_frame, from_=256, to=2048, increment=256, \n",
    "                   textvariable=self.block_size, width=15).grid(row=1, column=1, sticky=tk.W, padx=5)\n",
    "        \n",
    "        # 5. æ€§èƒ½ä¼˜åŒ–\n",
    "        opt_frame = ttk.LabelFrame(scrollable_left, text=\"âš¡ æ€§èƒ½ä¼˜åŒ–\", padding=\"10\")\n",
    "        opt_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        sample_frame = ttk.Frame(opt_frame)\n",
    "        sample_frame.pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        ttk.Checkbutton(sample_frame, text=\"å¯ç”¨é‡‡æ ·\", \n",
    "                       variable=self.enable_sampling,\n",
    "                       command=self.toggle_sampling).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Label(sample_frame, text=\"æœ€å¤§æ ·æœ¬æ•°:\").pack(side=tk.LEFT, padx=(10, 0))\n",
    "        self.max_samples_spinbox = ttk.Spinbox(sample_frame, from_=10000, to=200000, \n",
    "                                              increment=10000, textvariable=self.max_samples, \n",
    "                                              width=10)\n",
    "        self.max_samples_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Checkbutton(opt_frame, text=\"å¿«é€Ÿæ¨¡å¼\", \n",
    "                       variable=self.fast_mode).pack(anchor=tk.W, pady=2)\n",
    "        \n",
    "        # 6. åˆ†ç±»å™¨é€‰æ‹©\n",
    "        clf_frame = ttk.LabelFrame(scrollable_left, text=\"ğŸ¤– åˆ†ç±»å™¨é€‰æ‹©\", padding=\"10\")\n",
    "        clf_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # å¿«æ·æŒ‰é’®\n",
    "        btn_frame = ttk.Frame(clf_frame)\n",
    "        btn_frame.pack(fill=tk.X, pady=(0, 5))\n",
    "        \n",
    "        ttk.Button(btn_frame, text=\"å…¨é€‰\", command=self.select_all_classifiers, \n",
    "                  width=10).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"å…¨ä¸é€‰\", command=self.deselect_all_classifiers, \n",
    "                  width=10).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âœ“æ¨è\", command=self.select_recommended, \n",
    "                  width=10).pack(side=tk.LEFT, padx=2)\n",
    "        ttk.Button(btn_frame, text=\"âš¡å¿«é€Ÿ\", command=self.select_fast, \n",
    "                  width=10).pack(side=tk.LEFT, padx=2)\n",
    "        \n",
    "        # åˆ†ç±»å™¨å¤é€‰æ¡†\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        \n",
    "        clf_canvas = tk.Canvas(clf_frame, height=150)\n",
    "        clf_scrollbar = ttk.Scrollbar(clf_frame, orient=\"vertical\", command=clf_canvas.yview)\n",
    "        clf_scrollable = ttk.Frame(clf_canvas)\n",
    "        \n",
    "        clf_scrollable.bind(\"<Configure>\", \n",
    "                           lambda e: clf_canvas.configure(scrollregion=clf_canvas.bbox(\"all\")))\n",
    "        \n",
    "        clf_canvas.create_window((0, 0), window=clf_scrollable, anchor=\"nw\")\n",
    "        clf_canvas.configure(yscrollcommand=clf_scrollbar.set)\n",
    "        \n",
    "        # SVMç»„\n",
    "        ttk.Label(clf_scrollable, text=\"SVM:\", font=('', 9, 'bold')).grid(\n",
    "            row=0, column=0, sticky=tk.W, pady=2\n",
    "        )\n",
    "        row = 1\n",
    "        svm_codes = [\"svm_linear\", \"linear_svc\", \"sgd_svm\", \"nystroem_svm\", \n",
    "                     \"rbf_sampler_svm\", \"svm_rbf\"]\n",
    "        for code in svm_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                ttk.Checkbutton(clf_scrollable, text=name, \n",
    "                              variable=self.classifier_vars[code]).grid(\n",
    "                    row=row, column=0, sticky=tk.W, padx=20\n",
    "                )\n",
    "                row += 1\n",
    "        \n",
    "        # æ ‘æ¨¡å‹\n",
    "        ttk.Label(clf_scrollable, text=\"æ ‘æ¨¡å‹:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, sticky=tk.W, pady=(5, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        tree_codes = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"gb\", \"ada\"]\n",
    "        for code in tree_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                ttk.Checkbutton(clf_scrollable, text=name,\n",
    "                              variable=self.classifier_vars[code]).grid(\n",
    "                    row=row, column=0, sticky=tk.W, padx=20\n",
    "                )\n",
    "                row += 1\n",
    "        \n",
    "        # å…¶ä»–\n",
    "        ttk.Label(clf_scrollable, text=\"å…¶ä»–:\", font=('', 9, 'bold')).grid(\n",
    "            row=row, column=0, sticky=tk.W, pady=(5, 2)\n",
    "        )\n",
    "        row += 1\n",
    "        other_codes = [\"knn\", \"nb\", \"lr\", \"mlp\"]\n",
    "        for code in other_codes:\n",
    "            if code in all_classifiers:\n",
    "                _, name, _, _, _, _ = all_classifiers[code]\n",
    "                ttk.Checkbutton(clf_scrollable, text=name,\n",
    "                              variable=self.classifier_vars[code]).grid(\n",
    "                    row=row, column=0, sticky=tk.W, padx=20\n",
    "                )\n",
    "                row += 1\n",
    "        \n",
    "        clf_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        clf_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        \n",
    "        # 7. æ§åˆ¶æŒ‰é’®\n",
    "        control_frame = ttk.LabelFrame(scrollable_left, text=\"ğŸ® è¿è¡Œæ§åˆ¶\", padding=\"10\")\n",
    "        control_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        btn_control_frame = ttk.Frame(control_frame)\n",
    "        btn_control_frame.pack(fill=tk.X)\n",
    "        \n",
    "        self.start_btn = ttk.Button(btn_control_frame, text=\"â–¶ å¼€å§‹åˆ†ç±»\", \n",
    "                                    command=self.start_classification, width=15)\n",
    "        self.start_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(btn_control_frame, text=\"â¸ åœæ­¢\", \n",
    "                                   command=self.stop_classification, \n",
    "                                   state=tk.DISABLED, width=15)\n",
    "        self.stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Button(btn_control_frame, text=\"ğŸ“ æ‰“å¼€ç»“æœ\", \n",
    "                  command=self.open_result_dir, width=15).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # è¿›åº¦æ¡\n",
    "        ttk.Label(control_frame, text=\"è¿›åº¦:\").pack(anchor=tk.W, pady=(10, 0))\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress_bar = ttk.Progressbar(control_frame, variable=self.progress_var, \n",
    "                                           maximum=100)\n",
    "        self.progress_bar.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        # çŠ¶æ€\n",
    "        self.status_var = tk.StringVar(value=\"å°±ç»ª\")\n",
    "        ttk.Label(control_frame, textvariable=self.status_var, \n",
    "                 relief=tk.SUNKEN, anchor=tk.W).pack(fill=tk.X)\n",
    "        \n",
    "        # ===== å³ä¾§é¢æ¿ï¼šå›¾ä»¶æ˜¾ç¤º =====\n",
    "        right_frame = ttk.Frame(main_paned, width=900)\n",
    "        main_paned.add(right_frame, weight=2)\n",
    "        \n",
    "        # åˆ›å»ºNotebook\n",
    "        self.notebook = ttk.Notebook(right_frame)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # æ ‡ç­¾é¡µ1ï¼šè¿è¡Œæ—¥å¿—\n",
    "        log_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(log_tab, text=\"ğŸ“ è¿è¡Œæ—¥å¿—\")\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(log_tab, wrap=tk.WORD, \n",
    "                                                  font=('Consolas', 9))\n",
    "        self.log_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # æ ‡ç­¾é¡µ2ï¼šç²¾åº¦å¯¹æ¯”\n",
    "        accuracy_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(accuracy_tab, text=\"ğŸ“Š ç²¾åº¦å¯¹æ¯”\")\n",
    "        \n",
    "        self.accuracy_fig = Figure(figsize=(10, 6), dpi=100)\n",
    "        self.accuracy_canvas = FigureCanvasTkAgg(self.accuracy_fig, accuracy_tab)\n",
    "        self.accuracy_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        toolbar_acc = ttk.Frame(accuracy_tab)\n",
    "        toolbar_acc.pack(fill=tk.X)\n",
    "        NavigationToolbar2Tk(self.accuracy_canvas, toolbar_acc)\n",
    "        \n",
    "        # æ ‡ç­¾é¡µ3ï¼šæ··æ·†çŸ©é˜µ\n",
    "        cm_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(cm_tab, text=\"ğŸ”¥ æ··æ·†çŸ©é˜µ\")\n",
    "        \n",
    "        self.cm_fig = Figure(figsize=(8, 6), dpi=100)\n",
    "        self.cm_canvas = FigureCanvasTkAgg(self.cm_fig, cm_tab)\n",
    "        self.cm_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        toolbar_cm = ttk.Frame(cm_tab)\n",
    "        toolbar_cm.pack(fill=tk.X)\n",
    "        NavigationToolbar2Tk(self.cm_canvas, toolbar_cm)\n",
    "        \n",
    "        # æ ‡ç­¾é¡µ4ï¼šæ—¶é—´å¯¹æ¯”\n",
    "        time_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(time_tab, text=\"â±ï¸ æ—¶é—´å¯¹æ¯”\")\n",
    "        \n",
    "        self.time_fig = Figure(figsize=(10, 6), dpi=100)\n",
    "        self.time_canvas = FigureCanvasTkAgg(self.time_fig, time_tab)\n",
    "        self.time_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        toolbar_time = ttk.Frame(time_tab)\n",
    "        toolbar_time.pack(fill=tk.X)\n",
    "        NavigationToolbar2Tk(self.time_canvas, toolbar_time)\n",
    "        \n",
    "        # æ ‡ç­¾é¡µ5ï¼šåˆ†ç±»ç»“æœé¢„è§ˆ\n",
    "        result_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(result_tab, text=\"ğŸ—ºï¸ ç»“æœé¢„è§ˆ\")\n",
    "        \n",
    "        self.result_fig = Figure(figsize=(10, 6), dpi=100)\n",
    "        self.result_canvas = FigureCanvasTkAgg(self.result_fig, result_tab)\n",
    "        self.result_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        toolbar_result = ttk.Frame(result_tab)\n",
    "        toolbar_result.pack(fill=tk.X)\n",
    "        NavigationToolbar2Tk(self.result_canvas, toolbar_result)\n",
    "    \n",
    "    # ===== è¾…åŠ©å‡½æ•° =====\n",
    "    def toggle_sampling(self):\n",
    "        if self.enable_sampling.get():\n",
    "            self.max_samples_spinbox.config(state=tk.NORMAL)\n",
    "        else:\n",
    "            self.max_samples_spinbox.config(state=tk.DISABLED)\n",
    "    \n",
    "    def refresh_fields(self):\n",
    "        train_shp = self.train_shp_path.get()\n",
    "        if not train_shp or not os.path.exists(train_shp):\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"è¯·å…ˆé€‰æ‹©è®­ç»ƒæ ·æœ¬æ–‡ä»¶ï¼\")\n",
    "            return\n",
    "        \n",
    "        fields = self.backend.get_shapefile_fields(train_shp)\n",
    "        if fields:\n",
    "            fields = [f for f in fields if f.lower() != 'geometry']\n",
    "            \n",
    "            self.class_attr_combo['values'] = fields\n",
    "            self.name_attr_combo['values'] = fields\n",
    "            \n",
    "            if 'class' in fields:\n",
    "                self.class_attr.set('class')\n",
    "            elif 'Class' in fields:\n",
    "                self.class_attr.set('Class')\n",
    "            elif fields:\n",
    "                self.class_attr.set(fields[0])\n",
    "            \n",
    "            if 'name' in fields:\n",
    "                self.name_attr.set('name')\n",
    "            elif 'Name' in fields:\n",
    "                self.name_attr.set('Name')\n",
    "            elif len(fields) > 1:\n",
    "                self.name_attr.set(fields[1])\n",
    "            elif fields:\n",
    "                self.name_attr.set(fields[0])\n",
    "            \n",
    "            messagebox.showinfo(\"æˆåŠŸ\", f\"å·²åŠ è½½ {len(fields)} ä¸ªå­—æ®µ\")\n",
    "        else:\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"æ— æ³•è¯»å–å­—æ®µåˆ—è¡¨ï¼\")\n",
    "    \n",
    "    def browse_image(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©å½±åƒæ–‡ä»¶\",\n",
    "            filetypes=[(\"GeoTIFF\", \"*.tif *.tiff\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.image_path.set(filename)\n",
    "            self.status_var.set(f\"å·²é€‰æ‹©å½±åƒ: {Path(filename).name}\")\n",
    "    \n",
    "    def browse_train_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©è®­ç»ƒæ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.train_shp_path.set(filename)\n",
    "            self.refresh_fields()\n",
    "    \n",
    "    def browse_val_shp(self):\n",
    "        filename = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©éªŒè¯æ ·æœ¬\",\n",
    "            filetypes=[(\"Shapefile\", \"*.shp\"), (\"æ‰€æœ‰æ–‡ä»¶\", \"*.*\")]\n",
    "        )\n",
    "        if filename:\n",
    "            self.val_shp_path.set(filename)\n",
    "    \n",
    "    def browse_output(self):\n",
    "        dirname = filedialog.askdirectory(title=\"é€‰æ‹©è¾“å‡ºç›®å½•\")\n",
    "        if dirname:\n",
    "            self.output_dir.set(dirname)\n",
    "    \n",
    "    def select_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(True)\n",
    "    \n",
    "    def deselect_all_classifiers(self):\n",
    "        for var in self.classifier_vars.values():\n",
    "            var.set(False)\n",
    "    \n",
    "    def select_recommended(self):\n",
    "        recommended = [\"rf\", \"xgb\", \"et\", \"lgb\", \"linear_svc\", \"nystroem_svm\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in recommended)\n",
    "    \n",
    "    def select_fast(self):\n",
    "        fast = [\"rf\", \"et\", \"dt\", \"xgb\", \"lgb\", \"nb\", \"lr\", \"sgd_svm\", \"linear_svc\"]\n",
    "        for code, var in self.classifier_vars.items():\n",
    "            var.set(code in fast)\n",
    "    \n",
    "    def log(self, message):\n",
    "        self.log_queue.put(message)\n",
    "    \n",
    "    def update_log(self):\n",
    "        try:\n",
    "            while True:\n",
    "                message = self.log_queue.get_nowait()\n",
    "                self.log_text.insert(tk.END, message + \"\\n\")\n",
    "                self.log_text.see(tk.END)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        self.root.after(100, self.update_log)\n",
    "    \n",
    "    def update_accuracy_plot(self):\n",
    "        \"\"\"æ›´æ–°ç²¾åº¦å¯¹æ¯”å›¾\"\"\"\n",
    "        if not self.comparison_results:\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(self.comparison_results)\n",
    "        \n",
    "        self.accuracy_fig.clear()\n",
    "        \n",
    "        # åˆ›å»ºå­å›¾\n",
    "        ax1 = self.accuracy_fig.add_subplot(121)\n",
    "        ax2 = self.accuracy_fig.add_subplot(122)\n",
    "        \n",
    "        # ç²¾åº¦å¯¹æ¯”\n",
    "        x = np.arange(len(df))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, df['è®­ç»ƒé›†ç²¾åº¦'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')\n",
    "        ax1.bar(x + width/2, df['éªŒè¯é›†ç²¾åº¦'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')\n",
    "        \n",
    "        ax1.set_xlabel('åˆ†ç±»å™¨', fontsize=11)\n",
    "        ax1.set_ylabel('ç²¾åº¦', fontsize=11)\n",
    "        ax1.set_title('æ€»ä½“ç²¾åº¦å¯¹æ¯”', fontsize=12, fontweight='bold')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        ax1.set_ylim([0, 1.05])\n",
    "        \n",
    "        # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "        for i, (train_acc, val_acc) in enumerate(zip(df['è®­ç»ƒé›†ç²¾åº¦'], df['éªŒè¯é›†ç²¾åº¦'])):\n",
    "            ax1.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', \n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "            ax1.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', \n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        # Kappaå¯¹æ¯”\n",
    "        ax2.bar(x - width/2, df['è®­ç»ƒé›†Kappa'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')\n",
    "        ax2.bar(x + width/2, df['éªŒè¯é›†Kappa'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')\n",
    "        \n",
    "        ax2.set_xlabel('åˆ†ç±»å™¨', fontsize=11)\n",
    "        ax2.set_ylabel('Kappaç³»æ•°', fontsize=11)\n",
    "        ax2.set_title('Kappaç³»æ•°å¯¹æ¯”', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        ax2.set_ylim([0, 1.05])\n",
    "        \n",
    "        self.accuracy_fig.tight_layout()\n",
    "        self.accuracy_canvas.draw()\n",
    "    \n",
    "    def update_confusion_matrix(self, y_true, y_pred, class_names):\n",
    "        \"\"\"æ›´æ–°æ··æ·†çŸ©é˜µæ˜¾ç¤º\"\"\"\n",
    "        self.cm_fig.clear()\n",
    "        ax = self.cm_fig.add_subplot(111)\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # ç»˜åˆ¶çƒ­å›¾\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names,\n",
    "                    cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)\n",
    "        \n",
    "        ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)\n",
    "        ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)\n",
    "        ax.set_title('æœ€ä½³åˆ†ç±»å™¨æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        self.cm_fig.tight_layout()\n",
    "        self.cm_canvas.draw()\n",
    "    \n",
    "    def update_time_plot(self):\n",
    "        \"\"\"æ›´æ–°æ—¶é—´å¯¹æ¯”å›¾\"\"\"\n",
    "        if not self.comparison_results:\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(self.comparison_results)\n",
    "        \n",
    "        self.time_fig.clear()\n",
    "        ax = self.time_fig.add_subplot(111)\n",
    "        \n",
    "        x = np.arange(len(df))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax.bar(x - width/2, df['è®­ç»ƒæ—¶é—´(ç§’)'], width, label='è®­ç»ƒæ—¶é—´', \n",
    "                      alpha=0.8, color='lightgreen')\n",
    "        bars2 = ax.bar(x + width/2, df['é¢„æµ‹æ—¶é—´(ç§’)'], width, label='é¢„æµ‹æ—¶é—´', \n",
    "                      alpha=0.8, color='lightcoral')\n",
    "        \n",
    "        ax.set_xlabel('åˆ†ç±»å™¨', fontsize=11)\n",
    "        ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=11)\n",
    "        ax.set_title('è®­ç»ƒå’Œé¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "        for bars in [bars1, bars2]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.1f}s', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        self.time_fig.tight_layout()\n",
    "        self.time_canvas.draw()\n",
    "    \n",
    "    def update_result_preview(self, image_path, classified_path, class_names, class_colors):\n",
    "        \"\"\"æ›´æ–°åˆ†ç±»ç»“æœé¢„è§ˆ\"\"\"\n",
    "        try:\n",
    "            self.result_fig.clear()\n",
    "            \n",
    "            # è¯»å–å½±åƒå’Œåˆ†ç±»ç»“æœ\n",
    "            img = rxr.open_rasterio(image_path, masked=True)\n",
    "            classified = rxr.open_rasterio(classified_path)\n",
    "            \n",
    "            # åˆ›å»ºå­å›¾\n",
    "            ax1 = self.result_fig.add_subplot(121)\n",
    "            ax2 = self.result_fig.add_subplot(122)\n",
    "            \n",
    "            # æ˜¾ç¤ºåŸå§‹å½±åƒ\n",
    "            if img.shape[0] >= 3:\n",
    "                rgb_data = np.moveaxis(img.values[:3], 0, -1)\n",
    "                p2, p98 = np.percentile(rgb_data[rgb_data > 0], (2, 98))\n",
    "                rgb_display = np.clip((rgb_data - p2) / (p98 - p2), 0, 1)\n",
    "                ax1.imshow(rgb_display)\n",
    "            else:\n",
    "                ax1.imshow(img.values[0], cmap='gray')\n",
    "            \n",
    "            ax1.set_title('åŸå§‹é¥æ„Ÿå½±åƒ', fontsize=12, fontweight='bold')\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ\n",
    "            classified_data = classified.values.squeeze()\n",
    "            \n",
    "            # è·å–ç±»åˆ«\n",
    "            classes = np.unique(classified_data)\n",
    "            classes = classes[classes > 0]\n",
    "            \n",
    "            # åˆ›å»ºé¢œè‰²æ˜ å°„\n",
    "            colors = [class_colors.get(c, 'black') for c in classes]\n",
    "            labels = [class_names.get(c, f'ç±»åˆ«_{c}') for c in classes]\n",
    "            \n",
    "            cmap = mcolors.ListedColormap(colors)\n",
    "            bounds = np.append(classes, classes[-1] + 1) - 0.5\n",
    "            norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "            \n",
    "            # èƒŒæ™¯è®¾ä¸ºé€æ˜\n",
    "            display_data = classified_data.astype(float)\n",
    "            display_data[classified_data == 0] = np.nan\n",
    "            \n",
    "            im = ax2.imshow(display_data, cmap=cmap, norm=norm)\n",
    "            ax2.set_title('åˆ†ç±»ç»“æœï¼ˆæœ€ä½³åˆ†ç±»å™¨ï¼‰', fontsize=12, fontweight='bold')\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            # æ·»åŠ å›¾ä¾‹\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_elements = [Patch(facecolor=color, label=label) \n",
    "                              for color, label in zip(colors, labels)]\n",
    "            ax2.legend(handles=legend_elements, loc='upper left', \n",
    "                      bbox_to_anchor=(1.05, 1), fontsize=9)\n",
    "            \n",
    "            self.result_fig.tight_layout()\n",
    "            self.result_canvas.draw()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"é¢„è§ˆæ˜¾ç¤ºé”™è¯¯: {str(e)}\")\n",
    "    \n",
    "    def export_to_excel(self, out_dir):\n",
    "        \"\"\"å¯¼å‡ºç»“æœåˆ°Excel\"\"\"\n",
    "        if not HAS_OPENPYXL:\n",
    "            self.log(\"âš ï¸  æœªå®‰è£…openpyxlï¼Œæ— æ³•å¯¼å‡ºExcel\")\n",
    "            return\n",
    "        \n",
    "        if not self.comparison_results:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            df = pd.DataFrame(self.comparison_results)\n",
    "            \n",
    "            excel_path = out_dir / \"classification_comparison.xlsx\"\n",
    "            \n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "                # ä¸»ç»“æœè¡¨\n",
    "                df.to_excel(writer, sheet_name='åˆ†ç±»å™¨å¯¹æ¯”', index=False)\n",
    "                \n",
    "                # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨\n",
    "                workbook = writer.book\n",
    "                worksheet = writer.sheets['åˆ†ç±»å™¨å¯¹æ¯”']\n",
    "                \n",
    "                # è®¾ç½®åˆ—å®½\n",
    "                for column in worksheet.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(str(cell.value))\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = min(max_length + 2, 50)\n",
    "                    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "                \n",
    "                # æ·»åŠ ç»Ÿè®¡æ‘˜è¦è¡¨\n",
    "                summary_data = {\n",
    "                    'æŒ‡æ ‡': ['æœ€é«˜ç²¾åº¦', 'æœ€é«˜Kappa', 'æœ€å¿«è®­ç»ƒ', 'æœ€å¿«é¢„æµ‹'],\n",
    "                    'åˆ†ç±»å™¨': [\n",
    "                        df.loc[df['éªŒè¯é›†ç²¾åº¦'].idxmax(), 'åˆ†ç±»å™¨åç§°'],\n",
    "                        df.loc[df['éªŒè¯é›†Kappa'].idxmax(), 'åˆ†ç±»å™¨åç§°'],\n",
    "                        df.loc[df['è®­ç»ƒæ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°'],\n",
    "                        df.loc[df['é¢„æµ‹æ—¶é—´(ç§’)'].idxmin(), 'åˆ†ç±»å™¨åç§°']\n",
    "                    ],\n",
    "                    'æ•°å€¼': [\n",
    "                        f\"{df['éªŒè¯é›†ç²¾åº¦'].max():.4f}\",\n",
    "                        f\"{df['éªŒè¯é›†Kappa'].max():.4f}\",\n",
    "                        f\"{df['è®­ç»ƒæ—¶é—´(ç§’)'].min():.2f}ç§’\",\n",
    "                        f\"{df['é¢„æµ‹æ—¶é—´(ç§’)'].min():.2f}ç§’\"\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                summary_df = pd.DataFrame(summary_data)\n",
    "                summary_df.to_excel(writer, sheet_name='æ€§èƒ½æ‘˜è¦', index=False)\n",
    "            \n",
    "            self.log(f\"âœ“ ExcelæŠ¥å‘Šå·²ä¿å­˜: {excel_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"Excelå¯¼å‡ºå¤±è´¥: {str(e)}\")\n",
    "    \n",
    "    def start_classification(self):\n",
    "        \"\"\"å¼€å§‹åˆ†ç±»\"\"\"\n",
    "        # æ£€æŸ¥è¾“å…¥\n",
    "        if not self.image_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼\")\n",
    "            return\n",
    "        \n",
    "        if not self.train_shp_path.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©è®­ç»ƒæ ·æœ¬ï¼\")\n",
    "            return\n",
    "        \n",
    "        if not self.class_attr.get():\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·é€‰æ‹©ç±»åˆ«ç¼–å·å­—æ®µï¼\")\n",
    "            return\n",
    "        \n",
    "        selected_classifiers = [code for code, var in self.classifier_vars.items() if var.get()]\n",
    "        if not selected_classifiers:\n",
    "            messagebox.showerror(\"é”™è¯¯\", \"è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼\")\n",
    "            return\n",
    "        \n",
    "        # æ€§èƒ½è­¦å‘Š\n",
    "        all_classifiers = self.backend.get_all_classifiers()\n",
    "        very_slow_clfs = []\n",
    "        \n",
    "        for code in selected_classifiers:\n",
    "            if code in all_classifiers:\n",
    "                speed_tag = all_classifiers[code][5]\n",
    "                name = all_classifiers[code][1]\n",
    "                if speed_tag == \"very_slow\":\n",
    "                    very_slow_clfs.append(name)\n",
    "        \n",
    "        if very_slow_clfs:\n",
    "            warning_msg = \"âš ï¸ ä»¥ä¸‹åˆ†ç±»å™¨é¢„æµ‹éå¸¸æ…¢:\\n\"\n",
    "            for clf in very_slow_clfs:\n",
    "                warning_msg += f\"  â€¢ {clf}\\n\"\n",
    "            warning_msg += \"\\næ˜¯å¦ç»§ç»­?\"\n",
    "            \n",
    "            if not messagebox.askyesno(\"æ€§èƒ½è­¦å‘Š\", warning_msg, icon='warning'):\n",
    "                return\n",
    "        \n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.is_running = True\n",
    "        \n",
    "        # æ¸…ç©º\n",
    "        self.log_text.delete(1.0, tk.END)\n",
    "        self.comparison_results = []\n",
    "        \n",
    "        self.log(\"=\"*80)\n",
    "        self.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1\")\n",
    "        self.log(\"=\"*80)\n",
    "        self.log(f\"é€‰æ‹©çš„åˆ†ç±»å™¨: {len(selected_classifiers)} ä¸ª\")\n",
    "        self.log(f\"èƒŒæ™¯å€¼: {self.background_value.get()}\")\n",
    "        self.log(\"\")\n",
    "        \n",
    "        # åˆ‡æ¢åˆ°æ—¥å¿—æ ‡ç­¾é¡µ\n",
    "        self.notebook.select(0)\n",
    "        \n",
    "        thread = threading.Thread(target=self.run_classification, args=(selected_classifiers,))\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "    \n",
    "    def stop_classification(self):\n",
    "        self.is_running = False\n",
    "        self.log(\"\\nâ¸ ç”¨æˆ·è¯·æ±‚åœæ­¢...\")\n",
    "        self.status_var.set(\"å·²åœæ­¢\")\n",
    "    \n",
    "    def run_classification(self, selected_classifiers):\n",
    "        \"\"\"æ‰§è¡Œåˆ†ç±»ï¼ˆä¸»æµç¨‹ï¼‰\"\"\"\n",
    "        try:\n",
    "            out_dir = Path(self.output_dir.get())\n",
    "            out_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # è¯»å–å½±åƒ\n",
    "            self.log(f\"ğŸ“ è¯»å–å½±åƒ...\")\n",
    "            self.status_var.set(\"è¯»å–å½±åƒ...\")\n",
    "            img = rxr.open_rasterio(self.image_path.get(), masked=True)\n",
    "            n_pixels = img.shape[1] * img.shape[2]\n",
    "            self.log(f\"   å°ºå¯¸: {img.shape[1]}Ã—{img.shape[2]} = {n_pixels:,} åƒå…ƒ\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # è¯»å–ç±»åˆ«ä¿¡æ¯\n",
    "            self.log(f\"\\nğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...\")\n",
    "            class_names, class_colors, _ = self.backend.get_class_info_from_shp(\n",
    "                self.train_shp_path.get(), \n",
    "                self.class_attr.get(), \n",
    "                self.name_attr.get()\n",
    "            )\n",
    "            self.class_names_dict = class_names\n",
    "            self.class_colors_dict = class_colors\n",
    "            self.log(f\"   ç±»åˆ«: {list(class_names.values())}\")\n",
    "            \n",
    "            # æå–è®­ç»ƒæ ·æœ¬\n",
    "            self.log(f\"\\nğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            self.status_var.set(\"å¤„ç†è®­ç»ƒæ ·æœ¬...\")\n",
    "            train_mask = self.backend.rasterize_samples(\n",
    "                self.train_shp_path.get(), img, self.class_attr.get()\n",
    "            )\n",
    "            \n",
    "            max_samples = self.max_samples.get() if self.enable_sampling.get() else None\n",
    "            \n",
    "            X_train, y_train, n_nan, n_inf, n_sampled = self.backend.extract_samples(\n",
    "                img, train_mask, \n",
    "                ignore_background=self.ignore_background.get(),\n",
    "                background_value=self.background_value.get(),\n",
    "                max_samples=max_samples\n",
    "            )\n",
    "            \n",
    "            self.log(f\"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}\")\n",
    "            if n_nan > 0:\n",
    "                self.log(f\"   â””â”€ ç§»é™¤NaN: {n_nan:,}\")\n",
    "            if n_sampled > 0:\n",
    "                self.log(f\"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}\")\n",
    "            \n",
    "            if not self.is_running:\n",
    "                return\n",
    "            \n",
    "            # æå–éªŒè¯æ ·æœ¬\n",
    "            val_exists = os.path.exists(self.val_shp_path.get())\n",
    "            if val_exists:\n",
    "                self.log(f\"\\nâœ… å¤„ç†éªŒè¯æ ·æœ¬...\")\n",
    "                val_mask = self.backend.rasterize_samples(\n",
    "                    self.val_shp_path.get(), img, self.class_attr.get()\n",
    "                )\n",
    "                \n",
    "                if self.ignore_background.get():\n",
    "                    background_mask = self.backend.get_background_mask(\n",
    "                        img, self.background_value.get()\n",
    "                    )\n",
    "                    valid_val = (val_mask > 0) & (~background_mask)\n",
    "                else:\n",
    "                    valid_val = val_mask > 0\n",
    "                \n",
    "                yv_true = val_mask[valid_val]\n",
    "                self.log(f\"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}\")\n",
    "            \n",
    "            # åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°\n",
    "            all_classifiers = self.backend.get_all_classifiers(\n",
    "                self.n_estimators.get(), \n",
    "                fast_mode=self.fast_mode.get(),\n",
    "                n_train_samples=len(y_train)\n",
    "            )\n",
    "            \n",
    "            comparison_results = []\n",
    "            total_start_time = time.time()\n",
    "            best_accuracy = 0\n",
    "            best_clf_code = None\n",
    "            \n",
    "            for i, clf_code in enumerate(selected_classifiers):\n",
    "                if not self.is_running:\n",
    "                    break\n",
    "                \n",
    "                clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(f\"[{i+1}/{len(selected_classifiers)}] {clf_name}\")\n",
    "                self.log(f\"{'='*80}\")\n",
    "                \n",
    "                self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] è®­ç»ƒ {clf_name}...\")\n",
    "                \n",
    "                clf_dir = out_dir / clf_code\n",
    "                clf_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    # æ•°æ®é¢„å¤„ç†\n",
    "                    label_encoder = None\n",
    "                    scaler = None\n",
    "                    X_train_use = X_train.copy()\n",
    "                    y_train_use = y_train.copy()\n",
    "                    \n",
    "                    if needs_encoding:\n",
    "                        self.log(\"   ğŸ”„ æ ‡ç­¾ç¼–ç ...\")\n",
    "                        label_encoder = LabelEncoder()\n",
    "                        y_train_use = label_encoder.fit_transform(y_train)\n",
    "                    \n",
    "                    if needs_scaling:\n",
    "                        self.log(\"   ğŸ“ ç‰¹å¾ç¼©æ”¾...\")\n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_use = scaler.fit_transform(X_train_use)\n",
    "                    \n",
    "                    # è®­ç»ƒ\n",
    "                    self.log(\"   ğŸ”¨ è®­ç»ƒä¸­...\")\n",
    "                    train_start = time.time()\n",
    "                    clf.fit(X_train_use, y_train_use)\n",
    "                    train_time = time.time() - train_start\n",
    "                    self.log(f\"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’\")\n",
    "                    \n",
    "                    # è®­ç»ƒé›†ç²¾åº¦\n",
    "                    y_train_pred = clf.predict(X_train_use)\n",
    "                    \n",
    "                    if label_encoder is not None:\n",
    "                        y_train_pred = label_encoder.inverse_transform(y_train_pred)\n",
    "                    \n",
    "                    train_metrics = self.backend.calculate_metrics(y_train, y_train_pred)\n",
    "                    self.log(f\"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}\")\n",
    "                    \n",
    "                    if not self.is_running:\n",
    "                        break\n",
    "                    \n",
    "                    # é¢„æµ‹æ•´å¹…å½±åƒ\n",
    "                    self.log(\"   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...\")\n",
    "                    self.status_var.set(f\"[{i+1}/{len(selected_classifiers)}] é¢„æµ‹ {clf_name}...\")\n",
    "                    \n",
    "                    pred_start = time.time()\n",
    "                    classified_path = clf_dir / f\"classified_{clf_code}.tif\"\n",
    "                    \n",
    "                    def update_progress(progress):\n",
    "                        self.progress_var.set(progress)\n",
    "                    \n",
    "                    self.backend.predict_by_block(\n",
    "                        clf, img, classified_path, \n",
    "                        block_size=self.block_size.get(),\n",
    "                        ignore_background=self.ignore_background.get(),\n",
    "                        background_value=self.background_value.get(),\n",
    "                        progress_callback=update_progress,\n",
    "                        label_encoder=label_encoder,\n",
    "                        scaler=scaler\n",
    "                    )\n",
    "                    \n",
    "                    pred_time = time.time() - pred_start\n",
    "                    self.log(f\"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’\")\n",
    "                    \n",
    "                    # éªŒè¯é›†ç²¾åº¦\n",
    "                    val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan}\n",
    "                    yv_pred = None\n",
    "                    \n",
    "                    if val_exists:\n",
    "                        with rxr.open_rasterio(classified_path) as pred_img:\n",
    "                            pred_arr = pred_img.values.squeeze()\n",
    "                        \n",
    "                        yv_pred = pred_arr[valid_val]\n",
    "                        val_metrics = self.backend.calculate_metrics(yv_true, yv_pred)\n",
    "                        self.log(f\"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}\")\n",
    "                        \n",
    "                        # è®°å½•æœ€ä½³åˆ†ç±»å™¨\n",
    "                        if val_metrics['overall_accuracy'] > best_accuracy:\n",
    "                            best_accuracy = val_metrics['overall_accuracy']\n",
    "                            best_clf_code = clf_code\n",
    "                            self.best_result_path = classified_path\n",
    "                            self.current_y_true = yv_true\n",
    "                            self.current_y_pred = yv_pred\n",
    "                    \n",
    "                    # è®°å½•ç»“æœ\n",
    "                    result = {\n",
    "                        'åˆ†ç±»å™¨ä»£ç ': clf_code,\n",
    "                        'åˆ†ç±»å™¨åç§°': clf_name,\n",
    "                        'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],\n",
    "                        'è®­ç»ƒé›†Kappa': train_metrics['kappa'],\n",
    "                        'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],\n",
    "                        'éªŒè¯é›†Kappa': val_metrics['kappa'],\n",
    "                        'è®­ç»ƒæ—¶é—´(ç§’)': train_time,\n",
    "                        'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,\n",
    "                    }\n",
    "                    comparison_results.append(result)\n",
    "                    self.comparison_results = comparison_results\n",
    "                    \n",
    "                    # å®æ—¶æ›´æ–°å›¾è¡¨\n",
    "                    self.root.after(0, self.update_accuracy_plot)\n",
    "                    self.root.after(0, self.update_time_plot)\n",
    "                    \n",
    "                    self.log(f\"   âœ… {clf_name} å®Œæˆ!\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    self.log(f\"   âŒ {clf_name} å¤±è´¥: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                self.progress_var.set((i + 1) / len(selected_classifiers) * 100)\n",
    "            \n",
    "            # ç”ŸæˆæŠ¥å‘Š\n",
    "            if comparison_results and self.is_running:\n",
    "                total_time = time.time() - total_start_time\n",
    "                \n",
    "                self.log(f\"\\n{'='*80}\")\n",
    "                self.log(\"ğŸ“ ç”ŸæˆæŠ¥å‘Š...\")\n",
    "                \n",
    "                comparison_df = pd.DataFrame(comparison_results)\n",
    "                \n",
    "                # ä¿å­˜CSV\n",
    "                comparison_df.to_csv(out_dir / \"classifier_comparison.csv\", \n",
    "                                   index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # å¯¼å‡ºExcel\n",
    "                self.export_to_excel(out_dir)\n",
    "                \n",
    "                # æ–‡å­—æŠ¥å‘Š\n",
    "                with open(out_dir / \"comparison_summary.txt\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š\\n\")\n",
    "                    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "                    f.write(f\"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                    f.write(f\"å½±åƒ: {img.shape[1]}Ã—{img.shape[2]}\\n\")\n",
    "                    f.write(f\"è®­ç»ƒæ ·æœ¬: {len(y_train):,}\\n\")\n",
    "                    f.write(f\"æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\\n\")\n",
    "                    f.write(f\"æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\\n\\n\")\n",
    "                    \n",
    "                    sorted_df = comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)\n",
    "                    f.write(\"éªŒè¯é›†ç²¾åº¦æ’å:\\n\")\n",
    "                    f.write(\"-\"*70 + \"\\n\")\n",
    "                    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):\n",
    "                        f.write(f\"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - \"\n",
    "                               f\"ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}\\n\")\n",
    "                \n",
    "                # æ›´æ–°æ··æ·†çŸ©é˜µ\n",
    "                if self.current_y_true is not None and self.current_y_pred is not None:\n",
    "                    val_classes = sorted(np.unique(self.current_y_true))\n",
    "                    val_class_names = [class_names.get(c, f'ç±»åˆ«_{c}') for c in val_classes]\n",
    "                    self.root.after(0, lambda: self.update_confusion_matrix(\n",
    "                        self.current_y_true, self.current_y_pred, val_class_names\n",
    "                    ))\n",
    "                \n",
    "                # æ›´æ–°ç»“æœé¢„è§ˆ\n",
    "                if self.best_result_path:\n",
    "                    self.root.after(0, lambda: self.update_result_preview(\n",
    "                        self.image_path.get(), self.best_result_path, \n",
    "                        class_names, class_colors\n",
    "                    ))\n",
    "                \n",
    "                self.log(\"âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!\")\n",
    "                self.log(f\"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ\")\n",
    "                \n",
    "                best_clf = comparison_df.loc[comparison_df['éªŒè¯é›†ç²¾åº¦'].idxmax()]\n",
    "                self.log(f\"\\nğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\")\n",
    "                \n",
    "                self.status_var.set(f\"âœ… å®Œæˆ! æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']}\")\n",
    "                \n",
    "                # åˆ‡æ¢åˆ°ç²¾åº¦å¯¹æ¯”æ ‡ç­¾é¡µ\n",
    "                self.root.after(0, lambda: self.notebook.select(1))\n",
    "                \n",
    "                messagebox.showinfo(\"ä»»åŠ¡å®Œæˆ\", \n",
    "                    f\"ğŸ‰ åˆ†ç±»ä»»åŠ¡å®Œæˆ!\\n\\n\"\n",
    "                    f\"âœ… æˆåŠŸ: {len(comparison_results)}/{len(selected_classifiers)}\\n\"\n",
    "                    f\"ğŸ† æœ€ä½³: {best_clf['åˆ†ç±»å™¨åç§°']} ({best_clf['éªŒè¯é›†ç²¾åº¦']:.4f})\\n\"\n",
    "                    f\"ğŸ“Š ç»“æœå·²å¯¼å‡ºä¸ºExcelå’ŒCSV\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"\\nâŒ é”™è¯¯: {str(e)}\")\n",
    "            import traceback\n",
    "            self.log(traceback.format_exc())\n",
    "            messagebox.showerror(\"é”™è¯¯\", f\"å‘ç”Ÿé”™è¯¯:\\n{str(e)}\")\n",
    "            self.status_var.set(\"âŒ é”™è¯¯\")\n",
    "        \n",
    "        finally:\n",
    "            self.start_btn.config(state=tk.NORMAL)\n",
    "            self.stop_btn.config(state=tk.DISABLED)\n",
    "            self.progress_var.set(0)\n",
    "            self.is_running = False\n",
    "    \n",
    "    def open_result_dir(self):\n",
    "        \"\"\"æ‰“å¼€ç»“æœç›®å½•\"\"\"\n",
    "        out_dir = Path(self.output_dir.get())\n",
    "        if out_dir.exists():\n",
    "            import subprocess\n",
    "            import platform\n",
    "            \n",
    "            if platform.system() == \"Windows\":\n",
    "                os.startfile(out_dir)\n",
    "            elif platform.system() == \"Darwin\":\n",
    "                subprocess.Popen([\"open\", out_dir])\n",
    "            else:\n",
    "                subprocess.Popen([\"xdg-open\", out_dir])\n",
    "        else:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"ç»“æœç›®å½•ä¸å­˜åœ¨ï¼\")\n",
    "\n",
    "# ==================== ä¸»ç¨‹åºå…¥å£ ====================\n",
    "def main():\n",
    "    \"\"\"ç¨‹åºå…¥å£\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\næ­£åœ¨æ£€æŸ¥ä¾èµ–åº“...\")\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    app = ClassificationGUI(root)\n",
    "    \n",
    "    # æ¬¢è¿ä¿¡æ¯\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"  é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.1 - ä¸“ä¸šç‰ˆ\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"\\nä¸»è¦ç‰¹æ€§:\")\n",
    "    app.log(\"  âœ“ è‡ªå®šä¹‰èƒŒæ™¯å€¼è¾“å…¥\")\n",
    "    app.log(\"  âœ“ å­—æ®µä¸‹æ‹‰æ¡†è‡ªåŠ¨è¯†åˆ«\")\n",
    "    app.log(\"  âœ“ å®æ—¶ç²¾åº¦å¯¹æ¯”å›¾è¡¨\")\n",
    "    app.log(\"  âœ“ æ··æ·†çŸ©é˜µå¯è§†åŒ–\")\n",
    "    app.log(\"  âœ“ åˆ†ç±»ç»“æœé¢„è§ˆ\")\n",
    "    app.log(\"  âœ“ Excelæ ¼å¼æŠ¥å‘Šå¯¼å‡º\")\n",
    "    app.log(\"\\nä½¿ç”¨æµç¨‹:\")\n",
    "    app.log(\"  1. é€‰æ‹©å½±åƒå’Œæ ·æœ¬æ–‡ä»¶\")\n",
    "    app.log(\"  2. ç‚¹å‡»'åˆ·æ–°å­—æ®µåˆ—è¡¨'é€‰æ‹©ç±»åˆ«å­—æ®µ\")\n",
    "    app.log(\"  3. è®¾ç½®èƒŒæ™¯å€¼å’Œå…¶ä»–å‚æ•°\")\n",
    "    app.log(\"  4. é€‰æ‹©åˆ†ç±»å™¨\")\n",
    "    app.log(\"  5. ç‚¹å‡»'å¼€å§‹åˆ†ç±»'\")\n",
    "    app.log(\"  6. æŸ¥çœ‹å³ä¾§å®æ—¶å›¾è¡¨\")\n",
    "    app.log(\"=\"*80)\n",
    "    app.log(\"\")\n",
    "    \n",
    "    print(\"\\nâœ“ ç³»ç»Ÿå¯åŠ¨æˆåŠŸ!\")\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
