#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ - Streamlit Webç‰ˆ v4.4
==========================================
å¢å¼ºç‰ˆï¼šè‡ªåŠ¨è·å–åƒå…ƒå¤§å°å¹¶è®¡ç®—åƒå…ƒé¢ç§¯
"""

import os
import sys
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import seaborn as sns
import geopandas as gpd
import rioxarray as rxr
import xarray as xr
from rasterio import features
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, 
                              AdaBoostClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.kernel_approximation import Nystroem, RBFSampler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report, 
                           cohen_kappa_score, precision_score, recall_score, f1_score)
import warnings
warnings.filterwarnings('ignore')

import streamlit as st
from pathlib import Path
import tempfile
import base64
import zipfile
import shutil
import gc
from io import BytesIO

sns.set_style("whitegrid")

# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans", "Arial Unicode MS"]
plt.rcParams["axes.unicode_minus"] = False

# æ£€æŸ¥å¯é€‰åº“
try:
    import openpyxl
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False
    st.warning("âš ï¸ æœªå®‰è£…openpyxlï¼Œå°†æ— æ³•å¯¼å‡ºExcelæ–‡ä»¶")

# ==================== åç«¯å¤„ç†ç±» ====================
class ClassificationBackend:
    """åˆ†ç±»å¤„ç†åç«¯"""
    
    def __init__(self):
        self.RANDOM_STATE = 42
        
        # é¢„å®šä¹‰é¢œè‰²
        self.LANDUSE_COLORS = {
            "æ°´ä½“": "lightblue", "æ²³æµ": "blue", "æ¹–æ³Š": "deepskyblue",
            "æ¤è¢«": "forestgreen", "æ£®æ—": "darkgreen", "è‰åœ°": "limegreen",
            "å†œç”°": "yellowgreen", "è€•åœ°": "olivedrab",
            "å»ºç­‘": "gray", "åŸå¸‚": "dimgray", "å±…æ°‘åœ°": "slategray",
            "è£¸åœ°": "tan", "æ²™åœ°": "wheat", "å…¶ä»–": "darkred"
        }
        
        self.COLOR_PALETTE = ['forestgreen', 'lightblue', 'gray', 'tan', 'yellow', 
                             'darkred', 'purple', 'orange', 'pink', 'brown']
        
        # æ£€æŸ¥å¯é€‰åº“
        self.check_optional_libraries()
    
    def check_optional_libraries(self):
        """æ£€æŸ¥å¯é€‰åº“æ˜¯å¦å¯ç”¨"""
        self.has_xgboost = False
        self.has_lightgbm = False
        
        try:
            import xgboost
            from xgboost import XGBClassifier
            _ = XGBClassifier(n_estimators=10, verbosity=0)
            self.has_xgboost = True
        except Exception:
            pass
        
        try:
            import lightgbm
            from lightgbm import LGBMClassifier
            _ = LGBMClassifier(n_estimators=10, verbose=-1)
            self.has_lightgbm = True
        except Exception:
            pass
    
    def get_all_classifiers(self, n_estimators=100, fast_mode=False, n_train_samples=None):
        """è·å–æ‰€æœ‰å¯ç”¨åˆ†ç±»å™¨"""
        if fast_mode:
            n_est = min(50, n_estimators)
            max_depth = 10
            max_iter = 200
        else:
            n_est = n_estimators
            max_depth = 20
            max_iter = 500
        
        if n_train_samples:
            n_components = min(1000, n_train_samples // 2)
        else:
            n_components = 1000
        
        classifiers = {
            "rf": (RandomForestClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE, 
                                         verbose=0, max_depth=max_depth, min_samples_split=5, 
                                         max_features='sqrt'),
                  "éšæœºæ£®æ—", "Random Forest", False, False, "fast"),
            
            "et": (ExtraTreesClassifier(n_estimators=n_est, n_jobs=-1, random_state=self.RANDOM_STATE,
                                       verbose=0, max_depth=max_depth, min_samples_split=5, max_features='sqrt'),
                  "æç«¯éšæœºæ ‘", "Extra Trees", False, False, "fast"),
            
            "dt": (DecisionTreeClassifier(random_state=self.RANDOM_STATE, max_depth=max_depth,
                                         min_samples_split=5, min_samples_leaf=2),
                  "å†³ç­–æ ‘", "Decision Tree", False, False, "very_fast"),
            
            "svm_linear": (SVC(kernel="linear", C=1.0, cache_size=500, probability=True, 
                             random_state=self.RANDOM_STATE, max_iter=max_iter),
                          "SVM-çº¿æ€§æ ¸", "SVM Linear", False, True, "medium"),
            
            "linear_svc": (CalibratedClassifierCV(LinearSVC(C=1.0, max_iter=max_iter, random_state=self.RANDOM_STATE,
                                                           dual=False, loss='squared_hinge'), cv=3),
                          "çº¿æ€§SVM(å¿«)", "Linear SVM", False, True, "fast"),
            
            "sgd_svm": (SGDClassifier(loss='hinge', penalty='l2', max_iter=max_iter, n_jobs=-1,
                                     random_state=self.RANDOM_STATE, learning_rate='optimal'),
                       "SGD-SVM", "SGD SVM", False, True, "very_fast"),
            
            "nystroem_svm": (Pipeline([
                ("feature_map", Nystroem(kernel='rbf', gamma=0.1, n_components=n_components, 
                                        random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "æ ¸è¿‘ä¼¼SVM", "Nystroem SVM", False, True, "fast"),
            
            "rbf_sampler_svm": (Pipeline([
                ("feature_map", RBFSampler(gamma=0.1, n_components=n_components, random_state=self.RANDOM_STATE)),
                ("sgd", SGDClassifier(max_iter=max_iter, random_state=self.RANDOM_STATE))
            ]), "RBFé‡‡æ ·SVM", "RBF Sampler", False, True, "fast"),
            
            "svm_rbf": (SVC(kernel="rbf", C=1.0, gamma='scale', cache_size=500, probability=True, 
                          random_state=self.RANDOM_STATE),
                       "SVM-RBFæ ¸âš ï¸", "SVM RBF", False, True, "very_slow"),
            
            "knn": (KNeighborsClassifier(n_neighbors=5, n_jobs=-1, algorithm='ball_tree', leaf_size=30),
                   "Kè¿‘é‚»", "KNN", False, True, "slow"),
            
            "nb": (GaussianNB(), "æœ´ç´ è´å¶æ–¯", "Naive Bayes", False, False, "very_fast"),
            
            "gb": (GradientBoostingClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=5,
                                             random_state=self.RANDOM_STATE, verbose=0, subsample=0.8),
                  "æ¢¯åº¦æå‡", "Gradient Boosting", False, False, "medium"),
            
            "ada": (AdaBoostClassifier(n_estimators=n_est, learning_rate=1.0, 
                                      random_state=self.RANDOM_STATE, algorithm='SAMME'),
                   "AdaBoost", "AdaBoost", False, False, "medium"),
            
            "lr": (LogisticRegression(max_iter=max_iter, n_jobs=-1, random_state=self.RANDOM_STATE,
                                     verbose=0, solver='lbfgs', multi_class='multinomial'),
                  "é€»è¾‘å›å½’", "Logistic Regression", False, True, "very_fast"),
            
            "mlp": (MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=max_iter, random_state=self.RANDOM_STATE,
                                 verbose=False, early_stopping=True, validation_fraction=0.1, 
                                 n_iter_no_change=10, learning_rate='adaptive'),
                   "ç¥ç»ç½‘ç»œ", "MLP", False, True, "medium"),
        }
        
        if self.has_xgboost:
            try:
                from xgboost import XGBClassifier
                classifiers["xgb"] = (
                    XGBClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=6, n_jobs=-1,
                                 random_state=self.RANDOM_STATE, verbosity=0, tree_method='hist',
                                 subsample=0.8, colsample_bytree=0.8),
                    "XGBoost", "XGBoost", True, False, "fast"
                )
            except Exception:
                pass
        
        if self.has_lightgbm:
            try:
                from lightgbm import LGBMClassifier
                classifiers["lgb"] = (
                    LGBMClassifier(n_estimators=n_est, learning_rate=0.1, max_depth=max_depth, n_jobs=-1,
                                  random_state=self.RANDOM_STATE, verbose=-1, num_leaves=31,
                                  subsample=0.8, colsample_bytree=0.8, force_col_wise=True),
                    "LightGBM", "LightGBM", False, False, "very_fast"
                )
            except Exception:
                pass
        
        return classifiers
    
    def get_background_mask(self, image, background_value=0):
        """è·å–èƒŒæ™¯æ©è†œ"""
        data = image.values
        if background_value == 0:
            background_mask = np.all(data == 0, axis=0)
        else:
            background_mask = np.all(data == background_value, axis=0)
        return background_mask
    
    def get_shapefile_fields(self, shp_path):
        """è·å–shapefileçš„æ‰€æœ‰å­—æ®µå"""
        try:
            gdf = gpd.read_file(shp_path)
            return list(gdf.columns)
        except Exception as e:
            st.error(f"è¯»å–shapefileå­—æ®µå¤±è´¥: {e}")
            return []
    
    def get_class_info_from_shp(self, shp_path, class_attr, name_attr):
        """ä»shpæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯"""
        gdf = gpd.read_file(shp_path)
        
        # âœ… ç¡®ä¿ç±»åˆ«å­—æ®µæ˜¯æ•´æ•°ç±»å‹
        try:
            gdf[class_attr] = gdf[class_attr].astype(int)
        except (ValueError, TypeError) as e:
            st.warning(f"âš ï¸ ç±»åˆ«å­—æ®µè½¬æ¢ä¸ºæ•´æ•°æ—¶å‡ºé”™: {e}")
        
        if name_attr not in gdf.columns or name_attr == class_attr:
            gdf[name_attr] = gdf[class_attr].apply(lambda x: f"ç±»åˆ«_{x}")
        
        class_info = gdf[[class_attr, name_attr]].drop_duplicates()
        class_names = dict(zip(class_info[class_attr], class_info[name_attr]))
        
        class_colors = {}
        for i, (class_id, class_name) in enumerate(class_names.items()):
            color_found = False
            for key, color in self.LANDUSE_COLORS.items():
                if key in str(class_name):
                    class_colors[class_id] = color
                    color_found = True
                    break
            if not color_found:
                class_colors[class_id] = self.COLOR_PALETTE[i % len(self.COLOR_PALETTE)]
        
        return class_names, class_colors, sorted(class_names.keys())
    
    def rasterize_samples(self, shp, ref_img, attr):
        """çŸ¢é‡æ …æ ¼åŒ–"""
        gdf = gpd.read_file(shp)
        gdf = gdf.to_crs(ref_img.rio.crs)
        shapes = ((geom, value) for geom, value in zip(gdf.geometry, gdf[attr]))
        
        arr = features.rasterize(shapes=shapes, out_shape=ref_img.shape[1:],
                                transform=ref_img.rio.transform(), fill=0,
                                all_touched=True, dtype="uint16")
        return arr
    
    def extract_samples(self, image, mask, ignore_background=True, background_value=0, max_samples=None):
        """æå–æ ·æœ¬"""
        data = np.moveaxis(image.values, 0, -1)
        valid = mask > 0
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
            valid = valid & (~background_mask)
        
        X = data[valid]
        y = mask[valid]
        
        # æ¸…ç†NaNå’ŒInf
        nan_mask = np.isnan(X).any(axis=1)
        inf_mask = np.isinf(X).any(axis=1)
        bad_mask = nan_mask | inf_mask
        
        n_nan = np.sum(nan_mask)
        n_inf = np.sum(inf_mask)
        
        X = X[~bad_mask]
        y = y[~bad_mask]
        
        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        if len(y) == 0:
            return X, y, n_nan, n_inf, 0
        
        # åˆ†å±‚é‡‡æ ·
        n_sampled = 0
        if max_samples is not None and len(y) > max_samples:
            n_original = len(y)
            unique_classes = np.unique(y)
            
            if len(unique_classes) > 1:
                splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_samples, 
                                                 random_state=self.RANDOM_STATE)
                sample_idx, _ = next(splitter.split(X, y))
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
            else:
                np.random.seed(self.RANDOM_STATE)
                sample_idx = np.random.choice(len(y), max_samples, replace=False)
                X = X[sample_idx]
                y = y[sample_idx]
                n_sampled = n_original - len(y)
        
        return X, y, n_nan, n_inf, n_sampled
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        return {
            'overall_accuracy': accuracy_score(y_true, y_pred),
            'kappa': cohen_kappa_score(y_true, y_pred),
            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),
            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),
            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),
        }
    
    def estimate_prediction_time(self, clf_code, n_pixels, speed_tag):
        """ä¼°ç®—é¢„æµ‹æ—¶é—´"""
        time_per_million = {"very_fast": 1, "fast": 3, "medium": 10, "slow": 30, "very_slow": 300}
        base_time = time_per_million.get(speed_tag, 10)
        return (n_pixels / 1_000_000) * base_time
    
    def predict_by_block(self, model, image, out_path, block_size=512, 
                        ignore_background=True, background_value=0, progress_callback=None,
                        label_encoder=None, scaler=None):
        """åˆ†å—é¢„æµ‹"""
        height, width = image.shape[1], image.shape[2]
        prediction = np.zeros((height, width), dtype='uint16')
        
        if ignore_background:
            background_mask = self.get_background_mask(image, background_value)
        
        total_blocks = int(np.ceil(height / block_size))
        
        for i, y in enumerate(range(0, height, block_size)):
            h = min(block_size, height - y)
            block_data = image.isel(y=slice(y, y+h)).values
            data = np.moveaxis(block_data, 0, -1)
            original_shape = data.shape
            data_flat = data.reshape(-1, data.shape[-1])
            
            if ignore_background:
                block_bg_mask = background_mask[y:y+h, :].flatten()
                non_bg_indices = ~block_bg_mask
                
                if np.any(non_bg_indices):
                    data_to_predict = np.nan_to_num(data_flat[non_bg_indices], 
                                                   nan=0.0, posinf=0.0, neginf=0.0)
                    
                    if scaler is not None:
                        data_to_predict = scaler.transform(data_to_predict)
                    
                    preds_non_bg = model.predict(data_to_predict)
                    
                    if label_encoder is not None:
                        preds_non_bg = label_encoder.inverse_transform(preds_non_bg)
                    
                    preds_flat = np.zeros(len(data_flat), dtype='uint16')
                    preds_flat[non_bg_indices] = preds_non_bg
                    preds = preds_flat.reshape(original_shape[0], original_shape[1])
                else:
                    preds = np.zeros((original_shape[0], original_shape[1]), dtype='uint16')
            else:
                data_flat = np.nan_to_num(data_flat, nan=0.0, posinf=0.0, neginf=0.0)
                
                if scaler is not None:
                    data_flat = scaler.transform(data_flat)
                
                preds = model.predict(data_flat)
                
                if label_encoder is not None:
                    preds = label_encoder.inverse_transform(preds)
                
                preds = preds.reshape(original_shape[0], original_shape[1]).astype("uint16")
            
            prediction[y:y+h, :] = preds
            
            if progress_callback:
                progress_callback((i + 1) / total_blocks)
        
        # ä¿å­˜ç»“æœ
        prediction_da = xr.DataArray(prediction, dims=['y', 'x'],
                                     coords={'y': image.coords['y'], 'x': image.coords['x']})
        
        prediction_da.rio.write_crs(image.rio.crs, inplace=True)
        prediction_da.rio.write_transform(image.rio.transform(), inplace=True)
        prediction_da.rio.write_nodata(background_value, inplace=True)
        
        prediction_da.rio.to_raster(out_path, driver='GTiff', dtype='uint16', 
                                    compress='lzw', tiled=True)
        return out_path

    def get_pixel_info_from_image(self, image):
        """ä»å½±åƒä¸­è·å–åƒå…ƒå¤§å°å’Œé¢ç§¯ä¿¡æ¯"""
        try:
            # è·å–åƒå…ƒå¤§å°ï¼ˆä»transformä¸­ï¼‰
            transform = image.rio.transform()
            pixel_width = abs(transform[0])  # åƒå…ƒå®½åº¦ï¼ˆç±³ï¼‰
            pixel_height = abs(transform[4])  # åƒå…ƒé«˜åº¦ï¼ˆç±³ï¼‰
            
            # è®¡ç®—åƒå…ƒé¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
            pixel_area_m2 = pixel_width * pixel_height
            
            # è½¬æ¢ä¸ºå…¬é¡·ï¼ˆ1å…¬é¡· = 10000å¹³æ–¹ç±³ï¼‰
            pixel_area_ha = pixel_area_m2 / 10000
            
            # è·å–åæ ‡å‚è€ƒç³»ç»Ÿ
            crs = image.rio.crs
            
            return {
                'pixel_width': pixel_width,
                'pixel_height': pixel_height,
                'pixel_area_m2': pixel_area_m2,
                'pixel_area_ha': pixel_area_ha,
                'crs': crs,
                'is_geographic': crs.is_geographic if crs else False
            }
        except Exception as e:
            st.error(f"è·å–åƒå…ƒä¿¡æ¯å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                'pixel_width': 30.0,
                'pixel_height': 30.0,
                'pixel_area_m2': 900.0,
                'pixel_area_ha': 0.09,
                'crs': None,
                'is_geographic': False
            }

    def calculate_class_areas(self, classification_result, class_names, pixel_area_ha=1.0):
        """è®¡ç®—å„ç±»åˆ«é¢ç§¯"""
        # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„åƒç´ æ•°é‡
        unique, counts = np.unique(classification_result, return_counts=True)
        
        area_stats = {}
        total_pixels = np.sum(counts[unique != 0])  # æ’é™¤èƒŒæ™¯
        
        for class_id, count in zip(unique, counts):
            if class_id == 0:  # è·³è¿‡èƒŒæ™¯
                continue
            
            # âœ… ç¡®ä¿ class_id æ˜¯æ•´æ•°
            try:
                class_id_int = int(class_id)
            except (ValueError, TypeError):
                class_id_int = class_id
            
            class_name = class_names.get(class_id_int, f"æœªçŸ¥ç±»åˆ«_{class_id}")
            area_ha = count * pixel_area_ha
            percentage = (count / total_pixels) * 100 if total_pixels > 0 else 0
            
            area_stats[class_name] = {
                'class_id': class_id_int,
                'pixel_count': int(count),
                'area_ha': float(area_ha),
                'percentage': float(percentage)
            }
        
        return area_stats

    def create_classification_preview(self, classification_result, class_names, class_colors, figsize=(10, 8)):
        """åˆ›å»ºåˆ†ç±»ç»“æœé¢„è§ˆå›¾"""
        fig, ax = plt.subplots(figsize=figsize)
        
        # åˆ›å»ºé¢œè‰²æ˜ å°„
        cmap_colors = []
        class_ids = []
        
        # æ·»åŠ èƒŒæ™¯è‰²ï¼ˆé»‘è‰²ï¼‰
        cmap_colors.append('black')
        class_ids.append(0)
        
        for class_id, class_name in class_names.items():
            color = class_colors.get(class_id, 'gray')
            cmap_colors.append(color)
            # âœ… ç¡®ä¿ class_id æ˜¯æ•´æ•°ç±»å‹
            try:
                class_id_int = int(class_id)
            except (ValueError, TypeError):
                class_id_int = class_id
            class_ids.append(class_id_int)
        
        # åˆ›å»ºè‡ªå®šä¹‰é¢œè‰²æ˜ å°„
        from matplotlib.colors import ListedColormap
        cmap = ListedColormap(cmap_colors)
        
        # âœ… ç¡®ä¿æ‰€æœ‰ class_ids éƒ½æ˜¯æ•´æ•°
        max_class_id = max([int(cid) if isinstance(cid, (int, str)) else 0 for cid in class_ids])
        
        # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
        im = ax.imshow(classification_result, cmap=cmap, 
                    vmin=0, vmax=max_class_id)
        
        # åˆ›å»ºå›¾ä¾‹ï¼ˆæ’é™¤èƒŒæ™¯ï¼‰
        legend_elements = []
        for class_id, class_name in class_names.items():
            color = class_colors.get(class_id, 'gray')
            legend_elements.append(plt.Rectangle((0, 0), 1, 1, facecolor=color, 
                                            label=f"{class_name} ({class_id})"))
        
        ax.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.set_title('åˆ†ç±»ç»“æœé¢„è§ˆ')
        ax.axis('off')
        
        plt.tight_layout()
        return fig

    def create_area_pie_chart(self, area_stats, class_colors=None, figsize=(10, 8)):
        """åˆ›å»ºé¢ç§¯é¥¼å›¾ - ä½¿ç”¨å½©è‰²"""
        if not area_stats:
            fig, ax = plt.subplots(figsize=figsize)
            ax.text(0.5, 0.5, 'æ— é¢ç§¯ç»Ÿè®¡æ•°æ®', ha='center', va='center', transform=ax.transAxes)
            ax.set_title('åœŸåœ°åˆ©ç”¨ç±»å‹é¢ç§¯åˆ†å¸ƒ')
            return fig
                
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))
        
        labels = list(area_stats.keys())
        areas = [stats['area_ha'] for stats in area_stats.values()]
        percentages = [stats['percentage'] for stats in area_stats.values()]
        
        # ä½¿ç”¨ç±»åˆ«å¯¹åº”çš„é¢œè‰² - ä¼˜åŒ–é¢œè‰²é€‰æ‹©
        colors = []
        for label in labels:
            # å°è¯•ä»class_colorsä¸­è·å–é¢œè‰²
            if class_colors:
                # æŸ¥æ‰¾å¯¹åº”çš„class_id
                for class_name, stats in area_stats.items():
                    if class_name == label:
                        class_id = stats['class_id']
                        color = class_colors.get(class_id, 'gray')
                        colors.append(color)
                        break
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é¢„å®šä¹‰é¢œè‰²
                    main_type = label.split('_')[0] if '_' in label else label
                    color = self.LANDUSE_COLORS.get(main_type, 'gray')
                    colors.append(color)
            else:
                # ä½¿ç”¨é¢„å®šä¹‰é¢œè‰²
                main_type = label.split('_')[0] if '_' in label else label
                color = self.LANDUSE_COLORS.get(main_type, 'gray')
                colors.append(color)
        
        # é¥¼å›¾
        wedges, texts, autotexts = ax1.pie(areas, labels=labels, autopct='%1.1f%%',
                                        colors=colors, startangle=90)
        
        # ç¾åŒ–é¥¼å›¾æ–‡æœ¬
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')
        
        ax1.set_title('åœŸåœ°åˆ©ç”¨ç±»å‹é¢ç§¯åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        # é¢ç§¯ç»Ÿè®¡è¡¨æ ¼
        ax2.axis('off')
        table_data = []
        for label, stats in area_stats.items():
            table_data.append([
                label, 
                f"{stats['pixel_count']:,}", 
                f"{stats['area_ha']:.2f}", 
                f"{stats['percentage']:.1f}%"
            ])
        
        # åˆ›å»ºè¡¨æ ¼ - ä¼˜åŒ–æ ·å¼
        table = ax2.table(
            cellText=table_data,
            colLabels=['ç±»åˆ«', 'åƒç´ æ•°é‡', 'é¢ç§¯(å…¬é¡·)', 'ç™¾åˆ†æ¯”'],
            loc='center',
            cellLoc='center',
            bbox=[0.1, 0.1, 0.8, 0.8]
        )
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 1.8)
        
        # è®¾ç½®è¡¨å¤´æ ·å¼
        for i in range(len(table_data[0])):
            table[(0, i)].set_facecolor('#4B8BBE')
            table[(0, i)].set_text_props(color='white', weight='bold')
        
        # è®¾ç½®è¡Œäº¤æ›¿é¢œè‰²
        for i in range(1, len(table_data) + 1):
            color = '#F0F0F0' if i % 2 == 0 else 'white'
            for j in range(len(table_data[0])):
                table[(i, j)].set_facecolor(color)
        
        plt.tight_layout()
        return fig

# ==================== è¾…åŠ©å‡½æ•° ====================
def extract_zip_file(zip_file, extract_dir):
    """è§£å‹ZIPæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•"""
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    
    # æŸ¥æ‰¾.shpæ–‡ä»¶
    shp_files = list(Path(extract_dir).glob("*.shp"))
    if not shp_files:
        raise ValueError("ZIPæ–‡ä»¶ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶")
    
    return str(shp_files[0])

def save_uploaded_file(uploaded_file, temp_dir, filename):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    file_path = os.path.join(temp_dir, filename)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path

def safe_delete_temp_dir(temp_dir):
    """å®‰å…¨åˆ é™¤ä¸´æ—¶ç›®å½•ï¼Œå¤„ç†æ–‡ä»¶å ç”¨é—®é¢˜"""
    if not temp_dir or not os.path.exists(temp_dir):
        return
    
    max_retries = 3
    for i in range(max_retries):
        try:
            # å…ˆå°è¯•æ­£å¸¸åˆ é™¤
            shutil.rmtree(temp_dir)
            break
        except PermissionError:
            if i < max_retries - 1:
                # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                time.sleep(1)
                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()
            else:
                # æœ€åä¸€æ¬¡å°è¯•ï¼Œå¿½ç•¥é”™è¯¯
                try:
                    shutil.rmtree(temp_dir, ignore_errors=True)
                except:
                    pass

def add_log(message):
    """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
    if 'log_messages' not in st.session_state:
        st.session_state.log_messages = []
    st.session_state.log_messages.append(message)
    # ä¿æŒæ—¥å¿—é•¿åº¦åˆç†
    if len(st.session_state.log_messages) > 100:
        st.session_state.log_messages = st.session_state.log_messages[-50:]

def get_file_download_link(file_path, file_label):
    """ç”Ÿæˆæ–‡ä»¶ä¸‹è½½é“¾æ¥"""
    with open(file_path, "rb") as f:
        data = f.read()
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:application/octet-stream;base64,{b64}" download="{os.path.basename(file_path)}">{file_label}</a>'
    return href

# ==================== Streamlitåº”ç”¨ ====================
def main():
    st.set_page_config(
        page_title="é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.4 - Webç‰ˆ",
        page_icon="ğŸ›°ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # åˆå§‹åŒ–session state
    if 'backend' not in st.session_state:
        st.session_state.backend = ClassificationBackend()
    
    if 'is_running' not in st.session_state:
        st.session_state.is_running = False
    
    if 'comparison_results' not in st.session_state:
        st.session_state.comparison_results = []
    
    if 'comparison_df' not in st.session_state:
        st.session_state.comparison_df = None
    
    if 'log_messages' not in st.session_state:
        st.session_state.log_messages = []
    
    if 'progress' not in st.session_state:
        st.session_state.progress = 0
    
    # æ–°å¢ï¼šåˆ†ç±»å™¨æ‰§è¡ŒçŠ¶æ€
    if 'current_classifier_index' not in st.session_state:
        st.session_state.current_classifier_index = 0
    
    if 'selected_classifiers_list' not in st.session_state:
        st.session_state.selected_classifiers_list = []
    
    if 'classification_params' not in st.session_state:
        st.session_state.classification_params = {}
    
    # æ–°å¢ï¼šé¢ç§¯ç»Ÿè®¡ç»“æœ
    if 'area_statistics' not in st.session_state:
        st.session_state.area_statistics = {}
    
    # æ–°å¢ï¼šåƒå…ƒä¿¡æ¯
    if 'pixel_info' not in st.session_state:
        st.session_state.pixel_info = None
    
    # æ ‡é¢˜å’Œä»‹ç»
    st.title("ğŸ›°ï¸ é¥æ„Ÿå½±åƒç›‘ç£åˆ†ç±»ç³»ç»Ÿ v4.4 - Webç‰ˆ")
    st.markdown("""
    ### ä¸“ä¸šçº§é¥æ„Ÿå½±åƒåˆ†ç±»å·¥å…·
    
    åŸºäºæœºå™¨å­¦ä¹ çš„å¤šç®—æ³•å¯¹æ¯”åˆ†ç±»ç³»ç»Ÿï¼Œæ”¯æŒ15+ç§åˆ†ç±»å™¨ï¼Œæä¾›å®Œæ•´çš„ç²¾åº¦è¯„ä¼°å’Œå¯è§†åŒ–åˆ†æã€‚
    
    **æ–°å¢åŠŸèƒ½**:
    - âœ… è‡ªåŠ¨ä»å½±åƒè·å–åƒå…ƒå¤§å°
    - âœ… è‡ªåŠ¨è®¡ç®—åƒå…ƒé¢ç§¯
    - âœ… åˆ†ç±»ç»“æœå›¾åƒé¢„è§ˆå’Œä¸‹è½½
    - âœ… è¯¦ç»†ç²¾åº¦ç»Ÿè®¡æŠ¥å‘Š
    - âœ… å„ç±»åˆ«é¢ç§¯è®¡ç®—å’Œé¥¼å›¾æ˜¾ç¤º
    - âœ… å¤šåˆ†ç±»å™¨ç»“æœå¯¹æ¯”
    
    **æ³¨æ„**: 
    - Shapefileè¯·æ‰“åŒ…ä¸ºZIPæ ¼å¼ä¸Šä¼ ï¼ŒåŒ…å«.shp, .shx, .dbf, .prjç­‰æ‰€æœ‰å¿…éœ€æ–‡ä»¶
    - ç¡®ä¿è®­ç»ƒæ ·æœ¬ä¸å½±åƒæ–‡ä»¶åœ¨ç›¸åŒçš„åœ°ç†åæ ‡ç³»ä¸‹
    - å¦‚æœé‡åˆ°æ ·æœ¬æå–é—®é¢˜ï¼Œè¯·æ£€æŸ¥èƒŒæ™¯å€¼è®¾ç½®æ˜¯å¦æ­£ç¡®
    """)
    
    # ä¾§è¾¹æ  - å‚æ•°è®¾ç½®
    st.sidebar.header("ğŸ“‹ å‚æ•°è®¾ç½®")
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.sidebar.subheader("ğŸ“ æ•°æ®æ–‡ä»¶")
    image_file = st.sidebar.file_uploader("é¥æ„Ÿå½±åƒæ–‡ä»¶", type=['tif', 'tiff'], key="image")
    train_zip_file = st.sidebar.file_uploader("è®­ç»ƒæ ·æœ¬ZIPæ–‡ä»¶", type=['zip'], key="train_zip",
                                             help="è¯·ä¸Šä¼ åŒ…å«.shp, .shx, .dbf, .prjç­‰æ–‡ä»¶çš„ZIPå‹ç¼©åŒ…")
    
    val_zip_file = st.sidebar.file_uploader("éªŒè¯æ ·æœ¬ZIPæ–‡ä»¶ (å¯é€‰)", type=['zip'], key="val_zip",
                                           help="è¯·ä¸Šä¼ åŒ…å«.shp, .shx, .dbf, .prjç­‰æ–‡ä»¶çš„ZIPå‹ç¼©åŒ…")
    
    # æ˜¾ç¤ºåƒå…ƒä¿¡æ¯ï¼ˆå¦‚æœå·²åŠ è½½å½±åƒï¼‰
    if image_file and st.session_state.pixel_info:
        st.sidebar.subheader("ğŸ“ åƒå…ƒä¿¡æ¯")
        pixel_info = st.session_state.pixel_info
        
        st.sidebar.write(f"**åƒå…ƒå®½åº¦**: {pixel_info['pixel_width']:.2f} ç±³")
        st.sidebar.write(f"**åƒå…ƒé«˜åº¦**: {pixel_info['pixel_height']:.2f} ç±³")
        st.sidebar.write(f"**åƒå…ƒé¢ç§¯**: {pixel_info['pixel_area_m2']:.2f} å¹³æ–¹ç±³")
        st.sidebar.write(f"**åƒå…ƒé¢ç§¯**: {pixel_info['pixel_area_ha']:.6f} å…¬é¡·")
        
        if pixel_info['is_geographic']:
            st.sidebar.warning("âš ï¸ å½±åƒä½¿ç”¨åœ°ç†åæ ‡ç³»ï¼Œé¢ç§¯è®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
        else:
            st.sidebar.success("âœ… å½±åƒä½¿ç”¨æŠ•å½±åæ ‡ç³»ï¼Œé¢ç§¯è®¡ç®—å‡†ç¡®")
    
    # å­—æ®µé…ç½®
    st.sidebar.subheader("ğŸ·ï¸ å­—æ®µé…ç½®")
    
    # å¦‚æœä¸Šä¼ äº†è®­ç»ƒæ ·æœ¬ZIPæ–‡ä»¶ï¼Œå¤„ç†å¹¶è·å–å­—æ®µ
    if train_zip_file and 'train_shp_path' not in st.session_state:
        with st.spinner("æ­£åœ¨è§£å‹è®­ç»ƒæ ·æœ¬æ–‡ä»¶..."):
            try:
                # åˆ›å»ºä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                train_zip_path = save_uploaded_file(train_zip_file, temp_dir, "train_samples.zip")
                
                # è§£å‹ZIPæ–‡ä»¶
                extract_dir = os.path.join(temp_dir, "train_extracted")
                os.makedirs(extract_dir, exist_ok=True)
                
                train_shp_path = extract_zip_file(train_zip_path, extract_dir)
                st.session_state.train_shp_path = train_shp_path
                st.session_state.train_temp_dir = temp_dir
                
                st.sidebar.success("è®­ç»ƒæ ·æœ¬è§£å‹æˆåŠŸ!")
                
            except Exception as e:
                st.sidebar.error(f"è§£å‹è®­ç»ƒæ ·æœ¬å¤±è´¥: {str(e)}")
    
    # å¦‚æœä¸Šä¼ äº†éªŒè¯æ ·æœ¬ZIPæ–‡ä»¶ï¼Œå¤„ç†å¹¶è·å–å­—æ®µ
    if val_zip_file and 'val_shp_path' not in st.session_state:
        with st.spinner("æ­£åœ¨è§£å‹éªŒè¯æ ·æœ¬æ–‡ä»¶..."):
            try:
                # åˆ›å»ºä¸´æ—¶ç›®å½•
                temp_dir = tempfile.mkdtemp()
                val_zip_path = save_uploaded_file(val_zip_file, temp_dir, "val_samples.zip")
                
                # è§£å‹ZIPæ–‡ä»¶
                extract_dir = os.path.join(temp_dir, "val_extracted")
                os.makedirs(extract_dir, exist_ok=True)
                
                val_shp_path = extract_zip_file(val_zip_path, extract_dir)
                st.session_state.val_shp_path = val_shp_path
                st.session_state.val_temp_dir = temp_dir
                
                st.sidebar.success("éªŒè¯æ ·æœ¬è§£å‹æˆåŠŸ!")
                
            except Exception as e:
                st.sidebar.error(f"è§£å‹éªŒè¯æ ·æœ¬å¤±è´¥: {str(e)}")
    
    # è·å–å­—æ®µåˆ—è¡¨
    if 'train_shp_path' in st.session_state:
        fields = st.session_state.backend.get_shapefile_fields(st.session_state.train_shp_path)
        if fields:
            fields = [f for f in fields if f.lower() != 'geometry']
            
            class_attr = st.sidebar.selectbox("ç±»åˆ«ç¼–å·å­—æ®µ", fields, key="class_attr")
            name_attr = st.sidebar.selectbox("ç±»åˆ«åç§°å­—æ®µ", fields, key="name_attr")
        else:
            st.sidebar.error("æ— æ³•è¯»å–shapefileå­—æ®µ")
            class_attr = st.sidebar.text_input("ç±»åˆ«ç¼–å·å­—æ®µ", key="class_attr")
            name_attr = st.sidebar.text_input("ç±»åˆ«åç§°å­—æ®µ", key="name_attr")
    else:
        class_attr = st.sidebar.text_input("ç±»åˆ«ç¼–å·å­—æ®µ", key="class_attr")
        name_attr = st.sidebar.text_input("ç±»åˆ«åç§°å­—æ®µ", key="name_attr")
    
    # èƒŒæ™¯å€¼è®¾ç½®
    st.sidebar.subheader("ğŸ¨ èƒŒæ™¯å€¼è®¾ç½®")
    ignore_background = st.sidebar.checkbox("å¿½ç•¥èƒŒæ™¯å€¼", value=True, key="ignore_bg")
    background_value = st.sidebar.number_input("èƒŒæ™¯å€¼", value=0, key="bg_value")
    
    # åˆ†ç±»å‚æ•°
    st.sidebar.subheader("âš™ï¸ åˆ†ç±»å‚æ•°")
    n_estimators = st.sidebar.slider("æ ‘æ¨¡å‹æ•°é‡", 10, 500, 100, key="n_estimators")
    block_size = st.sidebar.selectbox("åˆ†å—å¤§å°", [256, 512, 1024, 2048], index=1, key="block_size")
    
    # æ‰‹åŠ¨åƒå…ƒé¢ç§¯è®¾ç½®ï¼ˆå¯é€‰ï¼‰
    st.sidebar.subheader("ğŸ“ æ‰‹åŠ¨åƒå…ƒè®¾ç½® (å¯é€‰)")
    use_custom_pixel_area = st.sidebar.checkbox("ä½¿ç”¨è‡ªå®šä¹‰åƒå…ƒé¢ç§¯", value=False, key="use_custom_pixel")
    custom_pixel_area_ha = st.sidebar.number_input("è‡ªå®šä¹‰åƒå…ƒé¢ç§¯ (å…¬é¡·)", value=0.0009, key="custom_pixel_area_ha",
                                                 help="ä»…åœ¨éœ€è¦è¦†ç›–è‡ªåŠ¨è®¡ç®—çš„åƒå…ƒé¢ç§¯æ—¶ä½¿ç”¨")
    
    # æ€§èƒ½ä¼˜åŒ–
    st.sidebar.subheader("âš¡ æ€§èƒ½ä¼˜åŒ–")
    enable_sampling = st.sidebar.checkbox("å¯ç”¨é‡‡æ ·", value=True, key="enable_sampling")
    max_samples = st.sidebar.slider("æœ€å¤§æ ·æœ¬æ•°", 10000, 200000, 50000, step=10000, key="max_samples")
    fast_mode = st.sidebar.checkbox("å¿«é€Ÿæ¨¡å¼", value=False, key="fast_mode")
    
    # åˆ†ç±»å™¨é€‰æ‹©
    st.sidebar.subheader("ğŸ¤– åˆ†ç±»å™¨é€‰æ‹©")
    all_classifiers = st.session_state.backend.get_all_classifiers()

    # åˆå§‹åŒ–checkboxåˆ·æ–°è®¡æ•°å™¨
    if 'checkbox_refresh_counter' not in st.session_state:
        st.session_state.checkbox_refresh_counter = 0

    # å¿«æ·é€‰æ‹©æŒ‰é’® - ä½¿ç”¨å”¯ä¸€çš„key
    st.sidebar.markdown("**å¿«æ·é€‰æ‹©:**")
    col1, col2, col3, col4 = st.sidebar.columns(4)

    with col1:
        if st.button("å…¨é€‰", key=f"btn_select_all_{st.session_state.checkbox_refresh_counter}", use_container_width=True):
            for code in all_classifiers.keys():
                st.session_state[f"selected_{code}"] = True
            st.session_state.checkbox_refresh_counter += 1
            st.rerun()

    with col2:
        if st.button("æ¨è", key=f"btn_select_recommended_{st.session_state.checkbox_refresh_counter}", use_container_width=True):
            recommended = ["rf", "xgb", "et", "lgb", "linear_svc", "nystroem_svm"]
            for code in all_classifiers.keys():
                st.session_state[f"selected_{code}"] = (code in recommended)
            st.session_state.checkbox_refresh_counter += 1
            st.rerun()

    with col3:
        if st.button("å¿«é€Ÿ", key=f"btn_select_fast_{st.session_state.checkbox_refresh_counter}", use_container_width=True):
            fast = ["rf", "et", "dt", "xgb", "lgb", "nb", "lr", "sgd_svm", "linear_svc"]
            for code in all_classifiers.keys():
                st.session_state[f"selected_{code}"] = (code in fast)
            st.session_state.checkbox_refresh_counter += 1
            st.rerun()

    with col4:
        if st.button("æ¸…ç©º", key=f"btn_clear_all_{st.session_state.checkbox_refresh_counter}", use_container_width=True):
            for code in all_classifiers.keys():
                st.session_state[f"selected_{code}"] = False
            st.session_state.checkbox_refresh_counter += 1
            st.rerun()

    # åˆ†ç±»å™¨åˆ†ç»„
    svm_codes = ["svm_linear", "linear_svc", "sgd_svm", "nystroem_svm", "rbf_sampler_svm", "svm_rbf"]
    tree_codes = ["rf", "et", "dt", "xgb", "lgb", "gb", "ada"]
    other_codes = ["knn", "nb", "lr", "mlp"]

    selected_classifiers = []

    # SVMåˆ†ç±»å™¨
    st.sidebar.markdown("**SVMåˆ†ç±»å™¨:**")
    for code in svm_codes:
        if code in all_classifiers:
            _, name, _, _, _, _ = all_classifiers[code]
            checkbox_key = f"clf_{code}_{st.session_state.checkbox_refresh_counter}"
            default_value = st.session_state.get(f"selected_{code}", False)
            if st.sidebar.checkbox(name, key=checkbox_key, value=default_value):
                selected_classifiers.append(code)
                st.session_state[f"selected_{code}"] = True
            else:
                st.session_state[f"selected_{code}"] = False

    # æ ‘æ¨¡å‹åˆ†ç±»å™¨
    st.sidebar.markdown("**æ ‘æ¨¡å‹åˆ†ç±»å™¨:**")
    for code in tree_codes:
        if code in all_classifiers:
            _, name, _, _, _, _ = all_classifiers[code]
            checkbox_key = f"clf_{code}_{st.session_state.checkbox_refresh_counter}"
            default_value = st.session_state.get(f"selected_{code}", False)
            if st.sidebar.checkbox(name, key=checkbox_key, value=default_value):
                selected_classifiers.append(code)
                st.session_state[f"selected_{code}"] = True
            else:
                st.session_state[f"selected_{code}"] = False

    # å…¶ä»–åˆ†ç±»å™¨
    st.sidebar.markdown("**å…¶ä»–åˆ†ç±»å™¨:**")
    for code in other_codes:
        if code in all_classifiers:
            _, name, _, _, _, _ = all_classifiers[code]
            checkbox_key = f"clf_{code}_{st.session_state.checkbox_refresh_counter}"
            default_value = st.session_state.get(f"selected_{code}", False)
            if st.sidebar.checkbox(name, key=checkbox_key, value=default_value):
                selected_classifiers.append(code)
                st.session_state[f"selected_{code}"] = True
            else:
                st.session_state[f"selected_{code}"] = False


        
    # ä¸»å†…å®¹åŒºåŸŸ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ è¿è¡Œæ§åˆ¶", "ğŸ“Š ç²¾åº¦å¯¹æ¯”", "ğŸ”¥ æ··æ·†çŸ©é˜µ", "â±ï¸ æ—¶é—´å¯¹æ¯”", "ğŸ—ºï¸ ç»“æœé¢„è§ˆ"])
    
    with tab1:
        st.header("è¿è¡Œæ§åˆ¶")
        
        # è¿è¡ŒæŒ‰é’®
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            if st.button("â–¶ å¼€å§‹åˆ†ç±»", type="primary", disabled=st.session_state.is_running):
                if not image_file:
                    st.error("è¯·é€‰æ‹©å½±åƒæ–‡ä»¶ï¼")
                elif 'train_shp_path' not in st.session_state:
                    st.error("è¯·ä¸Šä¼ è®­ç»ƒæ ·æœ¬ZIPæ–‡ä»¶ï¼")
                elif not class_attr:
                    st.error("è¯·é€‰æ‹©ç±»åˆ«ç¼–å·å­—æ®µï¼")
                elif not selected_classifiers:
                    st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»å™¨ï¼")
                else:
                    # ä¿å­˜åˆ†ç±»å‚æ•°
                    st.session_state.classification_params = {
                        'image_file': image_file,
                        'class_attr': class_attr,
                        'name_attr': name_attr,
                        'ignore_background': ignore_background,
                        'background_value': background_value,
                        'n_estimators': n_estimators,
                        'block_size': block_size,
                        'enable_sampling': enable_sampling,
                        'max_samples': max_samples,
                        'fast_mode': fast_mode,
                        'selected_classifiers': selected_classifiers,
                        'use_custom_pixel_area': use_custom_pixel_area,
                        'custom_pixel_area_ha': custom_pixel_area_ha
                    }
                    
                    st.session_state.is_running = True
                    st.session_state.log_messages = []
                    st.session_state.comparison_results = []
                    st.session_state.comparison_df = None
                    st.session_state.current_classifier_index = 0
                    st.session_state.selected_classifiers_list = selected_classifiers.copy()
                    st.session_state.area_statistics = {}
                    
                    add_log("ğŸš€ å¼€å§‹åˆ†ç±»ä»»åŠ¡...")
                    add_log(f"ğŸ“‹ é€‰æ‹©çš„åˆ†ç±»å™¨: {', '.join([all_classifiers[code][1] for code in selected_classifiers])}")
        
        with col2:
            if st.button("â¸ åœæ­¢", disabled=not st.session_state.is_running):
                st.session_state.is_running = False
                add_log("â¹ï¸ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢åˆ†ç±»ä»»åŠ¡")
        
        with col3:
            if st.session_state.comparison_df is not None and not st.session_state.comparison_df.empty:
                if st.button("ğŸ“¥ ä¸‹è½½ç»“æœ"):
                    download_results()
                if st.button("ğŸ“¦ ä¸‹è½½å®Œæ•´åŒ…"):
                    download_all_results()
        
        # è¿›åº¦æ˜¾ç¤º
        if st.session_state.progress > 0:
            st.progress(st.session_state.progress)
            if (st.session_state.current_classifier_index > 0 and 
                st.session_state.selected_classifiers_list):
                total_classifiers = len(st.session_state.selected_classifiers_list)
                current_index = st.session_state.current_classifier_index
                current_classifier = st.session_state.selected_classifiers_list[current_index - 1]
                all_classifiers = st.session_state.backend.get_all_classifiers()
                classifier_name = all_classifiers[current_classifier][1] if current_classifier in all_classifiers else current_classifier
                st.write(f"æ­£åœ¨å¤„ç†: {classifier_name} ({current_index}/{total_classifiers})")
        
        # æ—¥å¿—æ˜¾ç¤º
        st.subheader("è¿è¡Œæ—¥å¿—")
        log_container = st.container()
        with log_container:
            for message in st.session_state.log_messages:
                st.text(message)
        
        # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œæ‰§è¡Œåˆ†ç±»ä»»åŠ¡
        if st.session_state.is_running and st.session_state.selected_classifiers_list:
            if st.session_state.current_classifier_index < len(st.session_state.selected_classifiers_list):
                # æ‰§è¡Œä¸‹ä¸€ä¸ªåˆ†ç±»å™¨
                run_classification_step()
            else:
                # æ‰€æœ‰åˆ†ç±»å™¨å®Œæˆ
                st.session_state.is_running = False
                add_log("âœ… æ‰€æœ‰åˆ†ç±»å™¨å¤„ç†å®Œæˆ!")
                st.success("æ‰€æœ‰åˆ†ç±»å™¨å¤„ç†å®Œæˆ!")
    
    with tab2:
        st.header("ç²¾åº¦å¯¹æ¯”")
        if st.session_state.comparison_df is not None and not st.session_state.comparison_df.empty:
            display_accuracy_comparison()
        else:
            st.info("æš‚æ— åˆ†ç±»ç»“æœï¼Œè¯·å…ˆè¿è¡Œåˆ†ç±»")
    
    with tab3:
        st.header("æ··æ·†çŸ©é˜µ")
        if (st.session_state.comparison_df is not None and not st.session_state.comparison_df.empty and 
            'best_confusion_matrix' in st.session_state and st.session_state.best_confusion_matrix is not None):
            display_confusion_matrix()
        else:
            st.info("æš‚æ— æ··æ·†çŸ©é˜µæ•°æ®")
    
    with tab4:
        st.header("æ—¶é—´å¯¹æ¯”")
        if st.session_state.comparison_df is not None and not st.session_state.comparison_df.empty:
            display_time_comparison()
        else:
            st.info("æš‚æ— æ—¶é—´å¯¹æ¯”æ•°æ®")
    
    with tab5:
        st.header("åˆ†ç±»ç»“æœé¢„è§ˆ")
        if (st.session_state.comparison_df is not None and not st.session_state.comparison_df.empty and 
            'best_result_path' in st.session_state and st.session_state.best_result_path is not None):
            display_result_preview()
        else:
            st.info("æš‚æ— åˆ†ç±»ç»“æœé¢„è§ˆ")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if st.sidebar.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶"):
        if 'train_temp_dir' in st.session_state:
            safe_delete_temp_dir(st.session_state.train_temp_dir)
            st.session_state.train_temp_dir = None
            st.session_state.train_shp_path = None
        
        if 'val_temp_dir' in st.session_state:
            safe_delete_temp_dir(st.session_state.val_temp_dir)
            st.session_state.val_temp_dir = None
            st.session_state.val_shp_path = None
        
        st.sidebar.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†!")

def run_classification_step():
    """æ‰§è¡Œå•ä¸ªåˆ†ç±»å™¨çš„åˆ†ç±»ä»»åŠ¡"""
    
    backend = st.session_state.backend
    params = st.session_state.classification_params
    selected_classifiers = st.session_state.selected_classifiers_list
    current_index = st.session_state.current_classifier_index
    
    if current_index >= len(selected_classifiers):
        return
    
    clf_code = selected_classifiers[current_index]
    all_classifiers = backend.get_all_classifiers()
    
    if clf_code not in all_classifiers:
        add_log(f"âŒ æœªçŸ¥çš„åˆ†ç±»å™¨ä»£ç : {clf_code}")
        st.session_state.current_classifier_index += 1
        st.rerun()
        return
    
    clf, clf_name, clf_desc, needs_encoding, needs_scaling, speed_tag = all_classifiers[clf_code]
    
    add_log(f"\n{'='*80}")
    add_log(f"[{current_index+1}/{len(selected_classifiers)}] {clf_name}")
    add_log(f"{'='*80}")
    
    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œåˆå§‹åŒ–ä¸´æ—¶ç›®å½•å’Œæ•°æ®
    if current_index == 0:
        # åˆ›å»ºä¸»ä¸´æ—¶ç›®å½•
        main_temp_dir = tempfile.mkdtemp()
        st.session_state.main_temp_dir = main_temp_dir
        
        try:
            temp_path = Path(main_temp_dir)
            
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            image_path = temp_path / "image.tif"
            with open(image_path, 'wb') as f:
                f.write(params['image_file'].getvalue())
            
            # ä½¿ç”¨session stateä¸­ä¿å­˜çš„shapefileè·¯å¾„
            train_shp_path = st.session_state.train_shp_path
            val_shp_path = st.session_state.val_shp_path if 'val_shp_path' in st.session_state else None
            
            # è¯»å–å½±åƒ
            add_log("ğŸ“ è¯»å–å½±åƒ...")
            try:
                # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
                with rxr.open_rasterio(image_path, masked=True) as img:
                    # å°†æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­
                    img_data = img.load()
                    n_pixels = img_data.shape[1] * img_data.shape[2]
                    add_log(f"   å°ºå¯¸: {img_data.shape[1]}Ã—{img_data.shape[2]} = {n_pixels:,} åƒå…ƒ")
                    add_log(f"   æ³¢æ®µæ•°: {img_data.shape[0]}")
                    add_log(f"   æ•°æ®ç±»å‹: {img_data.dtype}")
                    add_log(f"   åæ ‡ç³»ç»Ÿ: {img_data.rio.crs}")
                    
                    # è·å–åƒå…ƒä¿¡æ¯
                    add_log("ğŸ“ è·å–åƒå…ƒä¿¡æ¯...")
                    pixel_info = backend.get_pixel_info_from_image(img_data)
                    st.session_state.pixel_info = pixel_info
                    
                    add_log(f"   åƒå…ƒå®½åº¦: {pixel_info['pixel_width']:.2f} ç±³")
                    add_log(f"   åƒå…ƒé«˜åº¦: {pixel_info['pixel_height']:.2f} ç±³")
                    add_log(f"   åƒå…ƒé¢ç§¯: {pixel_info['pixel_area_m2']:.2f} å¹³æ–¹ç±³")
                    add_log(f"   åƒå…ƒé¢ç§¯: {pixel_info['pixel_area_ha']:.6f} å…¬é¡·")
                    
                    if pixel_info['is_geographic']:
                        add_log("   âš ï¸ è­¦å‘Š: å½±åƒä½¿ç”¨åœ°ç†åæ ‡ç³»ï¼Œé¢ç§¯è®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
                    
                    # ç¡®å®šä½¿ç”¨çš„åƒå…ƒé¢ç§¯
                    if params['use_custom_pixel_area']:
                        pixel_area_ha = params['custom_pixel_area_ha']
                        add_log(f"   ä½¿ç”¨è‡ªå®šä¹‰åƒå…ƒé¢ç§¯: {pixel_area_ha:.6f} å…¬é¡·")
                    else:
                        pixel_area_ha = pixel_info['pixel_area_ha']
                        add_log(f"   ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„åƒå…ƒé¢ç§¯: {pixel_area_ha:.6f} å…¬é¡·")
                    
                    # è¯»å–ç±»åˆ«ä¿¡æ¯
                    add_log("ğŸ“Š è¯»å–ç±»åˆ«ä¿¡æ¯...")
                    class_names, class_colors, _ = backend.get_class_info_from_shp(
                        train_shp_path, params['class_attr'], params['name_attr']
                    )
                    st.session_state.class_names = class_names
                    st.session_state.class_colors = class_colors
                    add_log(f"   ç±»åˆ«: {list(class_names.values())}")
                    
                    # æå–è®­ç»ƒæ ·æœ¬
                    add_log("ğŸ¯ å¤„ç†è®­ç»ƒæ ·æœ¬...")
                    train_mask = backend.rasterize_samples(train_shp_path, img_data, params['class_attr'])
                    
                    max_samples_val = params['max_samples'] if params['enable_sampling'] else None
                    
                    X_train, y_train, n_nan, n_inf, n_sampled = backend.extract_samples(
                        img_data, train_mask, 
                        ignore_background=params['ignore_background'],
                        background_value=params['background_value'],
                        max_samples=max_samples_val
                    )
                    
                    add_log(f"   è®­ç»ƒæ ·æœ¬æ•°: {len(y_train):,}")
                    if n_nan > 0:
                        add_log(f"   â””â”€ ç§»é™¤NaN: {n_nan:,}")
                    if n_inf > 0:
                        add_log(f"   â””â”€ ç§»é™¤Inf: {n_inf:,}")
                    if n_sampled > 0:
                        add_log(f"   â””â”€ é‡‡æ ·å‡å°‘: {n_sampled:,}")
                    
                    # æ£€æŸ¥æ ·æœ¬æ•°é‡
                    if len(y_train) == 0:
                        add_log("âŒ é”™è¯¯: æ²¡æœ‰æå–åˆ°è®­ç»ƒæ ·æœ¬!")
                        st.session_state.is_running = False
                        return
                    
                    # æå–éªŒè¯æ ·æœ¬
                    val_exists = val_shp_path and os.path.exists(val_shp_path)
                    yv_true = None
                    valid_val = None
                    if val_exists:
                        add_log("âœ… å¤„ç†éªŒè¯æ ·æœ¬...")
                        val_mask = backend.rasterize_samples(val_shp_path, img_data, params['class_attr'])
                        
                        if params['ignore_background']:
                            background_mask = backend.get_background_mask(img_data, params['background_value'])
                            valid_val = (val_mask > 0) & (~background_mask)
                        else:
                            valid_val = val_mask > 0
                        
                        yv_true = val_mask[valid_val]
                        add_log(f"   éªŒè¯æ ·æœ¬æ•°: {len(yv_true):,}")
                    
                    # ä¿å­˜æ•°æ®åˆ°session state
                    st.session_state.temp_path = temp_path
                    st.session_state.image_path = image_path
                    st.session_state.img_data = img_data
                    st.session_state.X_train = X_train
                    st.session_state.y_train = y_train
                    st.session_state.val_exists = val_exists
                    st.session_state.yv_true = yv_true
                    st.session_state.valid_val = valid_val
                    st.session_state.pixel_area_ha = pixel_area_ha
                    
            except Exception as e:
                add_log(f"âŒ å½±åƒè¯»å–é”™è¯¯: {str(e)}")
                st.session_state.is_running = False
                return
            
        except Exception as e:
            add_log(f"\nâŒ é”™è¯¯: {str(e)}")
            st.session_state.is_running = False
            return
    
    # å¤„ç†å½“å‰åˆ†ç±»å™¨
    try:
        temp_path = st.session_state.temp_path
        img_data = st.session_state.img_data
        X_train = st.session_state.X_train
        y_train = st.session_state.y_train
        val_exists = st.session_state.val_exists
        yv_true = st.session_state.yv_true
        valid_val = st.session_state.valid_val
        pixel_area_ha = st.session_state.pixel_area_ha
        
        clf_dir = temp_path / clf_code
        clf_dir.mkdir(exist_ok=True)
        
        # æ•°æ®é¢„å¤„ç†
        label_encoder = None
        scaler = None
        X_train_use = X_train.copy()
        y_train_use = y_train.copy()
        
        if needs_encoding:
            add_log("   ğŸ”„ æ ‡ç­¾ç¼–ç ...")
            label_encoder = LabelEncoder()
            y_train_use = label_encoder.fit_transform(y_train)
        
        if needs_scaling:
            add_log("   ğŸ“ ç‰¹å¾ç¼©æ”¾...")
            scaler = StandardScaler()
            X_train_use = scaler.fit_transform(X_train_use)
        
        # è®­ç»ƒ
        add_log("   ğŸ”¨ è®­ç»ƒä¸­...")
        train_start = time.time()
        clf.fit(X_train_use, y_train_use)
        train_time = time.time() - train_start
        add_log(f"   âœ“ è®­ç»ƒå®Œæˆ: {train_time:.2f}ç§’")
        
        # è®­ç»ƒé›†ç²¾åº¦
        y_train_pred = clf.predict(X_train_use)
        
        if label_encoder is not None:
            y_train_pred = label_encoder.inverse_transform(y_train_pred)
        
        train_metrics = backend.calculate_metrics(y_train, y_train_pred)
        add_log(f"   ğŸ“ˆ è®­ç»ƒé›† - ç²¾åº¦: {train_metrics['overall_accuracy']:.4f}")
        
        if not st.session_state.is_running:
            return
        
        # é¢„æµ‹æ•´å¹…å½±åƒ
        add_log("   ğŸ—ºï¸  é¢„æµ‹å½±åƒ...")
        
        def update_progress(progress):
            st.session_state.progress = progress
        
        pred_start = time.time()
        classified_path = clf_dir / f"classified_{clf_code}.tif"
        
        backend.predict_by_block(
            clf, img_data, classified_path, 
            block_size=params['block_size'],
            ignore_background=params['ignore_background'],
            background_value=params['background_value'],
            progress_callback=update_progress,
            label_encoder=label_encoder,
            scaler=scaler
        )
        
        pred_time = time.time() - pred_start
        add_log(f"   âœ“ é¢„æµ‹å®Œæˆ: {pred_time:.2f}ç§’")
        
        # éªŒè¯é›†ç²¾åº¦
        val_metrics = {'overall_accuracy': np.nan, 'kappa': np.nan}
        yv_pred = None
        
        if val_exists and yv_true is not None:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¯»å–é¢„æµ‹ç»“æœ
            with rxr.open_rasterio(classified_path) as pred_img:
                pred_arr = pred_img.values.squeeze()
            
            yv_pred = pred_arr[valid_val]
            val_metrics = backend.calculate_metrics(yv_true, yv_pred)
            add_log(f"   ğŸ“Š éªŒè¯é›† - ç²¾åº¦: {val_metrics['overall_accuracy']:.4f}")
            
            # è®°å½•æœ€ä½³åˆ†ç±»å™¨
            if ('best_accuracy' not in st.session_state or 
                val_metrics['overall_accuracy'] > st.session_state.best_accuracy):
                st.session_state.best_accuracy = val_metrics['overall_accuracy']
                st.session_state.best_result_path = classified_path
                st.session_state.best_clf_code = clf_code
                
                # ä¿å­˜æ··æ·†çŸ©é˜µæ•°æ®
                cm = confusion_matrix(yv_true, yv_pred)
                st.session_state.best_confusion_matrix = cm
                st.session_state.best_y_true = yv_true
                st.session_state.best_y_pred = yv_pred
        
        # è®¡ç®—é¢ç§¯ç»Ÿè®¡
        add_log("   ğŸ“ è®¡ç®—é¢ç§¯ç»Ÿè®¡...")
        with rxr.open_rasterio(classified_path) as pred_img:
            pred_arr = pred_img.values.squeeze()
        
        area_stats = backend.calculate_class_areas(
            pred_arr, 
            st.session_state.class_names,
            pixel_area_ha=pixel_area_ha
        )
        
        # ä¿å­˜é¢ç§¯ç»Ÿè®¡
        st.session_state.area_statistics[clf_code] = area_stats
        add_log(f"   âœ“ é¢ç§¯ç»Ÿè®¡å®Œæˆ")
        
        # è®°å½•ç»“æœ
        result = {
            'åˆ†ç±»å™¨ä»£ç ': clf_code,
            'åˆ†ç±»å™¨åç§°': clf_name,
            'è®­ç»ƒé›†ç²¾åº¦': train_metrics['overall_accuracy'],
            'è®­ç»ƒé›†Kappa': train_metrics['kappa'],
            'éªŒè¯é›†ç²¾åº¦': val_metrics['overall_accuracy'],
            'éªŒè¯é›†Kappa': val_metrics['kappa'],
            'è®­ç»ƒæ—¶é—´(ç§’)': train_time,
            'é¢„æµ‹æ—¶é—´(ç§’)': pred_time,
        }
        
        # æ›´æ–°æ¯”è¾ƒç»“æœ
        if st.session_state.comparison_results is None:
            st.session_state.comparison_results = []
        
        st.session_state.comparison_results.append(result)
        st.session_state.comparison_df = pd.DataFrame(st.session_state.comparison_results)
        
        add_log(f"   âœ… {clf_name} å®Œæˆ!")
        
    except Exception as e:
        add_log(f"   âŒ {clf_name} å¤±è´¥: {str(e)}")
        import traceback
        add_log(traceback.format_exc())
    
    # æ›´æ–°è¿›åº¦å¹¶ç»§ç»­ä¸‹ä¸€ä¸ªåˆ†ç±»å™¨
    st.session_state.current_classifier_index += 1
    st.session_state.progress = st.session_state.current_classifier_index / len(selected_classifiers)
    
    # è‡ªåŠ¨åˆ·æ–°ç•Œé¢
    st.rerun()

# å…¶ä»–æ˜¾ç¤ºå‡½æ•°ä¿æŒä¸å˜...
def display_accuracy_comparison():
    """æ˜¾ç¤ºç²¾åº¦å¯¹æ¯”"""
    if st.session_state.comparison_df is None or st.session_state.comparison_df.empty:
        st.info("æš‚æ— åˆ†ç±»ç»“æœï¼Œè¯·å…ˆè¿è¡Œåˆ†ç±»")
        return
    
    df = st.session_state.comparison_df
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # ç²¾åº¦å¯¹æ¯”
    x = np.arange(len(df))
    width = 0.35
    
    ax1.bar(x - width/2, df['è®­ç»ƒé›†ç²¾åº¦'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
    ax1.bar(x + width/2, df['éªŒè¯é›†ç²¾åº¦'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
    
    ax1.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
    ax1.set_ylabel('ç²¾åº¦', fontsize=11)
    ax1.set_title('æ€»ä½“ç²¾åº¦å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax1.set_xticks(x)
    ax1.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.set_ylim([0, 1.05])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (train_acc, val_acc) in enumerate(zip(df['è®­ç»ƒé›†ç²¾åº¦'], df['éªŒè¯é›†ç²¾åº¦'])):
        ax1.text(i - width/2, train_acc + 0.01, f'{train_acc:.3f}', 
                ha='center', va='bottom', fontsize=8)
        ax1.text(i + width/2, val_acc + 0.01, f'{val_acc:.3f}', 
                ha='center', va='bottom', fontsize=8)
    
    # Kappaå¯¹æ¯”
    ax2.bar(x - width/2, df['è®­ç»ƒé›†Kappa'], width, label='è®­ç»ƒé›†', alpha=0.8, color='steelblue')
    ax2.bar(x + width/2, df['éªŒè¯é›†Kappa'], width, label='éªŒè¯é›†', alpha=0.8, color='coral')
    
    ax2.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
    ax2.set_ylabel('Kappaç³»æ•°', fontsize=11)
    ax2.set_title('Kappaç³»æ•°å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='y')
    ax2.set_ylim([0, 1.05])
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # æ˜¾ç¤ºè¯¦ç»†æ•°æ®
    st.subheader("è¯¦ç»†ç»“æœ")
    st.dataframe(df)

def display_confusion_matrix():
    """æ˜¾ç¤ºæ··æ·†çŸ©é˜µ"""
    if (st.session_state.comparison_df is None or st.session_state.comparison_df.empty or 
        'best_confusion_matrix' not in st.session_state or st.session_state.best_confusion_matrix is None):
        st.info("æš‚æ— æ··æ·†çŸ©é˜µæ•°æ®")
        return
    
    cm = st.session_state.best_confusion_matrix
    class_names = list(st.session_state.class_names.values())
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # ç»˜åˆ¶çƒ­å›¾
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names,
                cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}, ax=ax)
    
    ax.set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
    ax.set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)
    ax.set_title('æœ€ä½³åˆ†ç±»å™¨æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
    
    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    plt.setp(ax.get_yticklabels(), rotation=0)
    
    plt.tight_layout()
    st.pyplot(fig)

def display_time_comparison():
    """æ˜¾ç¤ºæ—¶é—´å¯¹æ¯”"""
    if st.session_state.comparison_df is None or st.session_state.comparison_df.empty:
        st.info("æš‚æ— æ—¶é—´å¯¹æ¯”æ•°æ®")
        return
    
    df = st.session_state.comparison_df
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    x = np.arange(len(df))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, df['è®­ç»ƒæ—¶é—´(ç§’)'], width, label='è®­ç»ƒæ—¶é—´', 
                  alpha=0.8, color='lightgreen')
    bars2 = ax.bar(x + width/2, df['é¢„æµ‹æ—¶é—´(ç§’)'], width, label='é¢„æµ‹æ—¶é—´', 
                  alpha=0.8, color='lightcoral')
    
    ax.set_xlabel('åˆ†ç±»å™¨', fontsize=11)
    ax.set_ylabel('æ—¶é—´ (ç§’)', fontsize=11)
    ax.set_title('è®­ç»ƒå’Œé¢„æµ‹æ—¶é—´å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(df['åˆ†ç±»å™¨åç§°'], rotation=45, ha='right', fontsize=9)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1f}s', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    st.pyplot(fig)

def display_result_preview():
    """æ˜¾ç¤ºåˆ†ç±»ç»“æœé¢„è§ˆ"""
    if (st.session_state.comparison_df is None or st.session_state.comparison_df.empty):
        st.info("æš‚æ— åˆ†ç±»ç»“æœé¢„è§ˆ")
        return
    
    backend = st.session_state.backend
    class_names = st.session_state.class_names
    class_colors = st.session_state.class_colors
    pixel_info = st.session_state.pixel_info
    
    # é€‰æ‹©è¦é¢„è§ˆçš„åˆ†ç±»å™¨
    st.subheader("é€‰æ‹©åˆ†ç±»å™¨è¿›è¡Œé¢„è§ˆ")
    classifier_options = {row['åˆ†ç±»å™¨åç§°']: row['åˆ†ç±»å™¨ä»£ç '] 
                         for _, row in st.session_state.comparison_df.iterrows()}
    selected_classifier_name = st.selectbox("é€‰æ‹©åˆ†ç±»å™¨", list(classifier_options.keys()))
    selected_classifier_code = classifier_options[selected_classifier_name]
    
    # è·å–åˆ†ç±»ç»“æœè·¯å¾„
    result_path = None
    if selected_classifier_code == st.session_state.get('best_clf_code', ''):
        result_path = st.session_state.best_result_path
    else:
        # ä»ä¸´æ—¶ç›®å½•æŸ¥æ‰¾
        temp_path = st.session_state.temp_path
        result_path = temp_path / selected_classifier_code / f"classified_{selected_classifier_code}.tif"
    
    if result_path is None or not result_path.exists():
        st.error(f"æ‰¾ä¸åˆ°åˆ†ç±»å™¨ {selected_classifier_name} çš„ç»“æœæ–‡ä»¶")
        return
    
    try:
        # è¯»å–åˆ†ç±»ç»“æœ
        with rxr.open_rasterio(result_path) as pred_img:
            pred_arr = pred_img.values.squeeze()
        
        # æ˜¾ç¤ºåˆ†ç±»ç»“æœé¢„è§ˆå›¾
        st.subheader("åˆ†ç±»ç»“æœé¢„è§ˆ")
        preview_fig = backend.create_classification_preview(
            pred_arr, class_names, class_colors
        )
        st.pyplot(preview_fig)
        
        # æ˜¾ç¤ºåƒå…ƒä¿¡æ¯
        if pixel_info:
            st.subheader("åƒå…ƒä¿¡æ¯")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("åƒå…ƒå®½åº¦", f"{pixel_info['pixel_width']:.2f} ç±³")
            with col2:
                st.metric("åƒå…ƒé«˜åº¦", f"{pixel_info['pixel_height']:.2f} ç±³")
            with col3:
                st.metric("åƒå…ƒé¢ç§¯", f"{pixel_info['pixel_area_m2']:.2f} å¹³æ–¹ç±³")
            with col4:
                st.metric("åƒå…ƒé¢ç§¯", f"{pixel_info['pixel_area_ha']:.6f} å…¬é¡·")
            
            if pixel_info['is_geographic']:
                st.warning("âš ï¸ å½±åƒä½¿ç”¨åœ°ç†åæ ‡ç³»ï¼Œé¢ç§¯è®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
        
        # æ˜¾ç¤ºç²¾åº¦ç»Ÿè®¡
        st.subheader("ç²¾åº¦ç»Ÿè®¡")
        classifier_row = st.session_state.comparison_df[
            st.session_state.comparison_df['åˆ†ç±»å™¨ä»£ç '] == selected_classifier_code
        ].iloc[0]
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è®­ç»ƒé›†ç²¾åº¦", f"{classifier_row['è®­ç»ƒé›†ç²¾åº¦']:.4f}")
        with col2:
            st.metric("éªŒè¯é›†ç²¾åº¦", f"{classifier_row['éªŒè¯é›†ç²¾åº¦']:.4f}")
        with col3:
            st.metric("è®­ç»ƒé›†Kappa", f"{classifier_row['è®­ç»ƒé›†Kappa']:.4f}")
        with col4:
            st.metric("éªŒè¯é›†Kappa", f"{classifier_row['éªŒè¯é›†Kappa']:.4f}")
        
        # æ˜¾ç¤ºé¢ç§¯ç»Ÿè®¡å’Œé¥¼å›¾
        st.subheader("é¢ç§¯ç»Ÿè®¡")
        if selected_classifier_code in st.session_state.area_statistics:
            area_stats = st.session_state.area_statistics[selected_classifier_code]
            
            # æ˜¾ç¤ºé¢ç§¯è¡¨æ ¼ - ä¼˜åŒ–æ˜¾ç¤º
            st.markdown("**é¢ç§¯ç»Ÿè®¡è¡¨æ ¼:**")
            area_df = pd.DataFrame([
                {
                    'ç±»åˆ«åç§°': class_name,
                    'ç±»åˆ«ID': stats['class_id'],
                    'åƒç´ æ•°é‡': stats['pixel_count'],
                    'é¢ç§¯(å…¬é¡·)': stats['area_ha'],
                    'ç™¾åˆ†æ¯”(%)': stats['percentage']
                }
                for class_name, stats in area_stats.items()
            ])
            
            # æ ¼å¼åŒ–æ˜¾ç¤º
            display_df = area_df.copy()
            display_df['åƒç´ æ•°é‡'] = display_df['åƒç´ æ•°é‡'].apply(lambda x: f"{x:,}")
            display_df['é¢ç§¯(å…¬é¡·)'] = display_df['é¢ç§¯(å…¬é¡·)'].apply(lambda x: f"{x:.2f}")
            display_df['ç™¾åˆ†æ¯”(%)'] = display_df['ç™¾åˆ†æ¯”(%)'].apply(lambda x: f"{x:.1f}%")
            
            st.dataframe(display_df, use_container_width=True)
            
            # æ˜¾ç¤ºé¥¼å›¾ - ä¼ å…¥class_colors
            st.markdown("**é¢ç§¯åˆ†å¸ƒé¥¼å›¾:**")
            pie_fig = backend.create_area_pie_chart(area_stats, class_colors)
            st.pyplot(pie_fig)
            
        else:
            st.warning("è¯¥åˆ†ç±»å™¨çš„é¢ç§¯ç»Ÿè®¡ä¿¡æ¯ä¸å¯ç”¨")
        
        # ä¸‹è½½åŒºåŸŸ - é‡æ–°ç»„ç»‡
        st.subheader("ä¸‹è½½ç»“æœ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # ä¸‹è½½åŸå§‹åˆ†ç±»å›¾åƒ
            with open(result_path, "rb") as f:
                result_data = f.read()
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½åˆ†ç±»ç»“æœ(TIF)",
                data=result_data,
                file_name=f"classification_{selected_classifier_name}.tif",
                mime="application/octet-stream"
            )
        
        with col2:
            # ä¸‹è½½é¢„è§ˆå›¾
            buf = BytesIO()
            preview_fig.savefig(buf, format="png", dpi=150, bbox_inches='tight')
            buf.seek(0)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½é¢„è§ˆå›¾(PNG)",
                data=buf,
                file_name=f"preview_{selected_classifier_name}.png",
                mime="image/png"
            )
        
        with col3:
            # ä¸‹è½½é¢ç§¯ç»Ÿè®¡
            if selected_classifier_code in st.session_state.area_statistics:
                area_csv = area_df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½é¢ç§¯ç»Ÿè®¡(CSV)",
                    data=area_csv,
                    file_name=f"area_stats_{selected_classifier_name}.csv",
                    mime="text/csv"
                )
        
        with col4:
            # ä¸‹è½½æ‰€æœ‰åˆ†ç±»å™¨ç»“æœï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
            if st.button("ğŸ“¦ ä¸‹è½½æ‰€æœ‰ç»“æœ", key="download_all"):
                download_all_results(selected_classifier_code)
        
    except Exception as e:
        st.error(f"é¢„è§ˆæ˜¾ç¤ºé”™è¯¯: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

def download_results():
    """ä¸‹è½½ç»“æœæ–‡ä»¶"""
    if st.session_state.comparison_df is None or st.session_state.comparison_df.empty:
        st.error("æ²¡æœ‰å¯ä¸‹è½½çš„ç»“æœ")
        return
    
    # åˆ›å»ºä¸‹è½½æ–‡ä»¶
    csv = st.session_state.comparison_df.to_csv(index=False)
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½CSVç»“æœ",
        data=csv,
        file_name="classification_results.csv",
        mime="text/csv"
    )
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
    report = f"""é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
================================
æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
è®­ç»ƒæ ·æœ¬: {len(st.session_state.y_train):,}
æ€»åˆ†ç±»å™¨æ•°: {len(st.session_state.comparison_df)}

éªŒè¯é›†ç²¾åº¦æ’å:
"""
    
    sorted_df = st.session_state.comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)
    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):
        report += f"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}\n"
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æ–‡æœ¬æŠ¥å‘Š",
        data=report,
        file_name="classification_report.txt",
        mime="text/plain"
    )
# æ–°å¢å‡½æ•°ï¼šä¸‹è½½æ‰€æœ‰åˆ†ç±»å™¨ç»“æœ
def download_all_results(current_classifier_code=None):
    """ä¸‹è½½æ‰€æœ‰åˆ†ç±»å™¨çš„ç»“æœæ–‡ä»¶"""
    if st.session_state.comparison_df is None or st.session_state.comparison_df.empty:
        st.error("æ²¡æœ‰å¯ä¸‹è½½çš„ç»“æœ")
        return
    
    try:
        # åˆ›å»ºZIPæ–‡ä»¶
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            
            # 1. æ·»åŠ æ¯”è¾ƒç»“æœCSV
            comparison_csv = st.session_state.comparison_df.to_csv(index=False)
            zip_file.writestr("æ‰€æœ‰åˆ†ç±»å™¨æ¯”è¾ƒç»“æœ.csv", comparison_csv)
            
            # 2. æ·»åŠ æ–‡æœ¬æŠ¥å‘Š
            report = generate_comprehensive_report()
            zip_file.writestr("åˆ†ç±»åˆ†ææŠ¥å‘Š.txt", report)
            
            # 3. æ·»åŠ å½“å‰åˆ†ç±»å™¨çš„è¯¦ç»†ç»“æœ
            if current_classifier_code:
                # åˆ†ç±»ç»“æœTIFF
                result_path = None
                if current_classifier_code == st.session_state.get('best_clf_code', ''):
                    result_path = st.session_state.best_result_path
                else:
                    temp_path = st.session_state.temp_path
                    result_path = temp_path / current_classifier_code / f"classified_{current_classifier_code}.tif"
                
                if result_path and result_path.exists():
                    zip_file.write(result_path, f"åˆ†ç±»ç»“æœ_{current_classifier_code}.tif")
                
                # é¢ç§¯ç»Ÿè®¡
                if current_classifier_code in st.session_state.area_statistics:
                    area_stats = st.session_state.area_statistics[current_classifier_code]
                    area_df = pd.DataFrame([
                        {
                            'ç±»åˆ«åç§°': class_name,
                            'ç±»åˆ«ID': stats['class_id'],
                            'åƒç´ æ•°é‡': stats['pixel_count'],
                            'é¢ç§¯(å…¬é¡·)': stats['area_ha'],
                            'ç™¾åˆ†æ¯”(%)': stats['percentage']
                        }
                        for class_name, stats in area_stats.items()
                    ])
                    area_csv = area_df.to_csv(index=False)
                    zip_file.writestr(f"é¢ç§¯ç»Ÿè®¡_{current_classifier_code}.csv", area_csv)
            
            # 4. æ·»åŠ æ‰€æœ‰åˆ†ç±»å™¨çš„é¢ç§¯ç»Ÿè®¡
            all_area_stats = {}
            for clf_code, area_stats in st.session_state.area_statistics.items():
                # è·å–åˆ†ç±»å™¨åç§°
                clf_name = st.session_state.comparison_df[
                    st.session_state.comparison_df['åˆ†ç±»å™¨ä»£ç '] == clf_code
                ]['åˆ†ç±»å™¨åç§°'].iloc[0] if not st.session_state.comparison_df.empty else clf_code
                
                for class_name, stats in area_stats.items():
                    key = f"{clf_name}_{class_name}"
                    all_area_stats[key] = {
                        'åˆ†ç±»å™¨': clf_name,
                        'ç±»åˆ«åç§°': class_name,
                        'ç±»åˆ«ID': stats['class_id'],
                        'åƒç´ æ•°é‡': stats['pixel_count'],
                        'é¢ç§¯(å…¬é¡·)': stats['area_ha'],
                        'ç™¾åˆ†æ¯”(%)': stats['percentage']
                    }
            
            if all_area_stats:
                all_area_df = pd.DataFrame(list(all_area_stats.values()))
                all_area_csv = all_area_df.to_csv(index=False)
                zip_file.writestr("æ‰€æœ‰åˆ†ç±»å™¨é¢ç§¯ç»Ÿè®¡.csv", all_area_csv)
        
        # æä¾›ä¸‹è½½
        zip_buffer.seek(0)
        current_time = time.strftime("%Y%m%d_%H%M%S")
        
        st.download_button(
            label="ğŸ“¦ ä¸‹è½½å®Œæ•´ç»“æœåŒ…(ZIP)",
            data=zip_buffer.getvalue(),
            file_name=f"é¥æ„Ÿåˆ†ç±»å®Œæ•´ç»“æœ_{current_time}.zip",
            mime="application/zip"
        )
        
    except Exception as e:
        st.error(f"åˆ›å»ºç»“æœåŒ…å¤±è´¥: {str(e)}")

# æ–°å¢å‡½æ•°ï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Š
def generate_comprehensive_report():
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
    report = f"""é¥æ„Ÿå½±åƒåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
================================
ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
è®­ç»ƒæ ·æœ¬æ•°: {len(st.session_state.y_train):,}
éªŒè¯æ ·æœ¬æ•°: {len(st.session_state.yv_true) if st.session_state.yv_true is not None else 0:,}
æ€»åˆ†ç±»å™¨æ•°: {len(st.session_state.comparison_df)}

åƒå…ƒä¿¡æ¯:
--------
åƒå…ƒå®½åº¦: {st.session_state.pixel_info['pixel_width']:.2f} ç±³
åƒå…ƒé«˜åº¦: {st.session_state.pixel_info['pixel_height']:.2f} ç±³
åƒå…ƒé¢ç§¯: {st.session_state.pixel_info['pixel_area_m2']:.2f} å¹³æ–¹ç±³
åƒå…ƒé¢ç§¯: {st.session_state.pixel_info['pixel_area_ha']:.6f} å…¬é¡·

éªŒè¯é›†ç²¾åº¦æ’å:
------------
"""
    
    sorted_df = st.session_state.comparison_df.sort_values('éªŒè¯é›†ç²¾åº¦', ascending=False)
    for idx, (_, row) in enumerate(sorted_df.iterrows(), 1):
        report += f"{idx}. {row['åˆ†ç±»å™¨åç§°']:15s} - ç²¾åº¦: {row['éªŒè¯é›†ç²¾åº¦']:.4f}, Kappa: {row['éªŒè¯é›†Kappa']:.4f}, è®­ç»ƒæ—¶é—´: {row['è®­ç»ƒæ—¶é—´(ç§’)']:.1f}s\n"
    
    # æ·»åŠ æœ€ä½³åˆ†ç±»å™¨ä¿¡æ¯
    if 'best_clf_code' in st.session_state:
        best_row = st.session_state.comparison_df[
            st.session_state.comparison_df['åˆ†ç±»å™¨ä»£ç '] == st.session_state.best_clf_code
        ].iloc[0]
        report += f"\næœ€ä½³åˆ†ç±»å™¨: {best_row['åˆ†ç±»å™¨åç§°']} (ç²¾åº¦: {best_row['éªŒè¯é›†ç²¾åº¦']:.4f})\n"
    
    return report
if __name__ == "__main__":
    main()


# åœ¨ ClassificationBackend ç±»ä¸­ä¿®æ”¹ create_area_pie_chart æ–¹æ³•


# åœ¨ display_result_preview å‡½æ•°ä¸­ä¿®æ”¹é¢ç§¯ç»Ÿè®¡æ˜¾ç¤ºéƒ¨åˆ†




# åœ¨ main() å‡½æ•°çš„ä¸‹è½½æŒ‰é’®éƒ¨åˆ†ä¹Ÿæ·»åŠ æ‰“åŒ…ä¸‹è½½åŠŸèƒ½
# åœ¨ tab1 çš„è¿è¡Œæ§åˆ¶éƒ¨åˆ†ä¿®æ”¹ä¸‹è½½æŒ‰é’®
